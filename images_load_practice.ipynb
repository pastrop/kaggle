{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "images_load_practice.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/images_load_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqWbTgsjttzn"
      },
      "source": [
        "*This a modified Google TF team notebook to demonstrate varios ways of loading images for further processing by neural networks.  As I found out, the preferred way of image using directory names as labels via tf.dataset doesn't work with tf.keras (neither it does with keras) bcs models built with tf.keras doesn't allow for string labels.  This problem has been first found in May and, allegedly fixed.  As I found out in June it wasn't...I found a workaround.  It allows to change labels into integers withouts a significant perfomance penalty (see melanoma_identification).<br> I checked again for the fix.  Google folk posted a very elegant workaround in the original notebook yet it look like they decided not to change the way tf.dataset process the labels internally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucMoYase6URl"
      },
      "source": [
        "# Load images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxw4WahM7DU9"
      },
      "source": [
        "This tutorial provides a simple example of how to load an image dataset using `tf.data`.\n",
        "\n",
        "The dataset used in this example is distributed as directories of images, with one class of image per directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoQQiZDB6URn"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vhAMaIOBIee"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6CcaqgQewg"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIksPgtT8B6B"
      },
      "source": [
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ20R66fzktl"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO0InzL66URu"
      },
      "source": [
        "### Retrieve the images\n",
        "\n",
        "Before you start any training, you will need a set of images to teach the network about the new classes you want to recognize. You can use an archive of creative-commons licensed flower photos from Google.\n",
        "\n",
        "Note: all images are licensed CC-BY, creators are listed in the `LICENSE.txt` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN-Pc6Zd6awg"
      },
      "source": [
        "import pathlib\n",
        "data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                                         fname='flower_photos', untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkFK74oO--g"
      },
      "source": [
        "After downloading (218MB), you should now have a copy of the flower photos available.\n",
        "\n",
        "The directory contains 5 sub-directories, one per class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWBhwK78tP3U"
      },
      "source": [
        "next(iter(data_dir.glob('*/*.jpg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhewYCxhXQBX"
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "image_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ1HKKdR4A7c"
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "CLASS_NAMES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVxsk4OW61TY"
      },
      "source": [
        "Each directory contains images of that type of flower. Here are some roses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crs7ZjEp60Ot"
      },
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "\n",
        "for image_path in roses[:3]:\n",
        "    display.display(Image.open(str(image_path)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jobDTUs8Wxu"
      },
      "source": [
        "## Load using `keras.preprocessing`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehhW308g8soJ"
      },
      "source": [
        "A simple way to load images is to use `tf.keras.preprocessing`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syDdF_LWVrWE"
      },
      "source": [
        "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAmtzsnjDNhB"
      },
      "source": [
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zf695or-Flq"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw94ajOOVrWI"
      },
      "source": [
        "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZgIZeXaDUsF"
      },
      "source": [
        "Inspect a batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLp0XVG_Vgi2"
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(32):\n",
        "      ax = plt.subplot(6,6,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suh6Sjv68rY3"
      },
      "source": [
        "image_batch, label_batch = next(train_data_gen)\n",
        "show_batch(image_batch, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxS1cLzM8mEp"
      },
      "source": [
        "## Load using `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylj9fgkamgWZ"
      },
      "source": [
        "The above `keras.preprocessing` method is convienient, but has three downsides: \n",
        "\n",
        "1. It's slow. See the performance section below.\n",
        "1. It lacks fine-grained control.\n",
        "1. It is not well integrated with the rest of TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIG5CPaULegg"
      },
      "source": [
        "To load the files as a `tf.data.Dataset` first create a dataset of the file paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAkQp5uxoINu"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coORvEH-NGwc"
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91CPfUUJ_8SZ"
      },
      "source": [
        "Write a short pure-tensorflow function that converts a file path to an `(img, label)` pair:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSQzIey-4D4"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGlq4IP4Aktb"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xhBRgvNqRRe"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9a5GpsUOBx8"
      },
      "source": [
        "Use `Dataset.map` to create a dataset of `image, label` pairs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SDhbo8lOBQv"
      },
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "test = labeled_ds.take(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxrl0lGdnpRz"
      },
      "source": [
        "for _, label in test:\n",
        "  #print(\"Image shape: \", image)\n",
        "  #print(\"Label: \", label.numpy())\n",
        "  #label = tf.strings.to_number('42', tf.int32)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIe9a9iSSPC0"
      },
      "source": [
        "for image, label in test:\n",
        "  print(\"Image shape: \", image.numpy())\n",
        "  print(\"Label: \", label.numpy())\n",
        "  #print(\"Label: \", label.numpy().decode('ascii'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZWuHq1HIQzk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNcIWpirBDH"
      },
      "source": [
        "**EXPERIMENTS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xsSrauBH9eR"
      },
      "source": [
        "changing labels to ints in the above dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DkrfYu4IR7B"
      },
      "source": [
        "# using \"test\" to experiment with\n",
        "imgs = []\n",
        "labels = []\n",
        "for image, label in test:\n",
        "  if label.numpy().decode('ascii') == 'daisy':\n",
        "    label = np.array([0])\n",
        "  else: \n",
        "    label = np.array([1])  \n",
        "  imgs.append(image.numpy())\n",
        "  labels.append(label)\n",
        "\n",
        "changed_test = tf.data.Dataset.from_tensor_slices((tf.constant(imgs), tf.constant(labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD2in37jL6sO"
      },
      "source": [
        "for img, label in changed_test:\n",
        "  print(\"Image shape: \", image.numpy())\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0GhhOn0sacC"
      },
      "source": [
        "#experiments:\n",
        "arg = tf.convert_to_tensor(['1','0','1'], dtype=tf.string); arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG4In9bEz2CH"
      },
      "source": [
        "def test_path(file_path):\n",
        "  #label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d22Lj0Df0K0G"
      },
      "source": [
        "test_path('/root/.keras/datasets/flower_photos/dandelion/5607669502_ccd2a76668_n.jpg').numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkcTitMoJTO8"
      },
      "source": [
        "test = pathlib.Path(data_dir/'roses/'); test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iPYP1AyKFiV"
      },
      "source": [
        "image_count = len(list(test.glob('*.jpg')))\n",
        "image_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruF0rrENKSfo"
      },
      "source": [
        "# random array of ones and zeros\n",
        "labels = [0]*400 + [1]*241"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MPSVZZBLRPv"
      },
      "source": [
        "#import shutil\n",
        "ex = list(test.glob('*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0AqqtnkMKEw"
      },
      "source": [
        "filenames = []\n",
        "for item in ex:\n",
        "    filenames.append(str(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgm8NWtVMrdy"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE5Wep2lMtYS"
      },
      "source": [
        "# Function to load and preprocess each image\n",
        "def _parse_fn(filename, label):\n",
        "    img = tf.io.read_file(filename)\n",
        "    img = tf.image.decode_jpeg(img)\n",
        "    img = (tf.cast(img, tf.float32)/127.5) - 1\n",
        "    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCAfWrCRM49p"
      },
      "source": [
        "IMAGE_SIZE = 224 # Minimum image size for use with MobileNetV2\n",
        "BATCH_SIZE = 32\n",
        "train_data = train_data.map(_parse_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvXjBhQ_NEqC"
      },
      "source": [
        "for image, label in train_data.take(1):\n",
        "    print(\"Image shape: \", image.numpy().shape)\n",
        "    print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYGCgJuR_9Qp"
      },
      "source": [
        "### Basic methods for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwZavzgsIytz"
      },
      "source": [
        "To train a model with this dataset you will want the data:\n",
        "\n",
        "* To be well shuffled.\n",
        "* To be batched.\n",
        "* Batches to be available as soon as possible.\n",
        "\n",
        "These features can be easily added using the `tf.data` api."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmZJx8ePw_5"
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YKnrfAeZV10"
      },
      "source": [
        "train_ds = prepare_for_training(labeled_ds)\n",
        "\n",
        "#image_batch, label_batch = next(iter(train_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bize0cNH43B"
      },
      "source": [
        "type(train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1y2cEngM3vC"
      },
      "source": [
        "test_ds = prepare_for_training(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDyMk7QjqaVr"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96CkOtu9Fbb2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzl5Mnj7qfP8"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzHrg9i-KtLL"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2u9zmf5qnho"
      },
      "source": [
        "model.fit(test_ds,\n",
        "          epochs=10,\n",
        "          steps_per_epoch = 3600//320)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLQAMeTRPhMm"
      },
      "source": [
        "model_multi = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model_multi.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5J93CadQOvk"
      },
      "source": [
        "# Compile the model\n",
        "model_multi.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sqn7VQnQovL"
      },
      "source": [
        "model.fit(train_ds,\n",
        "          epochs=5,\n",
        "          steps_per_epoch = 3600//320)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMVnoBcG_NlQ"
      },
      "source": [
        "## Performance\n",
        "\n",
        "Note: This section just shows a couple of easy tricks that may help performance. For an in depth guide see [Input Pipeline Performance](../../guide/performance/datasets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNmQqgGhLWie"
      },
      "source": [
        "To investigate, first here's a function to check the performance of our datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gFVe1rp_MYr"
      },
      "source": [
        "import time\n",
        "default_timeit_steps = 1000\n",
        "\n",
        "def timeit(ds, steps=default_timeit_steps):\n",
        "  start = time.time()\n",
        "  it = iter(ds)\n",
        "  for i in range(steps):\n",
        "    batch = next(it)\n",
        "    if i%10 == 0:\n",
        "      print('.',end='')\n",
        "  print()\n",
        "  end = time.time()\n",
        "\n",
        "  duration = end-start\n",
        "  print(\"{} batches: {} s\".format(steps, duration))\n",
        "  print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYiOr4vdLcNX"
      },
      "source": [
        "Let's compare the speed of the two data generators:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Yc-jZnVjvm"
      },
      "source": [
        "# `keras.preprocessing`\n",
        "timeit(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjouTJadRxyp"
      },
      "source": [
        "# `tf.data`\n",
        "timeit(train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB2TjJR62BJ3"
      },
      "source": [
        "A large part of the performance gain comes from the use of `.cache`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq1V854E2Nh4"
      },
      "source": [
        "uncached_ds = prepare_for_training(labeled_ds, cache=False)\n",
        "timeit(uncached_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JCHymejWSPZ"
      },
      "source": [
        "If the dataset doesn't fit in memory use a cache file to maintain some of the advantages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqHFQFwxWNbu"
      },
      "source": [
        "filecache_ds = prepare_for_training(labeled_ds, cache=\"./flowers.tfcache\")\n",
        "timeit(filecache_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2UkXXvhxhd4"
      },
      "source": [
        "# Sandbox<br> \n",
        "working with DCM images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uchBL5kUxof1"
      },
      "source": [
        "# file upload while using Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7wBNvxGyTTU"
      },
      "source": [
        "#loading .npy & .npz files. I am using a set of processed medical images from the kaggle pulmonary fibrosis competition\n",
        "import numpy as np\n",
        "# load numpy array from npy file\n",
        "from numpy import load\n",
        "# load array\n",
        "#images_set = load('data.npy')\n",
        "\n",
        "# load dict of arrays\n",
        "dict_data = load('data.npz')\n",
        "# extract the first array\n",
        "images_set = dict_data['arr_0']\n",
        "len(images_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfQDeFt6zGS8"
      },
      "source": [
        "import functools as f\n",
        "import matplotlib.pyplot as plt\n",
        "res_image = f.reduce(lambda x,y: np.add(x,y), images_set)/5\n",
        "fig, axes = plt.subplots(2,3, figsize=(20,20))\n",
        "axes[0,0].imshow(res_image, cmap='gray')\n",
        "axes[0,1].imshow(images_set[0], cmap='gray')\n",
        "axes[0,2].imshow(images_set[1], cmap='gray')\n",
        "axes[1,0].imshow(images_set[2], cmap='gray')\n",
        "axes[1,1].imshow(images_set[3], cmap='gray')\n",
        "axes[1,2].imshow(images_set[4], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJNY_1QE-kdY"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cELbl49K-sYC"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjsuJlMp_HqP"
      },
      "source": [
        "METRICS = [\n",
        "      #tf.keras.metrics.TruePositives(name='tp'),\n",
        "      #tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      #tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      #tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      #tf.keras.metrics.Precision(name='precision'),\n",
        "      #tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-QDMijv_Mgm"
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "# Pre-trained model with MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "# Freeze the pre-trained model weights\n",
        "base_model.trainable = True\n",
        "# Trainable classification head\n",
        "maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# Layer classification head with feature detector\n",
        "model_mobileNet = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    maxpool_layer,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "model_mobileNet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntpWIgAW_gNy"
      },
      "source": [
        "learning_rate = 0.0005\n",
        "model_mobileNet.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD2XfU94_mz8"
      },
      "source": [
        "model_mobileNet.fit(train_ds_batched,\n",
        "          epochs=5,\n",
        "          steps_per_epoch = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_RtGeLMlBKr"
      },
      "source": [
        "# Using Torch Hooks for Network Layers Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91_rGxljlVZ2"
      },
      "source": [
        "import torch\r\n",
        "from torchvision.models import resnet34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4qqcjdYlcDN"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\r\n",
        "model = resnet34(pretrained=True)\r\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olHP3ZSLlfrw"
      },
      "source": [
        "class SaveOutput:\r\n",
        "    def __init__(self):\r\n",
        "        self.outputs = []\r\n",
        "        \r\n",
        "    def __call__(self, module, module_in, module_out):\r\n",
        "        self.outputs.append(module_out)\r\n",
        "        \r\n",
        "    def clear(self):\r\n",
        "        self.outputs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw9lMo3_lozO"
      },
      "source": [
        "save_output = SaveOutput()\r\n",
        "\r\n",
        "hook_handles = []\r\n",
        "\r\n",
        "for layer in model.modules():\r\n",
        "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\r\n",
        "        handle = layer.register_forward_hook(save_output)\r\n",
        "        hook_handles.append(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZdwT-W5lvOw"
      },
      "source": [
        "from PIL import Image\r\n",
        "from torchvision import transforms as T\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYCBGR6RowpE"
      },
      "source": [
        "# file upload while using Google Colab\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRjvoAaVq078"
      },
      "source": [
        "image = Image.open('hmgoepprod.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z20-DhC2qI1w"
      },
      "source": [
        "plt.figure(figsize=(16, 6))\r\n",
        "plt.imshow(image)\r\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkLvNt01oSUo"
      },
      "source": [
        "transform = T.Compose([T.Resize((224, 224)), T.ToTensor()])\r\n",
        "X = transform(image).unsqueeze(dim=0).to(device)\r\n",
        "\r\n",
        "out = model(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE2t3o1rtYuh"
      },
      "source": [
        "save_output.outputs[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx0KzqSbl5Ra"
      },
      "source": [
        "# show some images\r\n",
        "def module_output_to_numpy(tensor):\r\n",
        "    return tensor.detach().to('cpu').numpy()    \r\n",
        "\r\n",
        "images = module_output_to_numpy(save_output.outputs[0])\r\n",
        "\r\n",
        "with plt.style.context(\"seaborn-white\"):\r\n",
        "    plt.figure(figsize=(20, 20), frameon=False)\r\n",
        "    for idx in range(64):\r\n",
        "        plt.subplot(8, 8, idx+1)\r\n",
        "        plt.imshow(images[0, idx])\r\n",
        "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}