{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ltWTb_wizi2G"
      ],
      "authorship_tag": "ABX9TyOO7U4tAHi6dUA4zAb0DSwn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/ThinkingAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "almxb-Dl3bpI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "#from anthropic import Anthropic\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional"
      ],
      "metadata": {
        "id": "Xa9wFmP_4DAO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#api_key_openAI = userdata.get('OpenAI')\n",
        "api_key_anthropic = userdata.get('Antropic')\n",
        "#api_key_gemini = userdata.get('google')"
      ],
      "metadata": {
        "id": "yAiFCOFa4dV3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = 'frog_ferry_meta.csv'"
      ],
      "metadata": {
        "id": "b5EW9t9nnRk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset to be used:\n",
        "df = pd.read_csv(csv_file)\n",
        "#Text cleanup\n",
        "def text_input(file = 'Mejuri_texts.csv'):\n",
        "  df = pd.read_csv(file)\n",
        "  df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "  texts = [item.replace(\"\\t\", \" \") for item in df_clean['Text']]\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "id": "dkaDtclI4j_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting a corpus of texts\n",
        "texts_cleaned = text_input(csv_file)\n",
        "corpus = ' '.join(texts_cleaned)\n",
        "test1 = ' '.join(corpus.split()[:20000])"
      ],
      "metadata": {
        "id": "9mD4X9ST4wwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the dataframe into the list of dicts\n",
        "df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "records = df_clean.to_dict(orient='records')"
      ],
      "metadata": {
        "id": "RCMpdaMOUsyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4HedLU2bVpt",
        "outputId": "f25a774e-2913-40a1-e1a7-e6555a3a9db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Text': 'We have GREATLY appreciated the addition of speed bumps and cross walks in our area by Roosevelt. More traffic calming features and accessible curbs would always be appreciated. A swing set at George park or some other fun addition to the play area there (basketball court, garden, or fenced area for off leash dogs) would be amazing! The FROG FERRY would be SO GREAT for our community, having the option to take a ferry downtown would be so fun for tourists and a great way for locals to spend the day and obviously commuters would benefit so much. I think the addition of a ferry would be ICONIC.',\n",
              " 'connection': 4,\n",
              " 'recommend': 5,\n",
              " 'satisfaction': 6,\n",
              " 'verified': 'Yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thinking Agent"
      ],
      "metadata": {
        "id": "gpHutfKBVpR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_context(self, corpus: str = None, question: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Your actual get_context tool implementation.\n",
        "    This is the function Claude can call.\n",
        "    \"\"\"\n",
        "\n",
        "    if corpus == None or question == None:\n",
        "        return \"No context available - empty corpus or question provided.\""
      ],
      "metadata": {
        "id": "nuyB1UHkR_fi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rK3wYScCTZHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key #or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        #print(f'task as defined in the analyze function: {task}')\n",
        "        #print(f'context as defined in the analyze function: {context}')\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "You have an access to a specialized tool called get_context.\n",
        "The get_context tool allows you to get a summary a corpus of text to find relevant information based on a question. Use this tool when:\n",
        "- The user asks a question that might be answered by searching through available text\n",
        "- You need to find specific information within a large body of text\n",
        "- The user's query would benefit from contextual information retrieval\n",
        "Provide your analysis in the VALID JSON FORMAT including the following fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- use_metadata: Set this field to 'True' if metadata analysis is required and 'False' otherwise\n",
        "- tools: List tools to use\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Define the tool\n",
        "        tools = [\n",
        "            {\n",
        "                \"name\": \"get_context\",\n",
        "                \"description\": \"Search through a corpus of text to find relevant context based on a question\",\n",
        "                \"input_schema\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"corpus\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The text corpus to search through\"\n",
        "                        },\n",
        "                        \"question\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The question or topic to find relevant context for\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"corpus\", \"question\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"filter\",\n",
        "                \"description\": \"Filter the dataset by given criteria\",\n",
        "                \"input_schema\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"data_set\": {\n",
        "                            \"type\": \"pandas dataframe\",\n",
        "                            \"description\": \"The dataframe to search through inluding text column and metadata columns\"\n",
        "                        },\n",
        "                        \"filter_criteria\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The cirteria to filter by\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"data_set\", \"filter_criteria\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"key_words\",\n",
        "                \"description\": \"Get keywords from the text\",\n",
        "                \"input_schema\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"text_corpus\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The text corpus to extract keywards from\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"text_corpus\"]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON\",\n",
        "            tools=tools,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        print(f'ANALYZE FUNCTION-RESPONSE: {response}')\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "\n",
        "        # Find JSON in the response content\n",
        "        content = response.content[0].text\n",
        "\n",
        "        print(f\"@@@@@@@@@@@@@@@@Claude's response - analyze function: {content}\")\n",
        "\n",
        "        print(f\"@@@@@@response.stop_reason - analyze function: {response.stop_reason}\")\n",
        "        tool_calls = [block for block in response.content if block.type == \"tool_use\"]\n",
        "        print(f\"$$$$$$$$$$$$$tool_calls - analyze function: { tool_calls}\")\n",
        "\n",
        "        return content\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fhlJ8nUl5Fyt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative thinking module\n",
        "class ThinkingModuleAlt:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key #or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        #print(f'task as defined in the analyze function: {task}')\n",
        "        #print(f'context as defined in the analyze function: {context}')\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in the VALID JSON FORMAT including the following fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- use_metadata: Set this field to 'True' if metadata analysis is required and 'False' otherwise\n",
        "- metadata_tool: Suggest a list of additional tools that can be used for metadata analysis if the use_ metadata field is set to 'True'\n",
        "</thinking>\"\"\"\n",
        "\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        print(f'ANALYZE FUNCTION-RESPONSE: {response}')\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "\n",
        "        # Find JSON in the response content\n",
        "        content = response.content[0].text\n",
        "\n",
        "        print(f\"@@@@@@@@@@@@@@@@Claude's response - analyze function: {content}\")\n",
        "\n",
        "        print(f\"@@@@@@response.stop_reason - analyze function: {response.stop_reason}\")\n",
        "        tool_calls = [block for block in response.content if block.type == \"tool_use\"]\n",
        "        print(f\"$$$$$$$$$$$$$tool_calls - analyze function: { tool_calls}\")\n",
        "\n",
        "        return content"
      ],
      "metadata": {
        "id": "9XKZM42aRTi2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \"```json\" in content:\n",
        "                json_str = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in content:\n",
        "                json_str = content.split(\"```\")[1].split(\"```\")[0].strip()"
      ],
      "metadata": {
        "id": "8qYN6KlsI9o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class MetadataAnalysisTool:\n",
        "    \"\"\"Stub for the metadata analysis tool.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialization for metadata tool would go here\n",
        "        pass\n",
        "\n",
        "    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Analyze reviews based on metadata parameters.\n",
        "\n",
        "        Args:\n",
        "            params: Parameters for filtering and analyzing metadata\n",
        "\n",
        "        Returns:\n",
        "            Filtered list of reviews\n",
        "        \"\"\"\n",
        "        # This is just a stub implementation\n",
        "        print(f\"Metadata tool called with parameters: {params}\")\n",
        "        # In a real implementation, this would filter the actual reviews\n",
        "        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "9x1DkfjBFd1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewAnalysisAgent:\n",
        "    \"\"\"Agent that processes customer queries about review data.\"\"\"\n",
        "\n",
        "    def __init__(self, review_corpus: List[Dict], api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the review analysis agent.\n",
        "\n",
        "        Args:\n",
        "            review_corpus: Collection of customer reviews with metadata\n",
        "            api_key: Anthropic API key (optional if set in environment variables)\n",
        "        \"\"\"\n",
        "        self.review_corpus = review_corpus\n",
        "        #self.metadata_tool = MetadataAnalysisTool()\n",
        "        self.thinking_module = ThinkingModule(api_key=api_key)\n",
        "        self.thinking_module_alt = ThinkingModuleAlt(api_key=api_key)\n",
        "\n",
        "    def process_query(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Process a customer query and return a response.\n",
        "\n",
        "        Args:\n",
        "            query: Natural language query about the review data\n",
        "\n",
        "        Returns:\n",
        "            Response to the query based on review analysis\n",
        "        \"\"\"\n",
        "        # Step 1: Understand the query through the thinking module\n",
        "        print(f'#####################step 1: Understand the query through the thinking module')\n",
        "\n",
        "        #change the thinking module type here\n",
        "        query_analysis = self.thinking_module_alt.analyze(\n",
        "            task=\"Analyze the user query to extract: (1) primary information need, \"\n",
        "                 \"(2)type of analysis requested, \"\n",
        "                 \"(3) whether numerical/metadata analysis is likely needed\",\n",
        "            context=f\"User query: {query}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "        return query_analysis\n",
        "\n",
        "'''\n",
        "        # Step 2: Decide whether to use metadata tool\n",
        "        print(f'#####################step 2: Decide whether to use metadata tool')\n",
        "\n",
        "\n",
        "        tool_decision = self.thinking_module.analyze(\n",
        "            task=\"Determine if metadata analysis is required or beneficial for this query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        print(f'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}')\n",
        "\n",
        "        # Step 3: Execute appropriate analysis\n",
        "        print(f'#####################calling thinking module form the process_query step 3')\n",
        "\n",
        "        #next line has a bug, needs work\n",
        "        #tools_decision_keys_to_extract = ['additional_fields', 'use_metadata_tool', 'd']\n",
        "        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\n",
        "        additional_fields = tool_decision.get(\"additional_fields\", {})\n",
        "        use_metadata = tool_decision.get(\"use_metadata\", False)\n",
        "        print(f'use_metadata call results: {use_metadata}')\n",
        "        print(f'additional_fields call results: {additional_fields}')\n",
        "        #######################################################################################\n",
        "        print('Execution terminated')\n",
        "        raise RuntimeError(\"Stopping execution intentionally.\")\n",
        "        #######################################################################################\n",
        "        if use_metadata:\n",
        "            # Define parameters for metadata tool\n",
        "            metadata_params = self.thinking_module.analyze(\n",
        "                task=\"Determine optimal parameters for metadata tool based on the query\",\n",
        "                context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\n",
        "                reflection_depth=1\n",
        "            )\n",
        "\n",
        "            # Use metadata tool to get filtered set of reviews\n",
        "            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\n",
        "            print(f'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}')\n",
        "            #test: making sure that the metada tool is properly activated\n",
        "            #test block ends\n",
        "            filtered_reviews = self.metadata_tool.analyze(tool_params)\n",
        "            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\n",
        "        else:\n",
        "            # Just analyze the full text corpus\n",
        "            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\n",
        "\n",
        "        # Step 4: Generate final response\n",
        "\n",
        "        print(f'#####################calling thinking module form the process_query step 4')\n",
        "\n",
        "        response = self.thinking_module.analyze(\n",
        "            task=\"Synthesize findings into a comprehensive response to the user query\",\n",
        "            context=f\"Query: {query}\\n\"\n",
        "                   f\"Analysis results: {text_analysis}\\n\"\n",
        "                   f\"Was metadata used: {'Yes' if use_metadata else 'No'}\\n\"\n",
        "                   f\"Thinking process: {query_analysis.get('reasoning', '')}\\n\"\n",
        "                   f\"Tool decision reasoning: {tool_decision.get('reasoning', '')}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Return the final response text\n",
        "        return response.get(\"conclusion\", \"I couldn't generate a proper response.\")\n",
        "\n",
        "    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze the text content of reviews.\n",
        "\n",
        "        Args:\n",
        "            reviews: List of review objects to analyze\n",
        "            query_analysis: Analysis of the user query to guide text analysis\n",
        "\n",
        "        Returns:\n",
        "            Results of the text analysis\n",
        "        \"\"\"\n",
        "        # In a real implementation, this would use NLP techniques\n",
        "        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\n",
        "\n",
        "        # Stub implementation\n",
        "        review_texts = [review.get(\"Text\", \"\") for review in reviews]\n",
        "\n",
        "        # Use the thinking module to analyze the reviews based on the query\n",
        "\n",
        "        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus')\n",
        "\n",
        "        analysis_result = self.thinking_module.analyze(\n",
        "            task=\"Analyze review texts to answer the user query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        return analysis_result\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "RXkurMUoFNkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "9a59911a-832a-45c4-e3a7-7314caf5ced1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n        # Step 2: Decide whether to use metadata tool\\n        print(f\\'#####################step 2: Decide whether to use metadata tool\\')\\n\\n\\n        tool_decision = self.thinking_module.analyze(\\n            task=\"Determine if metadata analysis is required or beneficial for this query\",\\n            context=f\"Query analysis: {query_analysis}\\n\"\\n                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\\n            reflection_depth=2\\n        )\\n\\n        print(f\\'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}\\')\\n\\n        # Step 3: Execute appropriate analysis\\n        print(f\\'#####################calling thinking module form the process_query step 3\\')\\n\\n        #next line has a bug, needs work\\n        #tools_decision_keys_to_extract = [\\'additional_fields\\', \\'use_metadata_tool\\', \\'d\\']\\n        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\\n        additional_fields = tool_decision.get(\"additional_fields\", {})\\n        use_metadata = tool_decision.get(\"use_metadata\", False)\\n        print(f\\'use_metadata call results: {use_metadata}\\')\\n        print(f\\'additional_fields call results: {additional_fields}\\')\\n        #######################################################################################\\n        print(\\'Execution terminated\\')\\n        raise RuntimeError(\"Stopping execution intentionally.\")\\n        #######################################################################################\\n        if use_metadata:\\n            # Define parameters for metadata tool\\n            metadata_params = self.thinking_module.analyze(\\n                task=\"Determine optimal parameters for metadata tool based on the query\",\\n                context=f\"Query analysis: {query_analysis}\\n\"\\n                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\\n                reflection_depth=1\\n            )\\n\\n            # Use metadata tool to get filtered set of reviews\\n            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\\n            print(f\\'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}\\')\\n            #test: making sure that the metada tool is properly activated\\n            #test block ends\\n            filtered_reviews = self.metadata_tool.analyze(tool_params)\\n            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\\n        else:\\n            # Just analyze the full text corpus\\n            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\\n\\n        # Step 4: Generate final response\\n\\n        print(f\\'#####################calling thinking module form the process_query step 4\\')\\n\\n        response = self.thinking_module.analyze(\\n            task=\"Synthesize findings into a comprehensive response to the user query\",\\n            context=f\"Query: {query}\\n\"\\n                   f\"Analysis results: {text_analysis}\\n\"\\n                   f\"Was metadata used: {\\'Yes\\' if use_metadata else \\'No\\'}\\n\"\\n                   f\"Thinking process: {query_analysis.get(\\'reasoning\\', \\'\\')}\\n\"\\n                   f\"Tool decision reasoning: {tool_decision.get(\\'reasoning\\', \\'\\')}\",\\n            reflection_depth=2\\n        )\\n\\n        # Return the final response text\\n        return response.get(\"conclusion\", \"I couldn\\'t generate a proper response.\")\\n\\n    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\\n        \"\"\"\\n        Analyze the text content of reviews.\\n\\n        Args:\\n            reviews: List of review objects to analyze\\n            query_analysis: Analysis of the user query to guide text analysis\\n\\n        Returns:\\n            Results of the text analysis\\n        \"\"\"\\n        # In a real implementation, this would use NLP techniques\\n        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\\n\\n        # Stub implementation\\n        review_texts = [review.get(\"Text\", \"\") for review in reviews]\\n\\n        # Use the thinking module to analyze the reviews based on the query\\n\\n        print(f\\'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus\\')\\n\\n        analysis_result = self.thinking_module.analyze(\\n            task=\"Analyze review texts to answer the user query\",\\n            context=f\"Query analysis: {query_analysis}\\n\"\\n                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\\n            reflection_depth=2\\n        )\\n\\n        return analysis_result\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "queries (St.John):\n",
        "Where are pedestrian safety improvements needed?\n",
        "What can police be doing to make the neighborhood safer?\n",
        "What can city council prioritize to help St Johns?\n",
        "What new businesses are needed in St Johns and where?\n",
        "What issues would Frog Ferry solve?"
      ],
      "metadata": {
        "id": "4QH6WsxFYhGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(records_stjohn[1000:5400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtxf247Xhjad",
        "outputId": "b34d3e13-184b-4bd0-adf4-1e15209ea55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4400"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "# Set your API key\n",
        "api_key = api_key_anthropic\n",
        "records = {}\n",
        "# Sample review corpus (in a real scenario, this would be much larger)\n",
        "sample_reviews = [\n",
        "    {\"id\": 1, \"text\": \"Love this product! Battery life is amazing.\", \"rating\": 5, \"verified\": True},\n",
        "    {\"id\": 2, \"text\": \"Decent product but overpriced for what you get.\", \"rating\": 3, \"verified\": True},\n",
        "    {\"id\": 3, \"text\": \"Terrible quality, broke after one week.\", \"rating\": 1, \"verified\": True},\n",
        "    # In reality, you'd have thousands more reviews here\n",
        "]\n",
        "\n",
        "# Initialize the agent\n",
        "\n",
        "agent = ReviewAnalysisAgent(review_corpus=records, api_key=api_key)\n",
        "\n",
        "# Example queries\n",
        "queries = [\n",
        "    \"What do customers think about the battery life? assume you have a dataset of the customer reviews about a produc\"\n",
        "    #\"Are verified purchasers happier with the product than non-verified ones?\",\n",
        "    #\"What are the most common complaints in 1-star reviews?\"\n",
        "]\n",
        "\n",
        "query_battery = '''\n",
        "What do customers think about the battery life? assume you have a dataset of the customer reviews about a product\n",
        "that includes a battery, reviews discuss the product and may include information and opinions about the battery.\n",
        "every review comes with the metadata including review rating, overall sentiment, geographic region the review comes from\n",
        "'''\n",
        "\n",
        "query_stjohn = '''\n",
        "What issues would 'Frog Ferry' ferry service solve? What customers are saying about the service? Pls only consider 'verified' reviews with 'satisfaction' rating above 5\"\n",
        "'''\n",
        "response = agent.process_query(query_stjohn)\n",
        "print(f\"#####Response: {response}\")\n",
        "\n",
        "'''\n",
        "queries_stjohn = [\n",
        "    #\"Where are pedestrian safety improvements needed?\",\n",
        "    #\"What can police be doing to make the neighborhood safer?\",\n",
        "    #\"What can city council prioritize to help St Johns?\",\n",
        "    #\"What new businesses are needed in St Johns and where?\",\n",
        "    #\"What issues would Frog Ferry solve?\",\n",
        "    \"What issues would 'Frog Ferry' ferry service solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5 \"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for query in queries_stjohn:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = agent.process_query(query)\n",
        "    print(f\"Response: {response}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "JDBFbblk5i35",
        "outputId": "3a7502ea-4ecd-4614-833e-96271dbb3713"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####################step 1: Understand the query through the thinking module\n",
            "ANALYZE FUNCTION-RESPONSE: Message(id='msg_01UppMsbWRC5M41yujHmcQHc', content=[TextBlock(citations=None, text='```json\\n{\\n  \"reasoning\": \"Let me analyze this query step by step:\\\\n\\\\n1. The user is asking about \\'Frog Ferry\\' ferry service, specifically:\\\\n   - What issues the service would solve\\\\n   - What customers are saying about the service\\\\n\\\\n2. There are specific filtering requirements:\\\\n   - Only consider \\'verified\\' reviews\\\\n   - Only include reviews with \\'satisfaction\\' rating above 5\\\\n\\\\n3. This suggests the user wants:\\\\n   - Information about the purpose/benefits of the Frog Ferry service\\\\n   - A filtered analysis of customer reviews based on specific metadata attributes\\\\n\\\\n4. The query explicitly mentions filtering by:\\\\n   - A verification status (likely a boolean or categorical field)\\\\n   - A numerical satisfaction rating (with a threshold of >5)\\\\n\\\\n5. To properly answer this query, I would need to:\\\\n   - Search for information about the Frog Ferry service\\'s purpose\\\\n   - Access a database of customer reviews\\\\n   - Filter those reviews based on verification status and satisfaction rating\\\\n   - Analyze the filtered reviews for common themes/sentiments\",\\n  \"conclusion\": \"The user needs information about the Frog Ferry service\\'s purpose and a filtered analysis of customer reviews that meet specific metadata criteria (verified status and satisfaction rating >5). This requires both content search and metadata filtering capabilities.\",\\n  \"confidence\": 0.9,\\n  \"use_metadata\": true,\\n  \"metadata_tool\": [\"review_database_filter\", \"sentiment_analysis\", \"numerical_comparison\", \"categorical_filter\"]\\n}\\n```', type='text')], model='claude-3-7-sonnet-20250219', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=270, output_tokens=360, server_tool_use=None, service_tier='standard'))\n",
            "@@@@@@@@@@@@@@@@Claude's response - analyze function: ```json\n",
            "{\n",
            "  \"reasoning\": \"Let me analyze this query step by step:\\n\\n1. The user is asking about 'Frog Ferry' ferry service, specifically:\\n   - What issues the service would solve\\n   - What customers are saying about the service\\n\\n2. There are specific filtering requirements:\\n   - Only consider 'verified' reviews\\n   - Only include reviews with 'satisfaction' rating above 5\\n\\n3. This suggests the user wants:\\n   - Information about the purpose/benefits of the Frog Ferry service\\n   - A filtered analysis of customer reviews based on specific metadata attributes\\n\\n4. The query explicitly mentions filtering by:\\n   - A verification status (likely a boolean or categorical field)\\n   - A numerical satisfaction rating (with a threshold of >5)\\n\\n5. To properly answer this query, I would need to:\\n   - Search for information about the Frog Ferry service's purpose\\n   - Access a database of customer reviews\\n   - Filter those reviews based on verification status and satisfaction rating\\n   - Analyze the filtered reviews for common themes/sentiments\",\n",
            "  \"conclusion\": \"The user needs information about the Frog Ferry service's purpose and a filtered analysis of customer reviews that meet specific metadata criteria (verified status and satisfaction rating >5). This requires both content search and metadata filtering capabilities.\",\n",
            "  \"confidence\": 0.9,\n",
            "  \"use_metadata\": true,\n",
            "  \"metadata_tool\": [\"review_database_filter\", \"sentiment_analysis\", \"numerical_comparison\", \"categorical_filter\"]\n",
            "}\n",
            "```\n",
            "@@@@@@response.stop_reason - analyze function: end_turn\n",
            "$$$$$$$$$$$$$tool_calls - analyze function: []\n",
            "#####Response: ```json\n",
            "{\n",
            "  \"reasoning\": \"Let me analyze this query step by step:\\n\\n1. The user is asking about 'Frog Ferry' ferry service, specifically:\\n   - What issues the service would solve\\n   - What customers are saying about the service\\n\\n2. There are specific filtering requirements:\\n   - Only consider 'verified' reviews\\n   - Only include reviews with 'satisfaction' rating above 5\\n\\n3. This suggests the user wants:\\n   - Information about the purpose/benefits of the Frog Ferry service\\n   - A filtered analysis of customer reviews based on specific metadata attributes\\n\\n4. The query explicitly mentions filtering by:\\n   - A verification status (likely a boolean or categorical field)\\n   - A numerical satisfaction rating (with a threshold of >5)\\n\\n5. To properly answer this query, I would need to:\\n   - Search for information about the Frog Ferry service's purpose\\n   - Access a database of customer reviews\\n   - Filter those reviews based on verification status and satisfaction rating\\n   - Analyze the filtered reviews for common themes/sentiments\",\n",
            "  \"conclusion\": \"The user needs information about the Frog Ferry service's purpose and a filtered analysis of customer reviews that meet specific metadata criteria (verified status and satisfaction rating >5). This requires both content search and metadata filtering capabilities.\",\n",
            "  \"confidence\": 0.9,\n",
            "  \"use_metadata\": true,\n",
            "  \"metadata_tool\": [\"review_database_filter\", \"sentiment_analysis\", \"numerical_comparison\", \"categorical_filter\"]\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nqueries_stjohn = [\\n    #\"Where are pedestrian safety improvements needed?\",\\n    #\"What can police be doing to make the neighborhood safer?\",\\n    #\"What can city council prioritize to help St Johns?\",\\n    #\"What new businesses are needed in St Johns and where?\",\\n    #\"What issues would Frog Ferry solve?\",\\n    \"What issues would \\'Frog Ferry\\' ferry service solve? pls only consider \\'verified\\' reviews with \\'satisfaction\\' rating above 5 \"\\n]\\n\\n# Process each query\\nfor query in queries_stjohn:\\n    print(f\"\\nQuery: {query}\")\\n    response = agent.process_query(query)\\n    print(f\"Response: {response}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTmCs87VjAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Future features**"
      ],
      "metadata": {
        "id": "ltWTb_wizi2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#including csv data into the prompt for the thinking module\n",
        "filtered_data_json = [\n",
        "    row for row in csv_data\n",
        "    if row['verified'] == 'Yes' and int(row['satisfaction']) > 5\n",
        "]\n",
        "\n",
        "thinking_prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Data:\n",
        "{json.dumps(filtered_data_json, indent=2)}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "[rest of your prompt...]\n",
        "</thinking>\"\"\""
      ],
      "metadata": {
        "id": "y0pNlfZdXz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent API calls using tenacity for retries\n",
        "!pip install tenacity\n",
        "\n",
        "import json\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key  # or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude with retries for OverloadedError.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON when requested.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \""
      ],
      "metadata": {
        "id": "rhNt1DnCi0Bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}