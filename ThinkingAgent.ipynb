{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8UU2UTHLySQDkaSBfpJ/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/ThinkingAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "almxb-Dl3bpI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "#from anthropic import Anthropic\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional"
      ],
      "metadata": {
        "id": "Xa9wFmP_4DAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#api_key_openAI = userdata.get('OpenAI')\n",
        "api_key_anthropic = userdata.get('Antropic')\n",
        "#api_key_gemini = userdata.get('google')"
      ],
      "metadata": {
        "id": "yAiFCOFa4dV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = 'frog_ferry_meta.csv'"
      ],
      "metadata": {
        "id": "b5EW9t9nnRk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset to be used:\n",
        "df = pd.read_csv(csv_file)\n",
        "#Text cleanup\n",
        "def text_input(file = 'Mejuri_texts.csv'):\n",
        "  df = pd.read_csv(file)\n",
        "  df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "  texts = [item.replace(\"\\t\", \" \") for item in df_clean['Text']]\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "id": "dkaDtclI4j_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting a corpus of texts\n",
        "texts_cleaned = text_input(csv_file)\n",
        "corpus = ' '.join(texts_cleaned)\n",
        "test1 = ' '.join(corpus.split()[:20000])"
      ],
      "metadata": {
        "id": "9mD4X9ST4wwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the dataframe into the list of dicts\n",
        "df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "records = df_clean.to_dict(orient='records')"
      ],
      "metadata": {
        "id": "RCMpdaMOUsyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4HedLU2bVpt",
        "outputId": "f25a774e-2913-40a1-e1a7-e6555a3a9db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Text': 'We have GREATLY appreciated the addition of speed bumps and cross walks in our area by Roosevelt. More traffic calming features and accessible curbs would always be appreciated. A swing set at George park or some other fun addition to the play area there (basketball court, garden, or fenced area for off leash dogs) would be amazing! The FROG FERRY would be SO GREAT for our community, having the option to take a ferry downtown would be so fun for tourists and a great way for locals to spend the day and obviously commuters would benefit so much. I think the addition of a ferry would be ICONIC.',\n",
              " 'connection': 4,\n",
              " 'recommend': 5,\n",
              " 'satisfaction': 6,\n",
              " 'verified': 'Yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thinking Agent"
      ],
      "metadata": {
        "id": "gpHutfKBVpR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key #or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        print(f'task as defined in the analyze function: {task}')\n",
        "        print(f'context as defined in the analyze function: {context}')\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- use_metadata: Set this field to 'True' if metadata analysis is required and 'False' otherwise\n",
        "- metadata_tool: Suggest a list of tools that can be used for metadata analysis if the use_ metadata field is set to 'True'\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \"```json\" in content:\n",
        "                json_str = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in content:\n",
        "                json_str = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            result = json.loads(json_str)\n",
        "\n",
        "            print(f\"Parsed JSON - analyze function: {result}\")\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            # Fallback if JSON parsing fails\n",
        "            return {\n",
        "                \"reasoning\": content,\n",
        "                \"conclusion\": \"Failed to parse structured output\",\n",
        "                \"confidence\": 0.5,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "'''\n",
        "class MetadataAnalysisTool:\n",
        "    \"\"\"Stub for the metadata analysis tool.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialization for metadata tool would go here\n",
        "        pass\n",
        "\n",
        "    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Analyze reviews based on metadata parameters.\n",
        "\n",
        "        Args:\n",
        "            params: Parameters for filtering and analyzing metadata\n",
        "\n",
        "        Returns:\n",
        "            Filtered list of reviews\n",
        "        \"\"\"\n",
        "        # This is just a stub implementation\n",
        "        print(f\"Metadata tool called with parameters: {params}\")\n",
        "        # In a real implementation, this would filter the actual reviews\n",
        "        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "fhlJ8nUl5Fyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewAnalysisAgent:\n",
        "    \"\"\"Agent that processes customer queries about review data.\"\"\"\n",
        "\n",
        "    def __init__(self, review_corpus: List[Dict], api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the review analysis agent.\n",
        "\n",
        "        Args:\n",
        "            review_corpus: Collection of customer reviews with metadata\n",
        "            api_key: Anthropic API key (optional if set in environment variables)\n",
        "        \"\"\"\n",
        "        self.review_corpus = review_corpus\n",
        "        #self.metadata_tool = MetadataAnalysisTool()\n",
        "        self.thinking_module = ThinkingModule(api_key=api_key)\n",
        "\n",
        "    def process_query(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Process a customer query and return a response.\n",
        "\n",
        "        Args:\n",
        "            query: Natural language query about the review data\n",
        "\n",
        "        Returns:\n",
        "            Response to the query based on review analysis\n",
        "        \"\"\"\n",
        "        # Step 1: Understand the query through the thinking module\n",
        "        print(f'#####################step 1: Understand the query through the thinking module')\n",
        "\n",
        "\n",
        "        query_analysis = self.thinking_module.analyze(\n",
        "            task=\"Analyze the user query to extract: (1) primary information need, \"\n",
        "                 \"(2) any filtering criteria, (3) type of analysis requested, \"\n",
        "                 \"(4) whether numerical/metadata analysis is likely needed\",\n",
        "            context=f\"User query: {query}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "'''\n",
        "        # Step 2: Decide whether to use metadata tool\n",
        "        print(f'#####################step 2: Decide whether to use metadata tool')\n",
        "\n",
        "\n",
        "        tool_decision = self.thinking_module.analyze(\n",
        "            task=\"Determine if metadata analysis is required or beneficial for this query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        print(f'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}')\n",
        "\n",
        "        # Step 3: Execute appropriate analysis\n",
        "        print(f'#####################calling thinking module form the process_query step 3')\n",
        "\n",
        "        #next line has a bug, needs work\n",
        "        #tools_decision_keys_to_extract = ['additional_fields', 'use_metadata_tool', 'd']\n",
        "        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\n",
        "        additional_fields = tool_decision.get(\"additional_fields\", {})\n",
        "        use_metadata = tool_decision.get(\"use_metadata\", False)\n",
        "        print(f'use_metadata call results: {use_metadata}')\n",
        "        print(f'additional_fields call results: {additional_fields}')\n",
        "        #######################################################################################\n",
        "        print('Execution terminated')\n",
        "        raise RuntimeError(\"Stopping execution intentionally.\")\n",
        "        #######################################################################################\n",
        "        if use_metadata:\n",
        "            # Define parameters for metadata tool\n",
        "            metadata_params = self.thinking_module.analyze(\n",
        "                task=\"Determine optimal parameters for metadata tool based on the query\",\n",
        "                context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\n",
        "                reflection_depth=1\n",
        "            )\n",
        "\n",
        "            # Use metadata tool to get filtered set of reviews\n",
        "            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\n",
        "            print(f'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}')\n",
        "            #test: making sure that the metada tool is properly activated\n",
        "            #test block ends\n",
        "            filtered_reviews = self.metadata_tool.analyze(tool_params)\n",
        "            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\n",
        "        else:\n",
        "            # Just analyze the full text corpus\n",
        "            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\n",
        "\n",
        "        # Step 4: Generate final response\n",
        "\n",
        "        print(f'#####################calling thinking module form the process_query step 4')\n",
        "\n",
        "        response = self.thinking_module.analyze(\n",
        "            task=\"Synthesize findings into a comprehensive response to the user query\",\n",
        "            context=f\"Query: {query}\\n\"\n",
        "                   f\"Analysis results: {text_analysis}\\n\"\n",
        "                   f\"Was metadata used: {'Yes' if use_metadata else 'No'}\\n\"\n",
        "                   f\"Thinking process: {query_analysis.get('reasoning', '')}\\n\"\n",
        "                   f\"Tool decision reasoning: {tool_decision.get('reasoning', '')}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Return the final response text\n",
        "        return response.get(\"conclusion\", \"I couldn't generate a proper response.\")\n",
        "\n",
        "    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze the text content of reviews.\n",
        "\n",
        "        Args:\n",
        "            reviews: List of review objects to analyze\n",
        "            query_analysis: Analysis of the user query to guide text analysis\n",
        "\n",
        "        Returns:\n",
        "            Results of the text analysis\n",
        "        \"\"\"\n",
        "        # In a real implementation, this would use NLP techniques\n",
        "        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\n",
        "\n",
        "        # Stub implementation\n",
        "        review_texts = [review.get(\"Text\", \"\") for review in reviews]\n",
        "\n",
        "        # Use the thinking module to analyze the reviews based on the query\n",
        "\n",
        "        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus')\n",
        "\n",
        "        analysis_result = self.thinking_module.analyze(\n",
        "            task=\"Analyze review texts to answer the user query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        return analysis_result\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "RXkurMUoFNkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "queries (St.John):\n",
        "Where are pedestrian safety improvements needed?\n",
        "What can police be doing to make the neighborhood safer?\n",
        "What can city council prioritize to help St Johns?\n",
        "What new businesses are needed in St Johns and where?\n",
        "What issues would Frog Ferry solve?"
      ],
      "metadata": {
        "id": "4QH6WsxFYhGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(records_stjohn[1000:5400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtxf247Xhjad",
        "outputId": "b34d3e13-184b-4bd0-adf4-1e15209ea55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4400"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "# Set your API key\n",
        "api_key = api_key_anthropic\n",
        "\n",
        "# Sample review corpus (in a real scenario, this would be much larger)\n",
        "sample_reviews = [\n",
        "    {\"id\": 1, \"text\": \"Love this product! Battery life is amazing.\", \"rating\": 5, \"verified\": True},\n",
        "    {\"id\": 2, \"text\": \"Decent product but overpriced for what you get.\", \"rating\": 3, \"verified\": True},\n",
        "    {\"id\": 3, \"text\": \"Terrible quality, broke after one week.\", \"rating\": 1, \"verified\": True},\n",
        "    # In reality, you'd have thousands more reviews here\n",
        "]\n",
        "\n",
        "# Initialize the agent\n",
        "\n",
        "agent = ReviewAnalysisAgent(review_corpus=records, api_key=api_key)\n",
        "\n",
        "# Example queries\n",
        "queries = [\n",
        "    \"What do customers think about the battery life?\"\n",
        "    #\"Are verified purchasers happier with the product than non-verified ones?\",\n",
        "    #\"What are the most common complaints in 1-star reviews?\"\n",
        "]\n",
        "\n",
        "queries_stjohn = [\n",
        "    #\"Where are pedestrian safety improvements needed?\",\n",
        "    #\"What can police be doing to make the neighborhood safer?\",\n",
        "    #\"What can city council prioritize to help St Johns?\",\n",
        "    #\"What new businesses are needed in St Johns and where?\",\n",
        "    #\"What issues would Frog Ferry solve?\",\n",
        "    \"What issues would Frog Ferry solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5 \"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for query in queries_stjohn:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = agent.process_query(query)\n",
        "    print(f\"Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JDBFbblk5i35",
        "outputId": "d618149a-ec3d-4a51-8319-cf5533f96c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What issues would Frog Ferry solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5 \n",
            "#####################step 1: Understand the query through the thinking module\n",
            "Claude's response - analyze function: I'll analyze this query step-by-step:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"reasoning\": \"Let me break down this query systematically:\\n\\nStep 1: Identify the primary information need.\\nThe user is asking 'What issues would Frog Ferry solve?' This indicates they want to understand problems that Frog Ferry (likely a ferry service) addresses or resolves.\\n\\nStep 2: Identify filtering criteria.\\nThe user specifies two clear filters:\\n- Only 'verified' reviews should be considered\\n- Only reviews with 'satisfaction' rating above 5 should be included\\nThese are explicit metadata filters that will need to be applied before analysis.\\n\\nStep 3: Determine the type of analysis requested.\\nThe user wants to extract issues that Frog Ferry solves. This requires content analysis of reviews to identify problem statements or challenges that Frog Ferry addresses. This is primarily a qualitative text analysis task.\\n\\nStep 4: Assess if numerical/metadata analysis is needed.\\nYes, metadata analysis is definitely required because:\\n- We need to filter by the 'verified' status (a metadata field)\\n- We need to filter by 'satisfaction' rating (a numerical metadata field)\\nBoth of these operations require accessing and filtering based on metadata fields before performing the content analysis.\\n\\nReflection 1: The query combines both metadata filtering and qualitative content analysis. The metadata filtering must happen first to create the proper subset of reviews before analyzing content.\\n\\nReflection 2: The primary task is extracting issues/problems from text, which is an information extraction task. The metadata filtering is a prerequisite step, not the main analysis goal.\",\n",
            "  \"conclusion\": \"The user wants to identify issues that Frog Ferry solves based on content from verified reviews with satisfaction ratings above 5. This requires both metadata filtering (for verification status and satisfaction rating) and qualitative text analysis to extract problem statements.\",\n",
            "  \"confidence\": 0.95,\n",
            "  \"use_metadata\": true,\n",
            "  \"additional_fields\": {\n",
            "    \"primary_information_need\": \"Issues solved by Frog Ferry\",\n",
            "    \"filtering_criteria\": [\"verified reviews only\", \"satisfaction rating > 5\"],\n",
            "    \"analysis_type\": \"qualitative content analysis\",\n",
            "    \"metadata_fields_required\": [\"verified status\", \"satisfaction rating\"]\n",
            "  }\n",
            "}\n",
            "```\n",
            "Parsed JSON - analyze function: {'reasoning': \"Let me break down this query systematically:\\n\\nStep 1: Identify the primary information need.\\nThe user is asking 'What issues would Frog Ferry solve?' This indicates they want to understand problems that Frog Ferry (likely a ferry service) addresses or resolves.\\n\\nStep 2: Identify filtering criteria.\\nThe user specifies two clear filters:\\n- Only 'verified' reviews should be considered\\n- Only reviews with 'satisfaction' rating above 5 should be included\\nThese are explicit metadata filters that will need to be applied before analysis.\\n\\nStep 3: Determine the type of analysis requested.\\nThe user wants to extract issues that Frog Ferry solves. This requires content analysis of reviews to identify problem statements or challenges that Frog Ferry addresses. This is primarily a qualitative text analysis task.\\n\\nStep 4: Assess if numerical/metadata analysis is needed.\\nYes, metadata analysis is definitely required because:\\n- We need to filter by the 'verified' status (a metadata field)\\n- We need to filter by 'satisfaction' rating (a numerical metadata field)\\nBoth of these operations require accessing and filtering based on metadata fields before performing the content analysis.\\n\\nReflection 1: The query combines both metadata filtering and qualitative content analysis. The metadata filtering must happen first to create the proper subset of reviews before analyzing content.\\n\\nReflection 2: The primary task is extracting issues/problems from text, which is an information extraction task. The metadata filtering is a prerequisite step, not the main analysis goal.\", 'conclusion': 'The user wants to identify issues that Frog Ferry solves based on content from verified reviews with satisfaction ratings above 5. This requires both metadata filtering (for verification status and satisfaction rating) and qualitative text analysis to extract problem statements.', 'confidence': 0.95, 'use_metadata': True, 'additional_fields': {'primary_information_need': 'Issues solved by Frog Ferry', 'filtering_criteria': ['verified reviews only', 'satisfaction rating > 5'], 'analysis_type': 'qualitative content analysis', 'metadata_fields_required': ['verified status', 'satisfaction rating']}}\n",
            "#####################step 2: Decide whether to use metadata tool\n",
            "Claude's response - analyze function: I'll analyze whether metadata analysis is required for this query:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"reasoning\": \"Let me analyze whether metadata analysis is required for this query:\\n\\nStep 1: Examine the query requirements.\\nThe query asks to identify 'What issues would Frog Ferry solve?' but with specific filtering criteria:\\n- Only 'verified' reviews should be considered\\n- Only reviews with 'satisfaction' rating above 5\\n\\nStep 2: Identify the data types involved.\\nThe filtering criteria explicitly reference metadata fields:\\n- 'verified' status is a boolean/categorical metadata field\\n- 'satisfaction' rating is a numerical metadata field\\nBoth of these are non-textual attributes that require accessing structured metadata.\\n\\nStep 3: Determine the processing sequence.\\nTo properly answer this query:\\n1. First, we must filter the corpus to include only verified reviews\\n2. Then, further filter to include only reviews with satisfaction ratings > 5\\n3. Finally, analyze the content of this filtered subset to identify issues Frog Ferry solves\\n\\nReflection 1: The first two steps in the processing sequence require metadata analysis. Without accessing the metadata fields, we cannot properly filter the corpus to the relevant subset of reviews. The text corpus analysis alone would be insufficient.\\n\\nReflection 2: While the ultimate goal is content analysis (identifying issues solved), the metadata is essential for creating the proper analysis set. This is a clear case where metadata analysis is a prerequisite for the text analysis phase.\",\n",
            "  \"conclusion\": \"Metadata analysis is definitely required for this query because we need to filter reviews based on two specific metadata fields ('verified' status and 'satisfaction' rating) before performing content analysis on the filtered subset.\",\n",
            "  \"confidence\": 0.98,\n",
            "  \"use_metadata\": true,\n",
            "  \"additional_fields\": {\n",
            "    \"required_metadata_fields\": [\"verified\", \"satisfaction\"],\n",
            "    \"metadata_operations\": [\"filtering\"],\n",
            "    \"processing_sequence\": [\"metadata filtering\", \"text content analysis\"]\n",
            "  }\n",
            "}\n",
            "```\n",
            "Parsed JSON - analyze function: {'reasoning': \"Let me analyze whether metadata analysis is required for this query:\\n\\nStep 1: Examine the query requirements.\\nThe query asks to identify 'What issues would Frog Ferry solve?' but with specific filtering criteria:\\n- Only 'verified' reviews should be considered\\n- Only reviews with 'satisfaction' rating above 5\\n\\nStep 2: Identify the data types involved.\\nThe filtering criteria explicitly reference metadata fields:\\n- 'verified' status is a boolean/categorical metadata field\\n- 'satisfaction' rating is a numerical metadata field\\nBoth of these are non-textual attributes that require accessing structured metadata.\\n\\nStep 3: Determine the processing sequence.\\nTo properly answer this query:\\n1. First, we must filter the corpus to include only verified reviews\\n2. Then, further filter to include only reviews with satisfaction ratings > 5\\n3. Finally, analyze the content of this filtered subset to identify issues Frog Ferry solves\\n\\nReflection 1: The first two steps in the processing sequence require metadata analysis. Without accessing the metadata fields, we cannot properly filter the corpus to the relevant subset of reviews. The text corpus analysis alone would be insufficient.\\n\\nReflection 2: While the ultimate goal is content analysis (identifying issues solved), the metadata is essential for creating the proper analysis set. This is a clear case where metadata analysis is a prerequisite for the text analysis phase.\", 'conclusion': \"Metadata analysis is definitely required for this query because we need to filter reviews based on two specific metadata fields ('verified' status and 'satisfaction' rating) before performing content analysis on the filtered subset.\", 'confidence': 0.98, 'use_metadata': True, 'additional_fields': {'required_metadata_fields': ['verified', 'satisfaction'], 'metadata_operations': ['filtering'], 'processing_sequence': ['metadata filtering', 'text content analysis']}}\n",
            "+++++++++++++++++++++++++++++tool_decision call results: {'reasoning': \"Let me analyze whether metadata analysis is required for this query:\\n\\nStep 1: Examine the query requirements.\\nThe query asks to identify 'What issues would Frog Ferry solve?' but with specific filtering criteria:\\n- Only 'verified' reviews should be considered\\n- Only reviews with 'satisfaction' rating above 5\\n\\nStep 2: Identify the data types involved.\\nThe filtering criteria explicitly reference metadata fields:\\n- 'verified' status is a boolean/categorical metadata field\\n- 'satisfaction' rating is a numerical metadata field\\nBoth of these are non-textual attributes that require accessing structured metadata.\\n\\nStep 3: Determine the processing sequence.\\nTo properly answer this query:\\n1. First, we must filter the corpus to include only verified reviews\\n2. Then, further filter to include only reviews with satisfaction ratings > 5\\n3. Finally, analyze the content of this filtered subset to identify issues Frog Ferry solves\\n\\nReflection 1: The first two steps in the processing sequence require metadata analysis. Without accessing the metadata fields, we cannot properly filter the corpus to the relevant subset of reviews. The text corpus analysis alone would be insufficient.\\n\\nReflection 2: While the ultimate goal is content analysis (identifying issues solved), the metadata is essential for creating the proper analysis set. This is a clear case where metadata analysis is a prerequisite for the text analysis phase.\", 'conclusion': \"Metadata analysis is definitely required for this query because we need to filter reviews based on two specific metadata fields ('verified' status and 'satisfaction' rating) before performing content analysis on the filtered subset.\", 'confidence': 0.98, 'use_metadata': True, 'additional_fields': {'required_metadata_fields': ['verified', 'satisfaction'], 'metadata_operations': ['filtering'], 'processing_sequence': ['metadata filtering', 'text content analysis']}}\n",
            "#####################calling thinking module form the process_query step 3\n",
            "use_metadata call results: True\n",
            "additional_fields call results: {'required_metadata_fields': ['verified', 'satisfaction'], 'metadata_operations': ['filtering'], 'processing_sequence': ['metadata filtering', 'text content analysis']}\n",
            "Execution terminated\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Stopping execution intentionally.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b242d9e02540>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries_stjohn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nQuery: {query}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-beccfd6b8a40>\u001b[0m in \u001b[0;36mprocess_query\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#######################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Execution terminated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stopping execution intentionally.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;31m#######################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Stopping execution intentionally."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTmCs87VjAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Future features**"
      ],
      "metadata": {
        "id": "ltWTb_wizi2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#including csv data into the prompt for the thinking module\n",
        "filtered_data_json = [\n",
        "    row for row in csv_data\n",
        "    if row['verified'] == 'Yes' and int(row['satisfaction']) > 5\n",
        "]\n",
        "\n",
        "thinking_prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Data:\n",
        "{json.dumps(filtered_data_json, indent=2)}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "[rest of your prompt...]\n",
        "</thinking>\"\"\""
      ],
      "metadata": {
        "id": "y0pNlfZdXz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent API calls using tenacity for retries\n",
        "!pip install tenacity\n",
        "\n",
        "import json\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key  # or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude with retries for OverloadedError.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON when requested.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \""
      ],
      "metadata": {
        "id": "rhNt1DnCi0Bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}