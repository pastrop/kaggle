{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNGIsdg8P72PQ3Q4NUnM0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/ThinkingAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "almxb-Dl3bpI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from anthropic import Anthropic\n",
        "from typing import Dict, List, Any, Optional"
      ],
      "metadata": {
        "id": "Xa9wFmP_4DAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#api_key_openAI = userdata.get('OpenAI')\n",
        "api_key_anthropic = userdata.get('Antropic')\n",
        "#api_key_gemini = userdata.get('google')"
      ],
      "metadata": {
        "id": "yAiFCOFa4dV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset to be used:\n",
        "df = pd.read_csv('Mejuri_texts.csv')\n",
        "#Text cleanup\n",
        "def text_input(file = 'alpha_test.csv'):\n",
        "  df = pd.read_csv(file)\n",
        "  df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "  texts = [item.replace(\"\\t\", \" \") for item in df_clean['Text']]\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "id": "dkaDtclI4j_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_cleaned = text_input('Mejuri_texts.csv')\n",
        "corpus = ' '.join(texts_cleaned)\n",
        "test1 = ' '.join(corpus.split()[:20000])"
      ],
      "metadata": {
        "id": "9mD4X9ST4wwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON when requested.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \"```json\" in content:\n",
        "                json_str = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in content:\n",
        "                json_str = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            result = json.loads(json_str)\n",
        "\n",
        "            print(f\"Parsed JSON - analyze function: {result}\")\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            # Fallback if JSON parsing fails\n",
        "            return {\n",
        "                \"reasoning\": content,\n",
        "                \"conclusion\": \"Failed to parse structured output\",\n",
        "                \"confidence\": 0.5,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "\n",
        "class MetadataAnalysisTool:\n",
        "    \"\"\"Stub for the metadata analysis tool.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialization for metadata tool would go here\n",
        "        pass\n",
        "\n",
        "    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Analyze reviews based on metadata parameters.\n",
        "\n",
        "        Args:\n",
        "            params: Parameters for filtering and analyzing metadata\n",
        "\n",
        "        Returns:\n",
        "            Filtered list of reviews\n",
        "        \"\"\"\n",
        "        # This is just a stub implementation\n",
        "        print(f\"Metadata tool called with parameters: {params}\")\n",
        "        # In a real implementation, this would filter the actual reviews\n",
        "        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\n"
      ],
      "metadata": {
        "id": "fhlJ8nUl5Fyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewAnalysisAgent:\n",
        "    \"\"\"Agent that processes customer queries about review data.\"\"\"\n",
        "\n",
        "    def __init__(self, review_corpus: List[Dict], api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the review analysis agent.\n",
        "\n",
        "        Args:\n",
        "            review_corpus: Collection of customer reviews with metadata\n",
        "            api_key: Anthropic API key (optional if set in environment variables)\n",
        "        \"\"\"\n",
        "        self.review_corpus = review_corpus\n",
        "        self.metadata_tool = MetadataAnalysisTool()\n",
        "        self.thinking_module = ThinkingModule(api_key=api_key)\n",
        "\n",
        "    def process_query(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Process a customer query and return a response.\n",
        "\n",
        "        Args:\n",
        "            query: Natural language query about the review data\n",
        "\n",
        "        Returns:\n",
        "            Response to the query based on review analysis\n",
        "        \"\"\"\n",
        "        # Step 1: Understand the query through the thinking module\n",
        "        query_analysis = self.thinking_module.analyze(\n",
        "            task=\"Analyze the user query to extract: (1) primary information need, \"\n",
        "                 \"(2) any filtering criteria, (3) type of analysis requested, \"\n",
        "                 \"(4) whether numerical/metadata analysis is likely needed\",\n",
        "            context=f\"User query: {query}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Step 2: Decide whether to use metadata tool\n",
        "        tool_decision = self.thinking_module.analyze(\n",
        "            task=\"Determine if metadata analysis is required or beneficial for this query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Step 3: Execute appropriate analysis\n",
        "        use_metadata = tool_decision.get(\"conclusion\", \"\").lower().startswith(\"yes\") or \\\n",
        "                      tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\n",
        "\n",
        "        if use_metadata:\n",
        "            # Define parameters for metadata tool\n",
        "            metadata_params = self.thinking_module.analyze(\n",
        "                task=\"Determine optimal parameters for metadata tool based on the query\",\n",
        "                context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\n",
        "                reflection_depth=1\n",
        "            )\n",
        "\n",
        "            # Use metadata tool to get filtered set of reviews\n",
        "            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\n",
        "            filtered_reviews = self.metadata_tool.analyze(tool_params)\n",
        "            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\n",
        "        else:\n",
        "            # Just analyze the full text corpus\n",
        "            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\n",
        "\n",
        "        # Step 4: Generate final response\n",
        "        response = self.thinking_module.analyze(\n",
        "            task=\"Synthesize findings into a comprehensive response to the user query\",\n",
        "            context=f\"Query: {query}\\n\"\n",
        "                   f\"Analysis results: {text_analysis}\\n\"\n",
        "                   f\"Was metadata used: {'Yes' if use_metadata else 'No'}\\n\"\n",
        "                   f\"Thinking process: {query_analysis.get('reasoning', '')}\\n\"\n",
        "                   f\"Tool decision reasoning: {tool_decision.get('reasoning', '')}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Return the final response text\n",
        "        return response.get(\"conclusion\", \"I couldn't generate a proper response.\")\n",
        "\n",
        "    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze the text content of reviews.\n",
        "\n",
        "        Args:\n",
        "            reviews: List of review objects to analyze\n",
        "            query_analysis: Analysis of the user query to guide text analysis\n",
        "\n",
        "        Returns:\n",
        "            Results of the text analysis\n",
        "        \"\"\"\n",
        "        # In a real implementation, this would use NLP techniques\n",
        "        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\n",
        "\n",
        "        # Stub implementation\n",
        "        review_texts = [review.get(\"text\", \"\") for review in reviews]\n",
        "\n",
        "        # Use the thinking module to analyze the reviews based on the query\n",
        "        analysis_result = self.thinking_module.analyze(\n",
        "            task=\"Analyze review texts to answer the user query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Reviews to analyze: {review_texts[:5]} (showing first 5 only)\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        return analysis_result"
      ],
      "metadata": {
        "id": "RXkurMUoFNkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "# Set your API key\n",
        "api_key = api_key_anthropic\n",
        "\n",
        "# Sample review corpus (in a real scenario, this would be much larger)\n",
        "sample_reviews = [\n",
        "    {\"id\": 1, \"text\": \"Love this product! Battery life is amazing.\", \"rating\": 5, \"verified\": True},\n",
        "    {\"id\": 2, \"text\": \"Decent product but overpriced for what you get.\", \"rating\": 3, \"verified\": True},\n",
        "    {\"id\": 3, \"text\": \"Terrible quality, broke after one week.\", \"rating\": 1, \"verified\": True},\n",
        "    # In reality, you'd have thousands more reviews here\n",
        "]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = ReviewAnalysisAgent(review_corpus=sample_reviews, api_key=api_key)\n",
        "\n",
        "# Example queries\n",
        "queries = [\n",
        "    \"What do customers think about the battery life?\",\n",
        "    #\"Are verified purchasers happier with the product than non-verified ones?\",\n",
        "    \"What are the most common complaints in 1-star reviews?\"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for query in queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = agent.process_query(query)\n",
        "    print(f\"Response: {response}\")"
      ],
      "metadata": {
        "id": "JDBFbblk5i35"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}