{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ltWTb_wizi2G"
      ],
      "authorship_tag": "ABX9TyOxKgQTaeLyI2cEWLbOcgGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/ThinkingAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "almxb-Dl3bpI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "#from anthropic import Anthropic\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional"
      ],
      "metadata": {
        "id": "Xa9wFmP_4DAO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#api_key_openAI = userdata.get('OpenAI')\n",
        "api_key_anthropic = userdata.get('Antropic')\n",
        "#api_key_gemini = userdata.get('google')"
      ],
      "metadata": {
        "id": "yAiFCOFa4dV3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = 'frog_ferry_meta.csv'"
      ],
      "metadata": {
        "id": "b5EW9t9nnRk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset to be used:\n",
        "df = pd.read_csv(csv_file)\n",
        "#Text cleanup\n",
        "def text_input(file = 'Mejuri_texts.csv'):\n",
        "  df = pd.read_csv(file)\n",
        "  df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "  texts = [item.replace(\"\\t\", \" \") for item in df_clean['Text']]\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "id": "dkaDtclI4j_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting a corpus of texts\n",
        "texts_cleaned = text_input(csv_file)\n",
        "corpus = ' '.join(texts_cleaned)\n",
        "test1 = ' '.join(corpus.split()[:20000])"
      ],
      "metadata": {
        "id": "9mD4X9ST4wwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the dataframe into the list of dicts\n",
        "df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "records = df_clean.to_dict(orient='records')"
      ],
      "metadata": {
        "id": "RCMpdaMOUsyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4HedLU2bVpt",
        "outputId": "f25a774e-2913-40a1-e1a7-e6555a3a9db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Text': 'We have GREATLY appreciated the addition of speed bumps and cross walks in our area by Roosevelt. More traffic calming features and accessible curbs would always be appreciated. A swing set at George park or some other fun addition to the play area there (basketball court, garden, or fenced area for off leash dogs) would be amazing! The FROG FERRY would be SO GREAT for our community, having the option to take a ferry downtown would be so fun for tourists and a great way for locals to spend the day and obviously commuters would benefit so much. I think the addition of a ferry would be ICONIC.',\n",
              " 'connection': 4,\n",
              " 'recommend': 5,\n",
              " 'satisfaction': 6,\n",
              " 'verified': 'Yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thinking Agent"
      ],
      "metadata": {
        "id": "gpHutfKBVpR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key #or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        print(f'task as defined in the analyze function: {task}')\n",
        "        print(f'context as defined in the analyze function: {context}')\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- use_metadata: Set this field to 'True' if metadata analysis is required and 'False' otherwise\n",
        "- metadata_tool: Suggest a list of tools that can be used for metadata analysis if the use_ metadata field is set to 'True'\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \"```json\" in content:\n",
        "                json_str = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in content:\n",
        "                json_str = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            result = json.loads(json_str)\n",
        "\n",
        "            print(f\"Parsed JSON - analyze function: {result}\")\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            # Fallback if JSON parsing fails\n",
        "            return {\n",
        "                \"reasoning\": content,\n",
        "                \"conclusion\": \"Failed to parse structured output\",\n",
        "                \"confidence\": 0.5,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "'''\n",
        "class MetadataAnalysisTool:\n",
        "    \"\"\"Stub for the metadata analysis tool.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialization for metadata tool would go here\n",
        "        pass\n",
        "\n",
        "    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Analyze reviews based on metadata parameters.\n",
        "\n",
        "        Args:\n",
        "            params: Parameters for filtering and analyzing metadata\n",
        "\n",
        "        Returns:\n",
        "            Filtered list of reviews\n",
        "        \"\"\"\n",
        "        # This is just a stub implementation\n",
        "        print(f\"Metadata tool called with parameters: {params}\")\n",
        "        # In a real implementation, this would filter the actual reviews\n",
        "        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "fhlJ8nUl5Fyt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5dd58a03-4cc6-4b88-cfd6-025930162a97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass MetadataAnalysisTool:\\n    \"\"\"Stub for the metadata analysis tool.\"\"\"\\n\\n    def __init__(self):\\n        # Initialization for metadata tool would go here\\n        pass\\n\\n    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        \"\"\"\\n        Analyze reviews based on metadata parameters.\\n\\n        Args:\\n            params: Parameters for filtering and analyzing metadata\\n\\n        Returns:\\n            Filtered list of reviews\\n        \"\"\"\\n        # This is just a stub implementation\\n        print(f\"Metadata tool called with parameters: {params}\")\\n        # In a real implementation, this would filter the actual reviews\\n        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewAnalysisAgent:\n",
        "    \"\"\"Agent that processes customer queries about review data.\"\"\"\n",
        "\n",
        "    def __init__(self, review_corpus: List[Dict], api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the review analysis agent.\n",
        "\n",
        "        Args:\n",
        "            review_corpus: Collection of customer reviews with metadata\n",
        "            api_key: Anthropic API key (optional if set in environment variables)\n",
        "        \"\"\"\n",
        "        self.review_corpus = review_corpus\n",
        "        #self.metadata_tool = MetadataAnalysisTool()\n",
        "        self.thinking_module = ThinkingModule(api_key=api_key)\n",
        "\n",
        "    def process_query(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Process a customer query and return a response.\n",
        "\n",
        "        Args:\n",
        "            query: Natural language query about the review data\n",
        "\n",
        "        Returns:\n",
        "            Response to the query based on review analysis\n",
        "        \"\"\"\n",
        "        # Step 1: Understand the query through the thinking module\n",
        "        print(f'#####################step 1: Understand the query through the thinking module')\n",
        "\n",
        "\n",
        "        query_analysis = self.thinking_module.analyze(\n",
        "            task=\"Analyze the user query to extract: (1) primary information need, \"\n",
        "                 \"(2)type of analysis requested, \"\n",
        "                 \"(3) whether numerical/metadata analysis is likely needed\",\n",
        "            context=f\"User query: {query}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "        return query_analysis\n",
        "\n",
        "'''\n",
        "        # Step 2: Decide whether to use metadata tool\n",
        "        print(f'#####################step 2: Decide whether to use metadata tool')\n",
        "\n",
        "\n",
        "        tool_decision = self.thinking_module.analyze(\n",
        "            task=\"Determine if metadata analysis is required or beneficial for this query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        print(f'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}')\n",
        "\n",
        "        # Step 3: Execute appropriate analysis\n",
        "        print(f'#####################calling thinking module form the process_query step 3')\n",
        "\n",
        "        #next line has a bug, needs work\n",
        "        #tools_decision_keys_to_extract = ['additional_fields', 'use_metadata_tool', 'd']\n",
        "        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\n",
        "        additional_fields = tool_decision.get(\"additional_fields\", {})\n",
        "        use_metadata = tool_decision.get(\"use_metadata\", False)\n",
        "        print(f'use_metadata call results: {use_metadata}')\n",
        "        print(f'additional_fields call results: {additional_fields}')\n",
        "        #######################################################################################\n",
        "        print('Execution terminated')\n",
        "        raise RuntimeError(\"Stopping execution intentionally.\")\n",
        "        #######################################################################################\n",
        "        if use_metadata:\n",
        "            # Define parameters for metadata tool\n",
        "            metadata_params = self.thinking_module.analyze(\n",
        "                task=\"Determine optimal parameters for metadata tool based on the query\",\n",
        "                context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\n",
        "                reflection_depth=1\n",
        "            )\n",
        "\n",
        "            # Use metadata tool to get filtered set of reviews\n",
        "            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\n",
        "            print(f'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}')\n",
        "            #test: making sure that the metada tool is properly activated\n",
        "            #test block ends\n",
        "            filtered_reviews = self.metadata_tool.analyze(tool_params)\n",
        "            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\n",
        "        else:\n",
        "            # Just analyze the full text corpus\n",
        "            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\n",
        "\n",
        "        # Step 4: Generate final response\n",
        "\n",
        "        print(f'#####################calling thinking module form the process_query step 4')\n",
        "\n",
        "        response = self.thinking_module.analyze(\n",
        "            task=\"Synthesize findings into a comprehensive response to the user query\",\n",
        "            context=f\"Query: {query}\\n\"\n",
        "                   f\"Analysis results: {text_analysis}\\n\"\n",
        "                   f\"Was metadata used: {'Yes' if use_metadata else 'No'}\\n\"\n",
        "                   f\"Thinking process: {query_analysis.get('reasoning', '')}\\n\"\n",
        "                   f\"Tool decision reasoning: {tool_decision.get('reasoning', '')}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Return the final response text\n",
        "        return response.get(\"conclusion\", \"I couldn't generate a proper response.\")\n",
        "\n",
        "    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze the text content of reviews.\n",
        "\n",
        "        Args:\n",
        "            reviews: List of review objects to analyze\n",
        "            query_analysis: Analysis of the user query to guide text analysis\n",
        "\n",
        "        Returns:\n",
        "            Results of the text analysis\n",
        "        \"\"\"\n",
        "        # In a real implementation, this would use NLP techniques\n",
        "        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\n",
        "\n",
        "        # Stub implementation\n",
        "        review_texts = [review.get(\"Text\", \"\") for review in reviews]\n",
        "\n",
        "        # Use the thinking module to analyze the reviews based on the query\n",
        "\n",
        "        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus')\n",
        "\n",
        "        analysis_result = self.thinking_module.analyze(\n",
        "            task=\"Analyze review texts to answer the user query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        return analysis_result\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "RXkurMUoFNkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "67f5bfd9-0b87-4973-e2cb-ef6defbf521b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n        # Step 2: Decide whether to use metadata tool\\n        print(f\\'#####################step 2: Decide whether to use metadata tool\\')\\n\\n\\n        tool_decision = self.thinking_module.analyze(\\n            task=\"Determine if metadata analysis is required or beneficial for this query\",\\n            context=f\"Query analysis: {query_analysis}\\n\"\\n                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\\n            reflection_depth=2\\n        )\\n\\n        print(f\\'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}\\')\\n\\n        # Step 3: Execute appropriate analysis\\n        print(f\\'#####################calling thinking module form the process_query step 3\\')\\n\\n        #next line has a bug, needs work\\n        #tools_decision_keys_to_extract = [\\'additional_fields\\', \\'use_metadata_tool\\', \\'d\\']\\n        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\\n        additional_fields = tool_decision.get(\"additional_fields\", {})\\n        use_metadata = tool_decision.get(\"use_metadata\", False)\\n        print(f\\'use_metadata call results: {use_metadata}\\')\\n        print(f\\'additional_fields call results: {additional_fields}\\')\\n        #######################################################################################\\n        print(\\'Execution terminated\\')\\n        raise RuntimeError(\"Stopping execution intentionally.\")\\n        #######################################################################################\\n        if use_metadata:\\n            # Define parameters for metadata tool\\n            metadata_params = self.thinking_module.analyze(\\n                task=\"Determine optimal parameters for metadata tool based on the query\",\\n                context=f\"Query analysis: {query_analysis}\\n\"\\n                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\\n                reflection_depth=1\\n            )\\n\\n            # Use metadata tool to get filtered set of reviews\\n            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\\n            print(f\\'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}\\')\\n            #test: making sure that the metada tool is properly activated\\n            #test block ends\\n            filtered_reviews = self.metadata_tool.analyze(tool_params)\\n            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\\n        else:\\n            # Just analyze the full text corpus\\n            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\\n\\n        # Step 4: Generate final response\\n\\n        print(f\\'#####################calling thinking module form the process_query step 4\\')\\n\\n        response = self.thinking_module.analyze(\\n            task=\"Synthesize findings into a comprehensive response to the user query\",\\n            context=f\"Query: {query}\\n\"\\n                   f\"Analysis results: {text_analysis}\\n\"\\n                   f\"Was metadata used: {\\'Yes\\' if use_metadata else \\'No\\'}\\n\"\\n                   f\"Thinking process: {query_analysis.get(\\'reasoning\\', \\'\\')}\\n\"\\n                   f\"Tool decision reasoning: {tool_decision.get(\\'reasoning\\', \\'\\')}\",\\n            reflection_depth=2\\n        )\\n\\n        # Return the final response text\\n        return response.get(\"conclusion\", \"I couldn\\'t generate a proper response.\")\\n\\n    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\\n        \"\"\"\\n        Analyze the text content of reviews.\\n\\n        Args:\\n            reviews: List of review objects to analyze\\n            query_analysis: Analysis of the user query to guide text analysis\\n\\n        Returns:\\n            Results of the text analysis\\n        \"\"\"\\n        # In a real implementation, this would use NLP techniques\\n        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\\n\\n        # Stub implementation\\n        review_texts = [review.get(\"Text\", \"\") for review in reviews]\\n\\n        # Use the thinking module to analyze the reviews based on the query\\n\\n        print(f\\'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus\\')\\n\\n        analysis_result = self.thinking_module.analyze(\\n            task=\"Analyze review texts to answer the user query\",\\n            context=f\"Query analysis: {query_analysis}\\n\"\\n                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\\n            reflection_depth=2\\n        )\\n\\n        return analysis_result\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "queries (St.John):\n",
        "Where are pedestrian safety improvements needed?\n",
        "What can police be doing to make the neighborhood safer?\n",
        "What can city council prioritize to help St Johns?\n",
        "What new businesses are needed in St Johns and where?\n",
        "What issues would Frog Ferry solve?"
      ],
      "metadata": {
        "id": "4QH6WsxFYhGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(records_stjohn[1000:5400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtxf247Xhjad",
        "outputId": "b34d3e13-184b-4bd0-adf4-1e15209ea55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4400"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "# Set your API key\n",
        "api_key = api_key_anthropic\n",
        "records = {}\n",
        "# Sample review corpus (in a real scenario, this would be much larger)\n",
        "sample_reviews = [\n",
        "    {\"id\": 1, \"text\": \"Love this product! Battery life is amazing.\", \"rating\": 5, \"verified\": True},\n",
        "    {\"id\": 2, \"text\": \"Decent product but overpriced for what you get.\", \"rating\": 3, \"verified\": True},\n",
        "    {\"id\": 3, \"text\": \"Terrible quality, broke after one week.\", \"rating\": 1, \"verified\": True},\n",
        "    # In reality, you'd have thousands more reviews here\n",
        "]\n",
        "\n",
        "# Initialize the agent\n",
        "\n",
        "agent = ReviewAnalysisAgent(review_corpus=records, api_key=api_key)\n",
        "\n",
        "# Example queries\n",
        "queries = [\n",
        "    \"What do customers think about the battery life? assume you have a dataset of the customer reviews about a produc\"\n",
        "    #\"Are verified purchasers happier with the product than non-verified ones?\",\n",
        "    #\"What are the most common complaints in 1-star reviews?\"\n",
        "]\n",
        "\n",
        "query_battery = '''\n",
        "What do customers think about the battery life? assume you have a dataset of the customer reviews about a product\n",
        "that includes a battery, reviews discuss the product and may include information and opinions about the battery.\n",
        "every review comes with the metadata including review rating, overall sentiment, geographic region the review comes from\n",
        "'''\n",
        "\n",
        "query_stjohn = '''\n",
        "What issues would 'Frog Ferry' ferry service solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5\n",
        "assume you have a dataset of the customer reviews the Ferry service\"\n",
        "'''\n",
        "response = agent.process_query(query_battery)\n",
        "print(f\"Response: {response}\")\n",
        "\n",
        "'''\n",
        "queries_stjohn = [\n",
        "    #\"Where are pedestrian safety improvements needed?\",\n",
        "    #\"What can police be doing to make the neighborhood safer?\",\n",
        "    #\"What can city council prioritize to help St Johns?\",\n",
        "    #\"What new businesses are needed in St Johns and where?\",\n",
        "    #\"What issues would Frog Ferry solve?\",\n",
        "    \"What issues would 'Frog Ferry' ferry service solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5 \"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for query in queries_stjohn:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = agent.process_query(query)\n",
        "    print(f\"Response: {response}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "JDBFbblk5i35",
        "outputId": "2d812032-10c6-43ff-9b20-a1839f5f399b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####################step 1: Understand the query through the thinking module\n",
            "task as defined in the analyze function: Analyze the user query to extract: (1) primary information need, (2)type of analysis requested, (3) whether numerical/metadata analysis is likely needed\n",
            "context as defined in the analyze function: User query: \n",
            "What do customers think about the battery life? assume you have a dataset of the customer reviews about a product\n",
            "that includes a battery, reviews discuss the product and may include information and opinions about the battery.\n",
            "every review comes with the metadata uncluding review rating, overal sentiment, geographic region the review comes from\n",
            "\n",
            "Claude's response - analyze function: ```json\n",
            "{\n",
            "  \"reasoning\": {\n",
            "    \"step1\": {\n",
            "      \"analysis\": \"Let me break down the user query to understand what is being asked.\",\n",
            "      \"details\": \"The user wants to know what customers think about battery life based on a dataset of customer reviews. The dataset contains reviews about a product with a battery, and each review includes metadata such as rating, sentiment, and geographic region.\"\n",
            "    },\n",
            "    \"step2\": {\n",
            "      \"analysis\": \"Identifying the primary information need and type of analysis requested.\",\n",
            "      \"details\": \"The primary need is to extract and summarize customer opinions specifically about battery life from product reviews. This requires sentiment analysis focused on a specific product feature (battery life). The user wants to understand customer perceptions and satisfaction regarding battery life.\"\n",
            "    },\n",
            "    \"step3\": {\n",
            "      \"analysis\": \"Determining if metadata analysis is needed.\",\n",
            "      \"details\": \"The query mentions that reviews come with metadata including review rating, overall sentiment, and geographic region. While not explicitly stated, analyzing this metadata could provide valuable insights such as: (1) correlation between battery life satisfaction and overall ratings, (2) regional differences in battery life perception, and (3) sentiment patterns specific to battery life comments. This metadata would enhance the analysis beyond simple text extraction.\"\n",
            "    }\n",
            "  },\n",
            "  \"conclusion\": \"The user needs an analysis of customer opinions about battery life from product reviews, requiring both text analysis to extract battery-related comments and sentiment analysis to understand opinions. Metadata analysis would significantly enhance insights by enabling correlations between battery life satisfaction and ratings, regional differences, and sentiment patterns.\",\n",
            "  \"confidence\": 0.9,\n",
            "  \"use_metadata\": true,\n",
            "  \"metadata_tool\": [\n",
            "    \"Sentiment analysis tools\",\n",
            "    \"Statistical correlation analysis\",\n",
            "    \"Geographic data visualization\",\n",
            "    \"Rating distribution analysis\",\n",
            "    \"Text mining with metadata filtering\"\n",
            "  ],\n",
            "  \"additional_fields\": {\n",
            "    \"primary_information_need\": \"Customer opinions about battery life\",\n",
            "    \"analysis_type\": \"Sentiment analysis focused on a specific product feature (battery life)\",\n",
            "    \"key_metadata_elements\": [\"review rating\", \"overall sentiment\", \"geographic region\"]\n",
            "  }\n",
            "}\n",
            "```\n",
            "Parsed JSON - analyze function: {'reasoning': {'step1': {'analysis': 'Let me break down the user query to understand what is being asked.', 'details': 'The user wants to know what customers think about battery life based on a dataset of customer reviews. The dataset contains reviews about a product with a battery, and each review includes metadata such as rating, sentiment, and geographic region.'}, 'step2': {'analysis': 'Identifying the primary information need and type of analysis requested.', 'details': 'The primary need is to extract and summarize customer opinions specifically about battery life from product reviews. This requires sentiment analysis focused on a specific product feature (battery life). The user wants to understand customer perceptions and satisfaction regarding battery life.'}, 'step3': {'analysis': 'Determining if metadata analysis is needed.', 'details': 'The query mentions that reviews come with metadata including review rating, overall sentiment, and geographic region. While not explicitly stated, analyzing this metadata could provide valuable insights such as: (1) correlation between battery life satisfaction and overall ratings, (2) regional differences in battery life perception, and (3) sentiment patterns specific to battery life comments. This metadata would enhance the analysis beyond simple text extraction.'}}, 'conclusion': 'The user needs an analysis of customer opinions about battery life from product reviews, requiring both text analysis to extract battery-related comments and sentiment analysis to understand opinions. Metadata analysis would significantly enhance insights by enabling correlations between battery life satisfaction and ratings, regional differences, and sentiment patterns.', 'confidence': 0.9, 'use_metadata': True, 'metadata_tool': ['Sentiment analysis tools', 'Statistical correlation analysis', 'Geographic data visualization', 'Rating distribution analysis', 'Text mining with metadata filtering'], 'additional_fields': {'primary_information_need': 'Customer opinions about battery life', 'analysis_type': 'Sentiment analysis focused on a specific product feature (battery life)', 'key_metadata_elements': ['review rating', 'overall sentiment', 'geographic region']}}\n",
            "Response: {'reasoning': {'step1': {'analysis': 'Let me break down the user query to understand what is being asked.', 'details': 'The user wants to know what customers think about battery life based on a dataset of customer reviews. The dataset contains reviews about a product with a battery, and each review includes metadata such as rating, sentiment, and geographic region.'}, 'step2': {'analysis': 'Identifying the primary information need and type of analysis requested.', 'details': 'The primary need is to extract and summarize customer opinions specifically about battery life from product reviews. This requires sentiment analysis focused on a specific product feature (battery life). The user wants to understand customer perceptions and satisfaction regarding battery life.'}, 'step3': {'analysis': 'Determining if metadata analysis is needed.', 'details': 'The query mentions that reviews come with metadata including review rating, overall sentiment, and geographic region. While not explicitly stated, analyzing this metadata could provide valuable insights such as: (1) correlation between battery life satisfaction and overall ratings, (2) regional differences in battery life perception, and (3) sentiment patterns specific to battery life comments. This metadata would enhance the analysis beyond simple text extraction.'}}, 'conclusion': 'The user needs an analysis of customer opinions about battery life from product reviews, requiring both text analysis to extract battery-related comments and sentiment analysis to understand opinions. Metadata analysis would significantly enhance insights by enabling correlations between battery life satisfaction and ratings, regional differences, and sentiment patterns.', 'confidence': 0.9, 'use_metadata': True, 'metadata_tool': ['Sentiment analysis tools', 'Statistical correlation analysis', 'Geographic data visualization', 'Rating distribution analysis', 'Text mining with metadata filtering'], 'additional_fields': {'primary_information_need': 'Customer opinions about battery life', 'analysis_type': 'Sentiment analysis focused on a specific product feature (battery life)', 'key_metadata_elements': ['review rating', 'overall sentiment', 'geographic region']}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nqueries_stjohn = [\\n    #\"Where are pedestrian safety improvements needed?\",\\n    #\"What can police be doing to make the neighborhood safer?\",\\n    #\"What can city council prioritize to help St Johns?\",\\n    #\"What new businesses are needed in St Johns and where?\",\\n    #\"What issues would Frog Ferry solve?\",\\n    \"What issues would \\'Frog Ferry\\' ferry service solve? pls only consider \\'verified\\' reviews with \\'satisfaction\\' rating above 5 \"\\n]\\n\\n# Process each query\\nfor query in queries_stjohn:\\n    print(f\"\\nQuery: {query}\")\\n    response = agent.process_query(query)\\n    print(f\"Response: {response}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTmCs87VjAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Future features**"
      ],
      "metadata": {
        "id": "ltWTb_wizi2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#including csv data into the prompt for the thinking module\n",
        "filtered_data_json = [\n",
        "    row for row in csv_data\n",
        "    if row['verified'] == 'Yes' and int(row['satisfaction']) > 5\n",
        "]\n",
        "\n",
        "thinking_prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Data:\n",
        "{json.dumps(filtered_data_json, indent=2)}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "[rest of your prompt...]\n",
        "</thinking>\"\"\""
      ],
      "metadata": {
        "id": "y0pNlfZdXz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent API calls using tenacity for retries\n",
        "!pip install tenacity\n",
        "\n",
        "import json\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key  # or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude with retries for OverloadedError.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON when requested.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \""
      ],
      "metadata": {
        "id": "rhNt1DnCi0Bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}