{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ltWTb_wizi2G"
      ],
      "authorship_tag": "ABX9TyO3MeYaV6OonlmfE30NefrV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/ThinkingAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "almxb-Dl3bpI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "#from anthropic import Anthropic\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional"
      ],
      "metadata": {
        "id": "Xa9wFmP_4DAO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "#api_key_openAI = userdata.get('OpenAI')\n",
        "api_key_anthropic = userdata.get('Antropic')\n",
        "#api_key_gemini = userdata.get('google')"
      ],
      "metadata": {
        "id": "yAiFCOFa4dV3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = 'frog_ferry_meta.csv'"
      ],
      "metadata": {
        "id": "b5EW9t9nnRk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset to be used:\n",
        "df = pd.read_csv(csv_file)\n",
        "#Text cleanup\n",
        "def text_input(file = 'Mejuri_texts.csv'):\n",
        "  df = pd.read_csv(file)\n",
        "  df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "  texts = [item.replace(\"\\t\", \" \") for item in df_clean['Text']]\n",
        "\n",
        "  return texts"
      ],
      "metadata": {
        "id": "dkaDtclI4j_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting a corpus of texts\n",
        "texts_cleaned = text_input(csv_file)\n",
        "corpus = ' '.join(texts_cleaned)\n",
        "test1 = ' '.join(corpus.split()[:20000])"
      ],
      "metadata": {
        "id": "9mD4X9ST4wwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the dataframe into the list of dicts\n",
        "df_clean = df[df['Text'].apply(lambda x: isinstance(x, str))]\n",
        "records = df_clean.to_dict(orient='records')"
      ],
      "metadata": {
        "id": "RCMpdaMOUsyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4HedLU2bVpt",
        "outputId": "f25a774e-2913-40a1-e1a7-e6555a3a9db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Text': 'We have GREATLY appreciated the addition of speed bumps and cross walks in our area by Roosevelt. More traffic calming features and accessible curbs would always be appreciated. A swing set at George park or some other fun addition to the play area there (basketball court, garden, or fenced area for off leash dogs) would be amazing! The FROG FERRY would be SO GREAT for our community, having the option to take a ferry downtown would be so fun for tourists and a great way for locals to spend the day and obviously commuters would benefit so much. I think the addition of a ferry would be ICONIC.',\n",
              " 'connection': 4,\n",
              " 'recommend': 5,\n",
              " 'satisfaction': 6,\n",
              " 'verified': 'Yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thinking Agent"
      ],
      "metadata": {
        "id": "gpHutfKBVpR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_context(self, corpus: str = None, question: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Your actual get_context tool implementation.\n",
        "    This is the function Claude can call.\n",
        "    \"\"\"\n",
        "\n",
        "    if corpus == None or question == None:\n",
        "        return \"No context available - empty corpus or question provided.\""
      ],
      "metadata": {
        "id": "nuyB1UHkR_fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rK3wYScCTZHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key #or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        #print(f'task as defined in the analyze function: {task}')\n",
        "        #print(f'context as defined in the analyze function: {context}')\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "You have an access to a specialized tool called get_context.\n",
        "The get_context tool allows you to get a summary a corpus of text to find relevant information based on a question. Use this tool when:\n",
        "- The user asks a question that might be answered by searching through available text\n",
        "- You need to find specific information within a large body of text\n",
        "- The user's query would benefit from contextual information retrieval\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- use_metadata: Set this field to 'True' if metadata analysis is required and 'False' otherwise\n",
        "- metadata_tool: Suggest a list of additional tools that can be used for metadata analysis if the use_ metadata field is set to 'True'\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Define the tool\n",
        "        tools = [\n",
        "            {\n",
        "                \"name\": \"get_context\",\n",
        "                \"description\": \"Search through a corpus of text to find relevant context based on a question\",\n",
        "                \"input_schema\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"corpus\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The text corpus to search through\"\n",
        "                        },\n",
        "                        \"question\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The question or topic to find relevant context for\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"corpus\", \"question\"]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \"```json\" in content:\n",
        "                json_str = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in content:\n",
        "                json_str = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            result = json.loads(content)\n",
        "\n",
        "            #print(f\"@@@@@@Parsed JSON - analyze function: {result}\")\n",
        "\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            # Fallback if JSON parsing fails\n",
        "            return {\n",
        "                \"reasoning\": content,\n",
        "                \"conclusion\": \"Failed to parse structured output\",\n",
        "                \"confidence\": 0.5,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "'''\n",
        "class MetadataAnalysisTool:\n",
        "    \"\"\"Stub for the metadata analysis tool.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialization for metadata tool would go here\n",
        "        pass\n",
        "\n",
        "    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Analyze reviews based on metadata parameters.\n",
        "\n",
        "        Args:\n",
        "            params: Parameters for filtering and analyzing metadata\n",
        "\n",
        "        Returns:\n",
        "            Filtered list of reviews\n",
        "        \"\"\"\n",
        "        # This is just a stub implementation\n",
        "        print(f\"Metadata tool called with parameters: {params}\")\n",
        "        # In a real implementation, this would filter the actual reviews\n",
        "        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "fhlJ8nUl5Fyt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "b704473d-66b6-4bc6-871b-c58b1e06a3d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass MetadataAnalysisTool:\\n    \"\"\"Stub for the metadata analysis tool.\"\"\"\\n\\n    def __init__(self):\\n        # Initialization for metadata tool would go here\\n        pass\\n\\n    def analyze(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        \"\"\"\\n        Analyze reviews based on metadata parameters.\\n\\n        Args:\\n            params: Parameters for filtering and analyzing metadata\\n\\n        Returns:\\n            Filtered list of reviews\\n        \"\"\"\\n        # This is just a stub implementation\\n        print(f\"Metadata tool called with parameters: {params}\")\\n        # In a real implementation, this would filter the actual reviews\\n        return [{\"id\": 1, \"text\": \"Example filtered review\", \"rating\": 5}]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewAnalysisAgent:\n",
        "    \"\"\"Agent that processes customer queries about review data.\"\"\"\n",
        "\n",
        "    def __init__(self, review_corpus: List[Dict], api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the review analysis agent.\n",
        "\n",
        "        Args:\n",
        "            review_corpus: Collection of customer reviews with metadata\n",
        "            api_key: Anthropic API key (optional if set in environment variables)\n",
        "        \"\"\"\n",
        "        self.review_corpus = review_corpus\n",
        "        #self.metadata_tool = MetadataAnalysisTool()\n",
        "        self.thinking_module = ThinkingModule(api_key=api_key)\n",
        "\n",
        "    def process_query(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Process a customer query and return a response.\n",
        "\n",
        "        Args:\n",
        "            query: Natural language query about the review data\n",
        "\n",
        "        Returns:\n",
        "            Response to the query based on review analysis\n",
        "        \"\"\"\n",
        "        # Step 1: Understand the query through the thinking module\n",
        "        print(f'#####################step 1: Understand the query through the thinking module')\n",
        "\n",
        "\n",
        "        query_analysis = self.thinking_module.analyze(\n",
        "            task=\"Analyze the user query to extract: (1) primary information need, \"\n",
        "                 \"(2)type of analysis requested, \"\n",
        "                 \"(3) whether numerical/metadata analysis is likely needed\",\n",
        "            context=f\"User query: {query}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "        return query_analysis\n",
        "\n",
        "'''\n",
        "        # Step 2: Decide whether to use metadata tool\n",
        "        print(f'#####################step 2: Decide whether to use metadata tool')\n",
        "\n",
        "\n",
        "        tool_decision = self.thinking_module.analyze(\n",
        "            task=\"Determine if metadata analysis is required or beneficial for this query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        print(f'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}')\n",
        "\n",
        "        # Step 3: Execute appropriate analysis\n",
        "        print(f'#####################calling thinking module form the process_query step 3')\n",
        "\n",
        "        #next line has a bug, needs work\n",
        "        #tools_decision_keys_to_extract = ['additional_fields', 'use_metadata_tool', 'd']\n",
        "        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\n",
        "        additional_fields = tool_decision.get(\"additional_fields\", {})\n",
        "        use_metadata = tool_decision.get(\"use_metadata\", False)\n",
        "        print(f'use_metadata call results: {use_metadata}')\n",
        "        print(f'additional_fields call results: {additional_fields}')\n",
        "        #######################################################################################\n",
        "        print('Execution terminated')\n",
        "        raise RuntimeError(\"Stopping execution intentionally.\")\n",
        "        #######################################################################################\n",
        "        if use_metadata:\n",
        "            # Define parameters for metadata tool\n",
        "            metadata_params = self.thinking_module.analyze(\n",
        "                task=\"Determine optimal parameters for metadata tool based on the query\",\n",
        "                context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\n",
        "                reflection_depth=1\n",
        "            )\n",
        "\n",
        "            # Use metadata tool to get filtered set of reviews\n",
        "            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\n",
        "            print(f'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}')\n",
        "            #test: making sure that the metada tool is properly activated\n",
        "            #test block ends\n",
        "            filtered_reviews = self.metadata_tool.analyze(tool_params)\n",
        "            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\n",
        "        else:\n",
        "            # Just analyze the full text corpus\n",
        "            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\n",
        "\n",
        "        # Step 4: Generate final response\n",
        "\n",
        "        print(f'#####################calling thinking module form the process_query step 4')\n",
        "\n",
        "        response = self.thinking_module.analyze(\n",
        "            task=\"Synthesize findings into a comprehensive response to the user query\",\n",
        "            context=f\"Query: {query}\\n\"\n",
        "                   f\"Analysis results: {text_analysis}\\n\"\n",
        "                   f\"Was metadata used: {'Yes' if use_metadata else 'No'}\\n\"\n",
        "                   f\"Thinking process: {query_analysis.get('reasoning', '')}\\n\"\n",
        "                   f\"Tool decision reasoning: {tool_decision.get('reasoning', '')}\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        # Return the final response text\n",
        "        return response.get(\"conclusion\", \"I couldn't generate a proper response.\")\n",
        "\n",
        "    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze the text content of reviews.\n",
        "\n",
        "        Args:\n",
        "            reviews: List of review objects to analyze\n",
        "            query_analysis: Analysis of the user query to guide text analysis\n",
        "\n",
        "        Returns:\n",
        "            Results of the text analysis\n",
        "        \"\"\"\n",
        "        # In a real implementation, this would use NLP techniques\n",
        "        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\n",
        "\n",
        "        # Stub implementation\n",
        "        review_texts = [review.get(\"Text\", \"\") for review in reviews]\n",
        "\n",
        "        # Use the thinking module to analyze the reviews based on the query\n",
        "\n",
        "        print(f'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus')\n",
        "\n",
        "        analysis_result = self.thinking_module.analyze(\n",
        "            task=\"Analyze review texts to answer the user query\",\n",
        "            context=f\"Query analysis: {query_analysis}\\n\"\n",
        "                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\n",
        "            reflection_depth=2\n",
        "        )\n",
        "\n",
        "        return analysis_result\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "RXkurMUoFNkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "b17a6052-960c-4695-8b62-cf63f0189eec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n        # Step 2: Decide whether to use metadata tool\\n        print(f\\'#####################step 2: Decide whether to use metadata tool\\')\\n\\n\\n        tool_decision = self.thinking_module.analyze(\\n            task=\"Determine if metadata analysis is required or beneficial for this query\",\\n            context=f\"Query analysis: {query_analysis}\\n\"\\n                   f\"Available tools: text corpus analysis, metadata analysis tool for numerical data\",\\n            reflection_depth=2\\n        )\\n\\n        print(f\\'+++++++++++++++++++++++++++++tool_decision call results: {tool_decision}\\')\\n\\n        # Step 3: Execute appropriate analysis\\n        print(f\\'#####################calling thinking module form the process_query step 3\\')\\n\\n        #next line has a bug, needs work\\n        #tools_decision_keys_to_extract = [\\'additional_fields\\', \\'use_metadata_tool\\', \\'d\\']\\n        #use_metadata = tool_decision.get(\"additional_fields\", {}).get(\"use_metadata_tool\", False)\\n        additional_fields = tool_decision.get(\"additional_fields\", {})\\n        use_metadata = tool_decision.get(\"use_metadata\", False)\\n        print(f\\'use_metadata call results: {use_metadata}\\')\\n        print(f\\'additional_fields call results: {additional_fields}\\')\\n        #######################################################################################\\n        print(\\'Execution terminated\\')\\n        raise RuntimeError(\"Stopping execution intentionally.\")\\n        #######################################################################################\\n        if use_metadata:\\n            # Define parameters for metadata tool\\n            metadata_params = self.thinking_module.analyze(\\n                task=\"Determine optimal parameters for metadata tool based on the query\",\\n                context=f\"Query analysis: {query_analysis}\\n\"\\n                       f\"Metadata tool capabilities: filter by ratings, aggregate statistics, etc.\",\\n                reflection_depth=1\\n            )\\n\\n            # Use metadata tool to get filtered set of reviews\\n            tool_params = metadata_params.get(\"additional_fields\", {}).get(\"tool_parameters\", {})\\n            print(f\\'@@@@@@@@@@@@@@@@@@@@@@@@@@@@tool_params call results: {tool_params}\\')\\n            #test: making sure that the metada tool is properly activated\\n            #test block ends\\n            filtered_reviews = self.metadata_tool.analyze(tool_params)\\n            text_analysis = self._analyze_text_corpus(filtered_reviews, query_analysis)\\n        else:\\n            # Just analyze the full text corpus\\n            text_analysis = self._analyze_text_corpus(self.review_corpus, query_analysis)\\n\\n        # Step 4: Generate final response\\n\\n        print(f\\'#####################calling thinking module form the process_query step 4\\')\\n\\n        response = self.thinking_module.analyze(\\n            task=\"Synthesize findings into a comprehensive response to the user query\",\\n            context=f\"Query: {query}\\n\"\\n                   f\"Analysis results: {text_analysis}\\n\"\\n                   f\"Was metadata used: {\\'Yes\\' if use_metadata else \\'No\\'}\\n\"\\n                   f\"Thinking process: {query_analysis.get(\\'reasoning\\', \\'\\')}\\n\"\\n                   f\"Tool decision reasoning: {tool_decision.get(\\'reasoning\\', \\'\\')}\",\\n            reflection_depth=2\\n        )\\n\\n        # Return the final response text\\n        return response.get(\"conclusion\", \"I couldn\\'t generate a proper response.\")\\n\\n    def _analyze_text_corpus(self, reviews: List[Dict], query_analysis: Dict) -> Dict[str, Any]:\\n        \"\"\"\\n        Analyze the text content of reviews.\\n\\n        Args:\\n            reviews: List of review objects to analyze\\n            query_analysis: Analysis of the user query to guide text analysis\\n\\n        Returns:\\n            Results of the text analysis\\n        \"\"\"\\n        # In a real implementation, this would use NLP techniques\\n        # appropriate for the query type (sentiment analysis, topic modeling, etc.)\\n\\n        # Stub implementation\\n        review_texts = [review.get(\"Text\", \"\") for review in reviews]\\n\\n        # Use the thinking module to analyze the reviews based on the query\\n\\n        print(f\\'!!!!!!!!!!!!!!!!!!!!!!!!!!calling thinking module from inside the analyze_text_corpus\\')\\n\\n        analysis_result = self.thinking_module.analyze(\\n            task=\"Analyze review texts to answer the user query\",\\n            context=f\"Query analysis: {query_analysis}\\n\"\\n                   f\"Reviews to analyze: {review_texts} (showing first 5 only)\",\\n            reflection_depth=2\\n        )\\n\\n        return analysis_result\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "queries (St.John):\n",
        "Where are pedestrian safety improvements needed?\n",
        "What can police be doing to make the neighborhood safer?\n",
        "What can city council prioritize to help St Johns?\n",
        "What new businesses are needed in St Johns and where?\n",
        "What issues would Frog Ferry solve?"
      ],
      "metadata": {
        "id": "4QH6WsxFYhGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(records_stjohn[1000:5400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtxf247Xhjad",
        "outputId": "b34d3e13-184b-4bd0-adf4-1e15209ea55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4400"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "# Set your API key\n",
        "api_key = api_key_anthropic\n",
        "records = {}\n",
        "# Sample review corpus (in a real scenario, this would be much larger)\n",
        "sample_reviews = [\n",
        "    {\"id\": 1, \"text\": \"Love this product! Battery life is amazing.\", \"rating\": 5, \"verified\": True},\n",
        "    {\"id\": 2, \"text\": \"Decent product but overpriced for what you get.\", \"rating\": 3, \"verified\": True},\n",
        "    {\"id\": 3, \"text\": \"Terrible quality, broke after one week.\", \"rating\": 1, \"verified\": True},\n",
        "    # In reality, you'd have thousands more reviews here\n",
        "]\n",
        "\n",
        "# Initialize the agent\n",
        "\n",
        "agent = ReviewAnalysisAgent(review_corpus=records, api_key=api_key)\n",
        "\n",
        "# Example queries\n",
        "queries = [\n",
        "    \"What do customers think about the battery life? assume you have a dataset of the customer reviews about a produc\"\n",
        "    #\"Are verified purchasers happier with the product than non-verified ones?\",\n",
        "    #\"What are the most common complaints in 1-star reviews?\"\n",
        "]\n",
        "\n",
        "query_battery = '''\n",
        "What do customers think about the battery life? assume you have a dataset of the customer reviews about a product\n",
        "that includes a battery, reviews discuss the product and may include information and opinions about the battery.\n",
        "every review comes with the metadata including review rating, overall sentiment, geographic region the review comes from\n",
        "'''\n",
        "\n",
        "query_stjohn = '''\n",
        "What issues would 'Frog Ferry' ferry service solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5\n",
        "assume you have a dataset of the customer reviews the Ferry service\"\n",
        "'''\n",
        "response = agent.process_query(query_stjohn)\n",
        "print(f\"#####Response: {response}\")\n",
        "\n",
        "'''\n",
        "queries_stjohn = [\n",
        "    #\"Where are pedestrian safety improvements needed?\",\n",
        "    #\"What can police be doing to make the neighborhood safer?\",\n",
        "    #\"What can city council prioritize to help St Johns?\",\n",
        "    #\"What new businesses are needed in St Johns and where?\",\n",
        "    #\"What issues would Frog Ferry solve?\",\n",
        "    \"What issues would 'Frog Ferry' ferry service solve? pls only consider 'verified' reviews with 'satisfaction' rating above 5 \"\n",
        "]\n",
        "\n",
        "# Process each query\n",
        "for query in queries_stjohn:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = agent.process_query(query)\n",
        "    print(f\"Response: {response}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "JDBFbblk5i35",
        "outputId": "6cfda81f-aa2c-4eb9-8355-2b3372216bf8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####################step 1: Understand the query through the thinking module\n",
            "Claude's response - analyze function: ```json\n",
            "{\n",
            "  \"reasoning\": {\n",
            "    \"step1\": {\n",
            "      \"analysis\": \"Let's break down the user query to understand what is being asked:\",\n",
            "      \"components\": {\n",
            "        \"main_question\": \"What issues would 'Frog Ferry' ferry service solve?\",\n",
            "        \"constraints\": [\n",
            "          \"only consider 'verified' reviews\",\n",
            "          \"with 'satisfaction' rating above 5\"\n",
            "        ],\n",
            "        \"dataset_assumption\": \"assume you have a dataset of the customer reviews the Ferry service\"\n",
            "      }\n",
            "    },\n",
            "    \"step2\": {\n",
            "      \"primary_need\": \"The user wants to identify problems or issues that the 'Frog Ferry' service addresses or solves based on customer reviews.\",\n",
            "      \"analysis_type\": \"This requires qualitative analysis of review content to extract mentioned issues/problems that were solved.\",\n",
            "      \"metadata_requirements\": {\n",
            "        \"needed\": true,\n",
            "        \"reasons\": [\n",
            "          \"Need to filter for only 'verified' reviews (metadata field)\",\n",
            "          \"Need to filter for reviews with 'satisfaction' rating > 5 (numerical metadata field)\",\n",
            "          \"These filtering operations must be performed before content analysis\"\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"conclusion\": \"The query asks for issues solved by 'Frog Ferry' service based on highly-rated verified reviews. This requires filtering review metadata (verification status and satisfaction rating) before analyzing review content to identify mentioned problems/issues that the ferry service addresses.\",\n",
            "  \"confidence\": 0.95,\n",
            "  \"use_metadata\": true,\n",
            "  \"metadata_tool\": [\"filtering_tool\", \"data_selection_tool\", \"numerical_comparison_tool\"]\n",
            "}\n",
            "```\n",
            "#####Response: {'reasoning': {'step1': {'analysis': \"Let's break down the user query to understand what is being asked:\", 'components': {'main_question': \"What issues would 'Frog Ferry' ferry service solve?\", 'constraints': [\"only consider 'verified' reviews\", \"with 'satisfaction' rating above 5\"], 'dataset_assumption': 'assume you have a dataset of the customer reviews the Ferry service'}}, 'step2': {'primary_need': \"The user wants to identify problems or issues that the 'Frog Ferry' service addresses or solves based on customer reviews.\", 'analysis_type': 'This requires qualitative analysis of review content to extract mentioned issues/problems that were solved.', 'metadata_requirements': {'needed': True, 'reasons': [\"Need to filter for only 'verified' reviews (metadata field)\", \"Need to filter for reviews with 'satisfaction' rating > 5 (numerical metadata field)\", 'These filtering operations must be performed before content analysis']}}}, 'conclusion': \"The query asks for issues solved by 'Frog Ferry' service based on highly-rated verified reviews. This requires filtering review metadata (verification status and satisfaction rating) before analyzing review content to identify mentioned problems/issues that the ferry service addresses.\", 'confidence': 0.95, 'use_metadata': True, 'metadata_tool': ['filtering_tool', 'data_selection_tool', 'numerical_comparison_tool']}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nqueries_stjohn = [\\n    #\"Where are pedestrian safety improvements needed?\",\\n    #\"What can police be doing to make the neighborhood safer?\",\\n    #\"What can city council prioritize to help St Johns?\",\\n    #\"What new businesses are needed in St Johns and where?\",\\n    #\"What issues would Frog Ferry solve?\",\\n    \"What issues would \\'Frog Ferry\\' ferry service solve? pls only consider \\'verified\\' reviews with \\'satisfaction\\' rating above 5 \"\\n]\\n\\n# Process each query\\nfor query in queries_stjohn:\\n    print(f\"\\nQuery: {query}\")\\n    response = agent.process_query(query)\\n    print(f\"Response: {response}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTmCs87VjAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Future features**"
      ],
      "metadata": {
        "id": "ltWTb_wizi2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#including csv data into the prompt for the thinking module\n",
        "filtered_data_json = [\n",
        "    row for row in csv_data\n",
        "    if row['verified'] == 'Yes' and int(row['satisfaction']) > 5\n",
        "]\n",
        "\n",
        "thinking_prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Data:\n",
        "{json.dumps(filtered_data_json, indent=2)}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "[rest of your prompt...]\n",
        "</thinking>\"\"\""
      ],
      "metadata": {
        "id": "y0pNlfZdXz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent API calls using tenacity for retries\n",
        "!pip install tenacity\n",
        "\n",
        "import json\n",
        "import anthropic\n",
        "from typing import Dict, List, Any, Optional\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "class ThinkingModule:\n",
        "    \"\"\"Custom module that leverages Claude's capabilities for reflective thinking.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the thinking module with the Anthropic API client.\"\"\"\n",
        "        self.api_key = api_key  # or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
        "        self.model = \"claude-3-7-sonnet-20250219\"  # Using Claude 3.7 Sonnet\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def analyze(self, task: str, context: str, reflection_depth: int = 1) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Perform reflective thinking using Claude with retries for OverloadedError.\n",
        "\n",
        "        Args:\n",
        "            task: The specific thinking task to perform\n",
        "            context: Relevant context for the thinking task\n",
        "            reflection_depth: How many levels of reflection to perform (1-3)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing the analysis results\n",
        "        \"\"\"\n",
        "        # Build the prompt for Claude\n",
        "        prompt = f\"\"\"<thinking>\n",
        "Task: {task}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Please think through this step-by-step with {reflection_depth} level(s) of reflection.\n",
        "Provide your analysis in JSON format with these fields:\n",
        "- reasoning: Your step-by-step reasoning process\n",
        "- conclusion: A concise summary of your conclusion\n",
        "- confidence: A number from 0-1 indicating your confidence\n",
        "- additional_fields: Any task-specific outputs needed\n",
        "</thinking>\"\"\"\n",
        "\n",
        "        # Call Claude API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=2000,\n",
        "            temperature=0.2,  # Low temperature for more deterministic thinking\n",
        "            system=\"You are an expert analytical assistant. When asked to think about a problem, you break it down methodically and provide clear, structured analysis. Your output should always be valid JSON when requested.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract and parse JSON response\n",
        "        try:\n",
        "            # Find JSON in the response content\n",
        "            content = response.content[0].text\n",
        "\n",
        "            print(f\"Claude's response - analyze function: {content}\")\n",
        "\n",
        "            # Extract JSON part (assuming it's properly formatted)\n",
        "            json_str = content\n",
        "            if \""
      ],
      "metadata": {
        "id": "rhNt1DnCi0Bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}