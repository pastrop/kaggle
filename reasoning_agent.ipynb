{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/reasoning_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192f5a65-b1fa-4e21-bda2-66d089680dc0",
      "metadata": {
        "id": "192f5a65-b1fa-4e21-bda2-66d089680dc0"
      },
      "source": [
        "# Reasoning Agent\n",
        "Idea: is generate a plan with `o1-mini` and then execute each step with `gpt-4o-mini`.\n",
        "Implementation: Planning agent is completed; implementation agent - work in progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f9ff70b6-24a5-4063-aad8-74ca6f599b9e",
      "metadata": {
        "height": 132,
        "id": "f9ff70b6-24a5-4063-aad8-74ca6f599b9e"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import OpenAI key\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OpenAI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "43e9b83e-510e-473b-8e41-0de8f279dd35",
      "metadata": {
        "height": 166,
        "id": "43e9b83e-510e-473b-8e41-0de8f279dd35"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "from utils import o1_tools\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "O1_MODEL = 'o1-mini'\n",
        "GPT_MODEL = 'gpt-4o-mini'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a8ff771-2ef8-4f6b-abad-47abd1ca99d1",
      "metadata": {
        "id": "0a8ff771-2ef8-4f6b-abad-47abd1ca99d1"
      },
      "source": [
        "## Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c7ad01af-c3f9-411d-b190-978f913e07c4",
      "metadata": {
        "height": 1203,
        "id": "c7ad01af-c3f9-411d-b190-978f913e07c4"
      },
      "outputs": [],
      "source": [
        "# Initialize the message list\n",
        "message_list = []\n",
        "\n",
        "# Define the initial context for the application\n",
        "context = {\n",
        "    'Providers': {\n",
        "        'Caregivers': 5  # Number of cargivers\n",
        "    },\n",
        "    'care_requests': [\n",
        "        {\n",
        "            'Locations': ['Queens','Brooklyn','Namhattan'],\n",
        "            'requests': [\n",
        "                {'patient': 'patient1', 'location': 'Queens', 'day': 'Monday', 'time': '10am-12pm'},\n",
        "                {'patient': 'patient2', 'location': 'Queens', 'day': 'Monday', 'time': '1pm-3pm'},\n",
        "                {'patient': 'patient3', 'location': 'Brooklyn', 'day': 'Tuesday', 'time': '10am-12pm'},\n",
        "                {'patient': 'patient4', 'location': 'Manhattan', 'day': 'Wednesday', 'time': '11am-2pm'},\n",
        "                {'patient': 'patient5', 'location': 'Queens', 'day': 'Wednesday', 'time': '3pm-5pm'},\n",
        "                {'patient': 'patient6', 'location': 'Brroklyn', 'day': 'Thursday', 'time': '1am-5pm'},\n",
        "                {'patient': 'patient7', 'location': 'Queens', 'day': 'Thursday', 'time': '10am-12pm'},\n",
        "                {'patient': 'patient8', 'location': 'Queens', 'day': 'Friday', 'time': '10am-12pm'}\n",
        "                ] # Dimensions in cm\n",
        "        }\n",
        "    ],\n",
        "    'available_caregivers': ['CG1', 'CG2', 'CG3', 'CG4', 'CG5'],\n",
        "    'suppliers': {\n",
        "        'CG1': {\n",
        "            'availability': {\n",
        "                'Location': ['Queens','Manhattan'],\n",
        "                'working_days':['Monday','Tuesday','Wednesday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00'\n",
        "                }\n",
        "            },\n",
        "         'CG2': {\n",
        "            'availability': {\n",
        "                'Location': ['Queens'],\n",
        "                'working_days':['Monday','Thursday','Friday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00'\n",
        "            },\n",
        "         },\n",
        "        'CG3': {\n",
        "            'availability': {\n",
        "                'Location': ['Brooklyn'],\n",
        "                'working_days':['Monday','Tuesday','Thursday','Friday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00'\n",
        "            }\n",
        "        },\n",
        "        'CG4': {\n",
        "            'availability': {\n",
        "                'Location': ['Broklyn', 'Manhattan'],\n",
        "                'working_days':['Monday','Tuesday','Wednesday','Thursday','Friday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00'\n",
        "            }\n",
        "        },\n",
        "        'CG5': {\n",
        "            'availability': {\n",
        "                'Location': ['Manhattan', 'Brooklyn'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "# Store the initial state of context\n",
        "initial_context = copy.deepcopy(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3fecabdc-9fea-4e71-bf61-ad56c2ee45c2",
      "metadata": {
        "height": 1016,
        "id": "3fecabdc-9fea-4e71-bf61-ad56c2ee45c2"
      },
      "outputs": [],
      "source": [
        "# Prompt for the planning model\n",
        "o1_prompt = \"\"\"\n",
        "You are a scheduling assistant. The first input you will receive will be a complex task that needs to be carefully reasoned through to solve.\n",
        "Your task is to review the challenge, and create a detailed plan to optimally match service providers (caregivers) with service users (patients)\n",
        "while considering cargivers work days and work hours, avoiding double-booking and taking into account the travel travel time between the service location.\n",
        "You may suggest adding new caregivers working hours or locations if you are not able to cover all the sevice requests.\n",
        "\n",
        "You will have access to an LLM agent that is responsible for executing the plan that you create and will return results.\n",
        "\n",
        "The LLM agent has access to the following functions:\n",
        "    - get_address(ID)\n",
        "        - This gets the addresses for service provider and service users\n",
        "    - calculate_travel_time(origin_address, destination_address)\n",
        "        - This function calculate travel time between locations\n",
        "    -add_caregiver(service_location)\n",
        "        - This function adds cargivers to udnerserved location\n",
        "\n",
        "\n",
        "When creating a plan for the LLM to execute, break your instructions into a logical, step-by-step order, using the specified format:\n",
        "    - **Main actions are numbered** (e.g., 1, 2, 3).\n",
        "    - **Sub-actions are lettered** under their relevant main actions (e.g., 1a, 1b).\n",
        "        - **Sub-actions should start on new lines**\n",
        "    - **Specify conditions using clear 'if...then...else' statements** (e.g., 'If the product was purchased within 30 days, then...').\n",
        "    - **For actions that require using one of the above functions defined**, write a step to call a function using backticks for the function name (e.g., `call the get_inventory_status function`).\n",
        "        - Ensure that the proper input arguments are given to the model for instruction. There should not be any ambiguity in the inputs.\n",
        "    - **The last step** in the instructions should always be calling the `instructions_complete` function. This is necessary so we know the LLM has completed all of the instructions you have given it.\n",
        "    - **Detailed steps** The plan generated must be extremely detailed and thorough with explanations at every step.\n",
        "Use markdown format when generating the plan with each step and sub-step.\n",
        "\n",
        "Please find the scenario below.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e9ff5752-acb0-4bb1-adb3-58ce2ac1133f",
      "metadata": {
        "height": 319,
        "id": "e9ff5752-acb0-4bb1-adb3-58ce2ac1133f"
      },
      "outputs": [],
      "source": [
        "# System prompt for the execution model\n",
        "gpt4o_system_prompt = \"\"\"\n",
        "You are a helpful assistant responsible for executing the policy on handling incoming orders. Your task is to follow the policy exactly as it is written and perform the necessary actions.\n",
        "\n",
        "You must explain your decision-making process across various steps.\n",
        "\n",
        "# Steps\n",
        "\n",
        "1. **Read and Understand Policy**: Carefully read and fully understand the given policy on handling incoming orders.\n",
        "2. **Identify the exact step in the policy**: Determine which step in the policy you are at, and execute the instructions according to the policy.\n",
        "3. **Decision Making**: Briefly explain your actions and why you are performing them.\n",
        "4. **Action Execution**: Perform the actions required by calling any relevant functions and input parameters.\n",
        "\n",
        "POLICY:\n",
        "{policy}\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb08d00-1371-4d86-beb4-56dcd44b8eb1",
      "metadata": {
        "id": "ebb08d00-1371-4d86-beb4-56dcd44b8eb1"
      },
      "source": [
        "#### Describe functions that will be passed to the 4o-mini helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fa6c37dd-8ec5-4ed7-9cfd-0259867cd4fd",
      "metadata": {
        "height": 4909,
        "id": "fa6c37dd-8ec5-4ed7-9cfd-0259867cd4fd"
      },
      "outputs": [],
      "source": [
        "TOOLS = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_address\",\n",
        "            \"description\": \"Retrives address of caregivers and patients\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unique identifier for the caregiver or patient.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"id\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculate_travel_time\",\n",
        "            \"description\": \"Cacculates travel time between locations\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"origin_address\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location were trip starts.\",\n",
        "                    },\n",
        "                    \"destination_addres\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location were trip ends\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"origina_address\", \"destination_address\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"add_caregiver\",\n",
        "            \"description\": \"Adds caregivers for the underserved locations\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"service_location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location were more caregiers need to be added.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": \"service_location\",\n",
        "                \"additionalProperties\": False,\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ebbecbe-8cbd-4355-bece-d272144149f4",
      "metadata": {
        "id": "2ebbecbe-8cbd-4355-bece-d272144149f4"
      },
      "source": [
        "#### These are the instantiations of the functions the 4o-mini helper will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "130643d7-3043-45b9-baec-a1e37db91c97",
      "metadata": {
        "height": 1866,
        "id": "130643d7-3043-45b9-baec-a1e37db91c97"
      },
      "outputs": [],
      "source": [
        "# Function Definitions\n",
        "def get_address(ID):\n",
        "    pass\n",
        "    return 'address'\n",
        "\n",
        "def calculate_travel_time(product_id):\n",
        "    time = random.randint(1, 100)\n",
        "    return time\n",
        "\n",
        "def add_caregiver(location):\n",
        "    id = random.randint(1, 100)\n",
        "    caregiver = {\n",
        "        'id': id,\n",
        "        'location': location\n",
        "    }\n",
        "    return caregiver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb77482-4a4c-4975-9b70-e1fd03060848",
      "metadata": {
        "id": "dfb77482-4a4c-4975-9b70-e1fd03060848"
      },
      "source": [
        "#### Knit together the process. 1) call o1 to generate a plan, 2) call 4o-mini to execute the plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "064c42b6-e79e-4172-b2cf-1f7d5f0d0dd2",
      "metadata": {
        "height": 251,
        "id": "064c42b6-e79e-4172-b2cf-1f7d5f0d0dd2"
      },
      "outputs": [],
      "source": [
        "def process_scenario(scenario):\n",
        "    append_message({'type': 'status', 'message': 'Generating plan...'})\n",
        "\n",
        "    plan = call_o1(scenario)\n",
        "\n",
        "    messages = append_message({'type': 'plan', 'content': plan})\n",
        "\n",
        "    #append_message({'type': 'status', 'message': 'Executing plan...'})\n",
        "\n",
        "    #messages = call_gpt4o(plan)\n",
        "\n",
        "    #append_message({'type': 'status', 'message': 'Processing complete.'})\n",
        "\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae32f60-4526-4607-8bc8-8ad2bd2702bb",
      "metadata": {
        "id": "3ae32f60-4526-4607-8bc8-8ad2bd2702bb"
      },
      "source": [
        "##### Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bfa04398-ccf6-4f98-b343-b9987d145e9b",
      "metadata": {
        "height": 302,
        "id": "bfa04398-ccf6-4f98-b343-b9987d145e9b"
      },
      "outputs": [],
      "source": [
        "def append_message(message):\n",
        "    message_list.append(message)\n",
        "    # Optionally, print the message for immediate feedback\n",
        "    message_type = message.get('type', '')\n",
        "    if message_type == 'status':\n",
        "        print(message['message'])\n",
        "    elif message_type == 'plan':\n",
        "        print(\"\\nPlan:\\n\", message['content'])\n",
        "    elif message_type == 'assistant':\n",
        "        print(\"\\nAssistant:\\n\", message['content'])\n",
        "    elif message_type == 'function_call':\n",
        "        print(f\"\\nFunction call: {message['function_name']} with arguments {message['arguments']}\")\n",
        "    elif message_type == 'function_response':\n",
        "        print(f\"\\nFunction response for {message['function_name']}: {message['response']}\")\n",
        "    else:\n",
        "        # Handle any other message types or default case\n",
        "        print(message.get('content', ''))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e7dfb7-0be4-4ea3-be3b-74e8fb6d9bce",
      "metadata": {
        "id": "54e7dfb7-0be4-4ea3-be3b-74e8fb6d9bce"
      },
      "source": [
        "#### Calls the planner, o1 model. The response will be the plan that will be provided to the  4o-mini helper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "71ce25c9-fff0-423e-9fa5-9314e0d0aeba",
      "metadata": {
        "height": 285,
        "id": "71ce25c9-fff0-423e-9fa5-9314e0d0aeba"
      },
      "outputs": [],
      "source": [
        "def call_o1(scenario):\n",
        "    prompt = f\"\"\"\n",
        "{o1_prompt}\n",
        "\n",
        "Scenario:\n",
        "{scenario}\n",
        "\n",
        "Please provide the next steps in your plan.\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=O1_MODEL,\n",
        "        messages=[{'role': 'user', 'content': prompt}]\n",
        "    )\n",
        "    plan = response.choices[0].message.content\n",
        "\n",
        "    return plan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9ffa22-1abb-4591-b785-e6a9b055a893",
      "metadata": {
        "id": "cc9ffa22-1abb-4591-b785-e6a9b055a893"
      },
      "source": [
        "#### Call 4o-mini to execute the plan. This will loop until the plan is complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35531ab2-040b-4fe9-ab1c-0c7dc3cd0974",
      "metadata": {
        "height": 1050,
        "id": "35531ab2-040b-4fe9-ab1c-0c7dc3cd0974"
      },
      "outputs": [],
      "source": [
        "def call_gpt4o(plan):\n",
        "    gpt4o_policy_prompt = gpt4o_system_prompt.replace(\"{policy}\", plan)\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': gpt4o_policy_prompt},\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        response = client.chat.completions.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=messages,\n",
        "            tools=TOOLS,\n",
        "            parallel_tool_calls=False\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message.to_dict()\n",
        "        print(assistant_message)\n",
        "        messages.append(assistant_message)\n",
        "\n",
        "        append_message({'type': 'assistant', 'content': assistant_message.get('content', '')})\n",
        "\n",
        "        if (response.choices[0].message.tool_calls and\n",
        "            response.choices[0].message.tool_calls[0].function.name == 'instructions_complete'):\n",
        "            break\n",
        "\n",
        "        if not response.choices[0].message.tool_calls:\n",
        "            continue\n",
        "\n",
        "        for tool in response.choices[0].message.tool_calls:\n",
        "            tool_id = tool.id\n",
        "            function_name = tool.function.name\n",
        "            input_arguments_str = tool.function.arguments\n",
        "\n",
        "            append_message({'type': 'tool_call', 'function_name': function_name, 'arguments': input_arguments_str})\n",
        "\n",
        "            try:\n",
        "                input_arguments = json.loads(input_arguments_str)\n",
        "            except (ValueError, json.JSONDecodeError):\n",
        "                continue\n",
        "\n",
        "            if function_name in function_mapping:\n",
        "                try:\n",
        "                    function_response = function_mapping[function_name](**input_arguments)\n",
        "                except Exception as e:\n",
        "                    function_response = {'error': str(e)}\n",
        "            else:\n",
        "                function_response = {'error': f\"Function '{function_name}' not implemented.\"}\n",
        "\n",
        "            try:\n",
        "                serialized_output = json.dumps(function_response)\n",
        "            except (TypeError, ValueError):\n",
        "                serialized_output = str(function_response)\n",
        "\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_id,\n",
        "                \"content\": serialized_output\n",
        "            })\n",
        "\n",
        "            append_message({'type': 'tool_response', 'function_name': function_name, 'response': serialized_output})\n",
        "\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9dc480-4a92-4c7b-a17a-e0fcaf5b5414",
      "metadata": {
        "id": "aa9dc480-4a92-4c7b-a17a-e0fcaf5b5414"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fcc9bae1-9f75-4ae1-98eb-900a501d54b0",
      "metadata": {
        "height": 268,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcc9bae1-9f75-4ae1-98eb-900a501d54b0",
        "outputId": "6a6bba59-eb1d-43db-c871-814762ff4c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating plan...\n",
            "\n",
            "Plan:\n",
            " ```markdown\n",
            "# Caregiver Scheduling Plan\n",
            "\n",
            "1. **Retrieve Service Requests for the Week**\n",
            "    - 1a. Compile a list of all service requests for the upcoming week, including patient IDs, requested service times, and service locations.\n",
            "    - 1b. For each patient ID in the service requests, `call the get_address` with the patient ID to obtain their address.\n",
            "\n",
            "2. **Gather Caregiver Availability and Locations**\n",
            "    - 2a. Compile a list of all caregivers, including their available work days, work hours, and current work locations.\n",
            "    - 2b. For each caregiver, `call the get_address` with the caregiver ID to obtain their work address.\n",
            "\n",
            "3. **Match Service Requests with Caregiver Availability**\n",
            "    - 3a. For each service request:\n",
            "        - 3a1. Identify caregivers available on the requested service day.\n",
            "        - 3a2. From the available caregivers, filter those whose work hours encompass the requested service time.\n",
            "    - 3b. For each eligible caregiver:\n",
            "        - 3b1. `call the calculate_travel_time` with the caregiver's work address as the origin and the patient's address as the destination to determine travel time.\n",
            "        - 3b2. Calculate the end time of travel and service to ensure it does not conflict with other scheduled services.\n",
            "    - 3c. Assign the service request to the caregiver who can accommodate the service time without overlapping other bookings and has the shortest travel time.\n",
            "        - If multiple caregivers qualify, prioritize based on least total assigned hours or proximity.\n",
            "        - Else, proceed to step 6 to address underserved locations.\n",
            "\n",
            "4. **Avoid Double-Booking Caregivers**\n",
            "    - 4a. Maintain a schedule for each caregiver, tracking their assigned service times and locations.\n",
            "    - 4b. Before assigning a new service request, check the caregiver's existing schedule:\n",
            "        - If the new service does not overlap with existing assignments considering travel time, proceed with the assignment.\n",
            "        - Else, exclude the caregiver from the current service request's eligible list.\n",
            "\n",
            "5. **Optimize Travel Time and Efficiency**\n",
            "    - 5a. For caregivers with multiple assigned service requests, order the assignments to minimize total travel time.\n",
            "    - 5b. Calculate the travel time between consecutive service locations:\n",
            "        - `call the calculate_travel_time` with the previous service location as origin and the next service location as destination.\n",
            "    - 5c. Adjust service assignments as necessary to ensure timely arrivals and efficient routing.\n",
            "\n",
            "6. **Identify and Address Underserved Locations**\n",
            "    - 6a. Analyze all service requests and caregiver assignments to identify locations with unmet service demands.\n",
            "    - 6b. For each underserved location:\n",
            "        - `call the add_caregiver` with the underserved location to add additional caregivers.\n",
            "    - 6c. Repeat steps 2 and 3 to assign newly added caregivers to service requests in underserved locations.\n",
            "\n",
            "7. **Finalize the Weekly Schedule**\n",
            "    - 7a. Compile the final schedule for each caregiver, detailing their assigned service requests, service times, and travel plans.\n",
            "    - 7b. Review the complete schedule to ensure all service requests are addressed and all constraints are satisfied.\n",
            "    - 7c. Make adjustments as necessary to handle any remaining conflicts or inefficiencies.\n",
            "\n",
            "8. **Communicate the Schedule**\n",
            "    - 8a. Distribute the finalized schedule to all caregivers, ensuring they are informed of their assignments and any relevant details.\n",
            "    - 8b. Provide service users with confirmation of their assigned caregivers and service times.\n",
            "\n",
            "9. **Monitor and Adjust**\n",
            "    - 9a. Throughout the week, monitor service execution to identify any issues or changes in availability.\n",
            "    - 9b. Make real-time adjustments to the schedule as necessary to accommodate unforeseen changes or emergencies.\n",
            "\n",
            "10. **Complete Instructions**\n",
            "    - 10. `call the instructions_complete` function\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "scenario_text = (\"We need to create a caregiver schedule for a week. \"\n",
        "                 \"Please generate a plan that gets caregivers availability \"\n",
        "                 \"and matches it with the service requests.\\n\\n\"\n",
        "                 \"The plan should consider patient locations\"\n",
        "                 \"and match it with the caregiver working location.\"\n",
        "                 \"The should avoid doublebooking caregivers and\"\n",
        "                 \"and account for travel time between work location.\"\n",
        "                 \"the plan may include a suggestion to add cargivers\"\n",
        "                 \"covering underserved locations\")\n",
        "\n",
        "# Process the scenario\n",
        "messages = process_scenario(scenario_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206ffcf2-8d2d-4220-980f-5367add8843b",
      "metadata": {
        "id": "206ffcf2-8d2d-4220-980f-5367add8843b"
      },
      "source": [
        "#### Print messages\n",
        "<span style=\"color:green;\">Note: Your results may differ from those in the video as the models outputs may change with each run.</span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "839da30a-24dd-44ae-96e9-6a8b5ff04663",
      "metadata": {
        "height": 64,
        "id": "839da30a-24dd-44ae-96e9-6a8b5ff04663"
      },
      "outputs": [],
      "source": [
        "#for x in messages:\n",
        "    #print(x)\n",
        "    #print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41341a9b-9cd9-4481-ad13-fa2dd251982e",
      "metadata": {
        "height": 30,
        "id": "41341a9b-9cd9-4481-ad13-fa2dd251982e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}