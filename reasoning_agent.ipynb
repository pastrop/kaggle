{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/reasoning_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192f5a65-b1fa-4e21-bda2-66d089680dc0",
      "metadata": {
        "id": "192f5a65-b1fa-4e21-bda2-66d089680dc0"
      },
      "source": [
        "# Reasoning Agent\n",
        "what we'll do is generate a plan with `o1-mini` and then execute each step with `gpt-4o-mini`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ff70b6-24a5-4063-aad8-74ca6f599b9e",
      "metadata": {
        "height": 132,
        "id": "f9ff70b6-24a5-4063-aad8-74ca6f599b9e"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import OpenAI key\n",
        "from helper import get_openai_api_key\n",
        "openai_api_key = get_openai_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e9b83e-510e-473b-8e41-0de8f279dd35",
      "metadata": {
        "height": 166,
        "id": "43e9b83e-510e-473b-8e41-0de8f279dd35"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "from utils import o1_tools\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "O1_MODEL = 'o1-mini'\n",
        "GPT_MODEL = 'gpt-4o-mini'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a8ff771-2ef8-4f6b-abad-47abd1ca99d1",
      "metadata": {
        "id": "0a8ff771-2ef8-4f6b-abad-47abd1ca99d1"
      },
      "source": [
        "## Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ad01af-c3f9-411d-b190-978f913e07c4",
      "metadata": {
        "height": 1203,
        "id": "c7ad01af-c3f9-411d-b190-978f913e07c4"
      },
      "outputs": [],
      "source": [
        "# Initialize the message list\n",
        "message_list = []\n",
        "\n",
        "# Define the initial context for the application\n",
        "context = {\n",
        "    'Providers': {\n",
        "        'Caregivers': 5  # Number of cargivers\n",
        "    },\n",
        "    'care_requests': [\n",
        "        {\n",
        "            'Locations': ['Queens','Brooklyn','Namhattan'],\n",
        "            'requests': [\n",
        "                {'patient': 'patient1', 'location': 'Queens', 'day': 'Monday', 'time': '10am-12pm'},\n",
        "                {'patient': 'patient2', 'location': 'Queens', 'day': 'Monday', 'time': '1pm-3pm'},\n",
        "                {'patient': 'patient3', 'location': 'Brooklyn', 'day': 'Tuesday', 'time': '10am-12pm'},\n",
        "                {'patient': 'patient4', 'location': 'Manhattan', 'day': 'Wednesday', 'time': '11am-2pm'},\n",
        "                {'patient': 'patient5', 'location': 'Queens', 'day': 'Wednesday', 'time': '3pm-5pm'},\n",
        "                {'patient': 'patient6', 'location': 'Brroklyn', 'day': 'Thursday', 'time': '1am-5pm'},\n",
        "                {'patient': 'patient7', 'location': 'Queens', 'day': 'Thursday', 'time': '10am-12pm'},\n",
        "                {'patient': 'patient8', 'location': 'Queens', 'day': 'Friday', 'time': '10am-12pm'}\n",
        "                ] # Dimensions in cm\n",
        "        }\n",
        "    ],\n",
        "    'available_caregivers': ['CG1', 'CG2', 'CG3', 'CG4', 'CG5'],\n",
        "    'suppliers': {\n",
        "        'CG1': {\n",
        "            'availability': {\n",
        "                'Location': ['Queens','Manhattan'],\n",
        "                'working_days';['Monday','Tuesday','Wednesday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00\n",
        "                }\n",
        "            },\n",
        "         'CG2': {\n",
        "            'availability': {\n",
        "                'Location': ['Queens'],\n",
        "                'working_days';['Monday','Thursday','Friday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00\n",
        "            },\n",
        "         },\n",
        "        'CG3': {\n",
        "            'availability': {\n",
        "                'Location': ['Brooklyn'],\n",
        "                'working_days';['Monday','Tuesday','Thursday','Friday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00\n",
        "            }\n",
        "        },\n",
        "        'CG4': {\n",
        "            'availability': {\n",
        "                'Location': ['Broklyn', 'Manhattan'],\n",
        "                'working_days';['Monday','Tuesday','Wednesday','Thursday','Friday'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00\n",
        "            }\n",
        "        },\n",
        "        'CG5': {\n",
        "            'availability': {\n",
        "                'Location': ['Manhattan', 'Brooklyn'],\n",
        "                'start_time': '09:00',\n",
        "                'end_time': '17:00\n",
        "            }\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "# Store the initial state of context\n",
        "initial_context = copy.deepcopy(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fecabdc-9fea-4e71-bf61-ad56c2ee45c2",
      "metadata": {
        "height": 1016,
        "id": "3fecabdc-9fea-4e71-bf61-ad56c2ee45c2"
      },
      "outputs": [],
      "source": [
        "# Prompt for the planning model\n",
        "o1_prompt = \"\"\"\n",
        "You are a scheduling assistant. The first input you will receive will be a complex task that needs to be carefully reasoned through to solve.\n",
        "Your task is to review the challenge, and create a detailed plan to optimally match service providers (caregivers) with service users (patients)\n",
        "while considering cargivers work days and work hours, avoiding double-booking and taking into account the travel travel time between the service location.\n",
        "You may suggest adding new caregivers working hours or locations if you are not able to cover all the sevice requests.\n",
        "\n",
        "You will have access to an LLM agent that is responsible for executing the plan that you create and will return results.\n",
        "\n",
        "The LLM agent has access to the following functions:\n",
        "    - get_address(ID)\n",
        "        - This gets the addresses for service provider and service users\n",
        "    - calculate_travel_time(origin_address, destination_address)\n",
        "        - This function calculate travel time between locations\n",
        "    -add_caregiver(service_location)\n",
        "        - This function adds cargivers to udnerserved location\n",
        "\n",
        "\n",
        "When creating a plan for the LLM to execute, break your instructions into a logical, step-by-step order, using the specified format:\n",
        "    - **Main actions are numbered** (e.g., 1, 2, 3).\n",
        "    - **Sub-actions are lettered** under their relevant main actions (e.g., 1a, 1b).\n",
        "        - **Sub-actions should start on new lines**\n",
        "    - **Specify conditions using clear 'if...then...else' statements** (e.g., 'If the product was purchased within 30 days, then...').\n",
        "    - **For actions that require using one of the above functions defined**, write a step to call a function using backticks for the function name (e.g., `call the get_inventory_status function`).\n",
        "        - Ensure that the proper input arguments are given to the model for instruction. There should not be any ambiguity in the inputs.\n",
        "    - **The last step** in the instructions should always be calling the `instructions_complete` function. This is necessary so we know the LLM has completed all of the instructions you have given it.\n",
        "    - **Detailed steps** The plan generated must be extremely detailed and thorough with explanations at every step.\n",
        "Use markdown format when generating the plan with each step and sub-step.\n",
        "\n",
        "Please find the scenario below.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ff5752-acb0-4bb1-adb3-58ce2ac1133f",
      "metadata": {
        "height": 319,
        "id": "e9ff5752-acb0-4bb1-adb3-58ce2ac1133f"
      },
      "outputs": [],
      "source": [
        "# System prompt for the execution model\n",
        "gpt4o_system_prompt = \"\"\"\n",
        "You are a helpful assistant responsible for executing the policy on handling incoming orders. Your task is to follow the policy exactly as it is written and perform the necessary actions.\n",
        "\n",
        "You must explain your decision-making process across various steps.\n",
        "\n",
        "# Steps\n",
        "\n",
        "1. **Read and Understand Policy**: Carefully read and fully understand the given policy on handling incoming orders.\n",
        "2. **Identify the exact step in the policy**: Determine which step in the policy you are at, and execute the instructions according to the policy.\n",
        "3. **Decision Making**: Briefly explain your actions and why you are performing them.\n",
        "4. **Action Execution**: Perform the actions required by calling any relevant functions and input parameters.\n",
        "\n",
        "POLICY:\n",
        "{policy}\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb08d00-1371-4d86-beb4-56dcd44b8eb1",
      "metadata": {
        "id": "ebb08d00-1371-4d86-beb4-56dcd44b8eb1"
      },
      "source": [
        "#### Describe functions that will be passed to the 4o-mini helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6c37dd-8ec5-4ed7-9cfd-0259867cd4fd",
      "metadata": {
        "height": 4909,
        "id": "fa6c37dd-8ec5-4ed7-9cfd-0259867cd4fd"
      },
      "outputs": [],
      "source": [
        "TOOLS = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_address\",\n",
        "            \"description\": \"Retrives address of caregivers and patients\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unique identifier for the caregiver or patient.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"id\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculate_travel_time\",\n",
        "            \"description\": \"Cacculates travel time between locations\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"origin_address\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location were trip starts.\",\n",
        "                    },\n",
        "                    \"destination_addres\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location were trip ends\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"origina_address\", \"destination_address\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"add_caregiver\",\n",
        "            \"description\": \"Adds caregivers for the underserved locations\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"service_location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location were more caregiers need to be added.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": \"service_location\",\n",
        "                \"additionalProperties\": False,\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ebbecbe-8cbd-4355-bece-d272144149f4",
      "metadata": {
        "id": "2ebbecbe-8cbd-4355-bece-d272144149f4"
      },
      "source": [
        "#### These are the instantiations of the functions the 4o-mini helper will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "130643d7-3043-45b9-baec-a1e37db91c97",
      "metadata": {
        "height": 1866,
        "id": "130643d7-3043-45b9-baec-a1e37db91c97"
      },
      "outputs": [],
      "source": [
        "# Function Definitions\n",
        "def get_inventory_status(product_id):\n",
        "    quantity = context['inventory'].get(product_id, 0)\n",
        "    return {'product_id': product_id, 'quantity': quantity}\n",
        "\n",
        "def get_product_details(product_id):\n",
        "    product = context['products'].get(product_id, {})\n",
        "    return {\"name\": product.get('name', ''), \"components_needed\": product.get(\"components_needed\", {})}\n",
        "\n",
        "def update_inventory(product_id, quantity_change):\n",
        "    if product_id not in context['inventory']:\n",
        "        return {'error': f\"Product ID {product_id} not found in inventory.\"}\n",
        "\n",
        "    new_quantity = context['inventory'][product_id] + int(quantity_change)\n",
        "\n",
        "    if new_quantity < 0:\n",
        "        return {'error': 'Resulting inventory cannot be negative.'}\n",
        "\n",
        "    context['inventory'][product_id] = new_quantity\n",
        "    return {'product_id': product_id, 'new_quantity': new_quantity}\n",
        "\n",
        "def fetch_new_orders():\n",
        "    return context['orders'][0]\n",
        "\n",
        "def allocate_stock(order_id, product_id, quantity):\n",
        "    available = context['inventory'].get(product_id, 0)\n",
        "    if available >= quantity:\n",
        "        context['inventory'][product_id] -= quantity\n",
        "        return {'order_id': order_id, 'allocated_quantity': quantity}\n",
        "    else:\n",
        "        allocated_quantity = available\n",
        "        context['inventory'][product_id] = 0\n",
        "        return {\n",
        "            'order_id': order_id,\n",
        "            'allocated_quantity': allocated_quantity,\n",
        "            'error': 'Insufficient stock'\n",
        "        }\n",
        "\n",
        "def check_available_suppliers():\n",
        "    available_suppliers = context['available_suppliers']\n",
        "    return {\"available_suppliers\": available_suppliers}\n",
        "\n",
        "def get_supplier_info(supplier_id):\n",
        "    supplier = context['suppliers'].get(supplier_id)\n",
        "    if not supplier:\n",
        "        return {'error': f\"Supplier {supplier_id} not found.\"}\n",
        "\n",
        "    components = supplier.get('components', {})\n",
        "    return {'supplier_id': supplier_id, 'components': components}\n",
        "\n",
        "def place_purchase_order(supplier_id, component_id, quantity):\n",
        "    supplier = context['suppliers'].get(supplier_id)\n",
        "    if not supplier:\n",
        "        return {'error': f\"Supplier {supplier_id} not found.\"}\n",
        "    component = supplier['components'].get(component_id)\n",
        "    if not component:\n",
        "        return {'error': f\"Component {component_id} not found with supplier {supplier_id}.\"}\n",
        "    if component['available_quantity'] < quantity:\n",
        "        return {'error': f\"Insufficient component quantity available from supplier {supplier_id}.\"}\n",
        "    component['available_quantity'] -= quantity\n",
        "    po_number = f\"PO_{supplier_id}_{component_id}\"\n",
        "    context['production_capacity']['next_week'] += quantity\n",
        "\n",
        "    return {'po_number': po_number, 'status': 'Placed'}\n",
        "\n",
        "def check_production_capacity(time_frame):\n",
        "    capacity = context['production_capacity'].get(time_frame, 0)\n",
        "    return {'time_frame': time_frame, 'available_capacity': capacity}\n",
        "\n",
        "def schedule_production_run(product_id, quantity, time_frame):\n",
        "    capacity = context['production_capacity'].get(time_frame, 0)\n",
        "    if capacity >= quantity:\n",
        "        context['production_capacity'][time_frame] -= quantity\n",
        "        if time_frame == 'immediate':\n",
        "            context['inventory'][product_id] += quantity\n",
        "        return {'production_id': 'PROD1001', 'status': 'Scheduled', 'time_frame': time_frame}\n",
        "    else:\n",
        "        return {'error': 'Insufficient production capacity, please order more from supplier.'}\n",
        "\n",
        "def calculate_shipping_options(destination, weight, dimensions):\n",
        "    options = context['shipping_options'].get(destination)\n",
        "    if not options:\n",
        "        return {'error': f\"No shipping options available for destination {destination}.\"}\n",
        "    return options\n",
        "\n",
        "def book_shipment(order_id, carrier_id, service_level):\n",
        "    tracking_number = f'TRACK_{order_id}'\n",
        "    return {'tracking_number': tracking_number, 'status': 'Booked'}\n",
        "\n",
        "def send_order_update(customer_id, order_id, message):\n",
        "    return {'customer_id': customer_id, 'order_id': order_id, 'message_sent': True}\n",
        "\n",
        "# Map function names to actual functions\n",
        "function_mapping = {\n",
        "    'get_inventory_status': get_inventory_status,\n",
        "    'get_product_details': get_product_details,\n",
        "    'update_inventory': update_inventory,\n",
        "    'fetch_new_orders': fetch_new_orders,\n",
        "    'allocate_stock': allocate_stock,\n",
        "    'place_purchase_order': place_purchase_order,\n",
        "    'check_available_suppliers': check_available_suppliers,\n",
        "    'get_supplier_info': get_supplier_info,\n",
        "    'check_production_capacity': check_production_capacity,\n",
        "    'schedule_production_run': schedule_production_run,\n",
        "    'calculate_shipping_options': calculate_shipping_options,\n",
        "    'book_shipment': book_shipment,\n",
        "    'send_order_update': send_order_update\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb77482-4a4c-4975-9b70-e1fd03060848",
      "metadata": {
        "id": "dfb77482-4a4c-4975-9b70-e1fd03060848"
      },
      "source": [
        "#### Knit together the process. 1) call o1 to generate a plan, 2) call 4o-mini to execute the plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064c42b6-e79e-4172-b2cf-1f7d5f0d0dd2",
      "metadata": {
        "height": 251,
        "id": "064c42b6-e79e-4172-b2cf-1f7d5f0d0dd2"
      },
      "outputs": [],
      "source": [
        "def process_scenario(scenario):\n",
        "    append_message({'type': 'status', 'message': 'Generating plan...'})\n",
        "\n",
        "    plan = call_o1(scenario)\n",
        "\n",
        "    append_message({'type': 'plan', 'content': plan})\n",
        "\n",
        "    append_message({'type': 'status', 'message': 'Executing plan...'})\n",
        "\n",
        "    messages = call_gpt4o(plan)\n",
        "\n",
        "    append_message({'type': 'status', 'message': 'Processing complete.'})\n",
        "\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae32f60-4526-4607-8bc8-8ad2bd2702bb",
      "metadata": {
        "id": "3ae32f60-4526-4607-8bc8-8ad2bd2702bb"
      },
      "source": [
        "##### Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa04398-ccf6-4f98-b343-b9987d145e9b",
      "metadata": {
        "height": 302,
        "id": "bfa04398-ccf6-4f98-b343-b9987d145e9b"
      },
      "outputs": [],
      "source": [
        "def append_message(message):\n",
        "    message_list.append(message)\n",
        "    # Optionally, print the message for immediate feedback\n",
        "    message_type = message.get('type', '')\n",
        "    if message_type == 'status':\n",
        "        print(message['message'])\n",
        "    elif message_type == 'plan':\n",
        "        print(\"\\nPlan:\\n\", message['content'])\n",
        "    elif message_type == 'assistant':\n",
        "        print(\"\\nAssistant:\\n\", message['content'])\n",
        "    elif message_type == 'function_call':\n",
        "        print(f\"\\nFunction call: {message['function_name']} with arguments {message['arguments']}\")\n",
        "    elif message_type == 'function_response':\n",
        "        print(f\"\\nFunction response for {message['function_name']}: {message['response']}\")\n",
        "    else:\n",
        "        # Handle any other message types or default case\n",
        "        print(message.get('content', ''))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e7dfb7-0be4-4ea3-be3b-74e8fb6d9bce",
      "metadata": {
        "id": "54e7dfb7-0be4-4ea3-be3b-74e8fb6d9bce"
      },
      "source": [
        "#### Calls the planner, o1 model. The response will be the plan that will be provided to the  4o-mini helper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ce25c9-fff0-423e-9fa5-9314e0d0aeba",
      "metadata": {
        "height": 285,
        "id": "71ce25c9-fff0-423e-9fa5-9314e0d0aeba"
      },
      "outputs": [],
      "source": [
        "def call_o1(scenario):\n",
        "    prompt = f\"\"\"\n",
        "{o1_prompt}\n",
        "\n",
        "Scenario:\n",
        "{scenario}\n",
        "\n",
        "Please provide the next steps in your plan.\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=O1_MODEL,\n",
        "        messages=[{'role': 'user', 'content': prompt}]\n",
        "    )\n",
        "    plan = response.choices[0].message.content\n",
        "\n",
        "    return plan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9ffa22-1abb-4591-b785-e6a9b055a893",
      "metadata": {
        "id": "cc9ffa22-1abb-4591-b785-e6a9b055a893"
      },
      "source": [
        "#### Call 4o-mini to execute the plan. This will loop until the plan is complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35531ab2-040b-4fe9-ab1c-0c7dc3cd0974",
      "metadata": {
        "height": 1050,
        "id": "35531ab2-040b-4fe9-ab1c-0c7dc3cd0974"
      },
      "outputs": [],
      "source": [
        "def call_gpt4o(plan):\n",
        "    gpt4o_policy_prompt = gpt4o_system_prompt.replace(\"{policy}\", plan)\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': gpt4o_policy_prompt},\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        response = client.chat.completions.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=messages,\n",
        "            tools=TOOLS,\n",
        "            parallel_tool_calls=False\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message.to_dict()\n",
        "        print(assistant_message)\n",
        "        messages.append(assistant_message)\n",
        "\n",
        "        append_message({'type': 'assistant', 'content': assistant_message.get('content', '')})\n",
        "\n",
        "        if (response.choices[0].message.tool_calls and\n",
        "            response.choices[0].message.tool_calls[0].function.name == 'instructions_complete'):\n",
        "            break\n",
        "\n",
        "        if not response.choices[0].message.tool_calls:\n",
        "            continue\n",
        "\n",
        "        for tool in response.choices[0].message.tool_calls:\n",
        "            tool_id = tool.id\n",
        "            function_name = tool.function.name\n",
        "            input_arguments_str = tool.function.arguments\n",
        "\n",
        "            append_message({'type': 'tool_call', 'function_name': function_name, 'arguments': input_arguments_str})\n",
        "\n",
        "            try:\n",
        "                input_arguments = json.loads(input_arguments_str)\n",
        "            except (ValueError, json.JSONDecodeError):\n",
        "                continue\n",
        "\n",
        "            if function_name in function_mapping:\n",
        "                try:\n",
        "                    function_response = function_mapping[function_name](**input_arguments)\n",
        "                except Exception as e:\n",
        "                    function_response = {'error': str(e)}\n",
        "            else:\n",
        "                function_response = {'error': f\"Function '{function_name}' not implemented.\"}\n",
        "\n",
        "            try:\n",
        "                serialized_output = json.dumps(function_response)\n",
        "            except (TypeError, ValueError):\n",
        "                serialized_output = str(function_response)\n",
        "\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_id,\n",
        "                \"content\": serialized_output\n",
        "            })\n",
        "\n",
        "            append_message({'type': 'tool_response', 'function_name': function_name, 'response': serialized_output})\n",
        "\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9dc480-4a92-4c7b-a17a-e0fcaf5b5414",
      "metadata": {
        "id": "aa9dc480-4a92-4c7b-a17a-e0fcaf5b5414"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc9bae1-9f75-4ae1-98eb-900a501d54b0",
      "metadata": {
        "height": 268,
        "id": "fcc9bae1-9f75-4ae1-98eb-900a501d54b0"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "scenario_text = (\"We need to create a caregiver schedule for a week. \"\n",
        "                 \"Please generate a plan that gets caregivers availability \"\n",
        "                 \"and matches it with the service requests.\\n\\n\"\n",
        "                 \"The plan should consider patient locations\"\n",
        "                 \"and match it with the caregiver working location.\"\n",
        "                 \"The should avoid doublebooking caregivers and\"\n",
        "                 \"and account for travel time between work location.\"\n",
        "                 \"the plan may include a suggestion to add cargivers\"\n",
        "                 \"covering underserved locations\")\n",
        "\n",
        "# Process the scenario\n",
        "messages = process_scenario(scenario_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206ffcf2-8d2d-4220-980f-5367add8843b",
      "metadata": {
        "id": "206ffcf2-8d2d-4220-980f-5367add8843b"
      },
      "source": [
        "#### Print messages\n",
        "<span style=\"color:green;\">Note: Your results may differ from those in the video as the models outputs may change with each run.</span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "839da30a-24dd-44ae-96e9-6a8b5ff04663",
      "metadata": {
        "height": 64,
        "id": "839da30a-24dd-44ae-96e9-6a8b5ff04663"
      },
      "outputs": [],
      "source": [
        "for x in messages:\n",
        "    print(x)\n",
        "    print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41341a9b-9cd9-4481-ad13-fa2dd251982e",
      "metadata": {
        "height": 30,
        "id": "41341a9b-9cd9-4481-ad13-fa2dd251982e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}