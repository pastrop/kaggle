{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "coursera": {
      "schema_names": [
        "GANSC1-2A"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1czVdIlqnImH"
      },
      "source": [
        "# Deep Convolutional GAN (DCGAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KD3ZgLs80vY"
      },
      "source": [
        "\n",
        "*Underlying research: [here](https://arxiv.org/pdf/1511.06434v1.pdf) is the paper that first described this network*\n",
        "\n",
        "Figure: Architectural drawing of a generator from DCGAN from [Radford et al (2016)](https://arxiv.org/pdf/1511.06434v1.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8DDM6l9rZb"
      },
      "source": [
        "\n",
        "**DCGAN Main Features:**\n",
        "\n",
        "*   Use convolutions without any pooling layers\n",
        "*   Use batchnorm in both the generator and the discriminator\n",
        "*   Don't use fully connected hidden layers\n",
        "*   Use ReLU activation in the generator for all layers except for the output, which uses a Tanh activation.\n",
        "*   Use LeakyReLU activation in the discriminator for all layers except for the output, which does not use an activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfkorNJrnmNO"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
        "\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3RFpQuM_7rL"
      },
      "source": [
        "# torch device check:\n",
        "print(torch.cuda.current_device())\n",
        "\n",
        "print(torch.cuda.device(0))\n",
        "\n",
        "print(torch.cuda.device_count())\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1A1M6kpnfxw"
      },
      "source": [
        "## Generator\n",
        "4 layers (3 hidden layers + 1 output layer). \n",
        "<!-- From the paper, we know to \"[u]se batchnorm in both the generator and the discriminator\" and \"[u]se ReLU activation in generator for all layers except for the output, which uses Tanh.\" --> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvO7h0LYnEJZ"
      },
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    '''\n",
        "    Generator Class\n",
        "    Values:\n",
        "        z_dim: the dimension of the noise vector, a scalar\n",
        "        im_chan: the number of channels in the images, fitted for the dataset used, a scalar\n",
        "              (MNIST is black-and-white, so 1 channel is your default)\n",
        "        hidden_dim: the inner dimension, a scalar\n",
        "    '''\n",
        "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
        "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
        "        '''\n",
        "        Function to return a sequence of operations corresponding to a generator block of DCGAN, \n",
        "        corresponding to a transposed convolution, a batchnorm (except for in the last layer), and an activation.\n",
        "        Parameters:\n",
        "            input_channels: how many channels the input feature representation has\n",
        "            output_channels: how many channels the output feature representation should have\n",
        "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
        "            stride: the stride of the convolution\n",
        "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
        "                      (affects activation and batchnorm)\n",
        "        '''\n",
        "\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                torch.nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "        else: # Final Layer\n",
        "            return nn.Sequential(\n",
        "                torch.nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.Tanh()                \n",
        "            )\n",
        "\n",
        "    def unsqueeze_noise(self, noise):\n",
        "        '''\n",
        "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
        "        returns a copy of that noise with width and height = 1 and channels = z_dim.\n",
        "        Parameters:\n",
        "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
        "        '''\n",
        "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        '''\n",
        "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
        "        returns generated images.\n",
        "        Parameters:\n",
        "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
        "        '''\n",
        "        x = self.unsqueeze_noise(noise)\n",
        "        return self.gen(x)\n",
        "\n",
        "def get_noise(n_samples, z_dim, device='cpu'):\n",
        "    '''\n",
        "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n",
        "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
        "    Parameters:\n",
        "        n_samples: the number of samples to generate, a scalar\n",
        "        z_dim: the dimension of the noise vector, a scalar\n",
        "        device: the device type\n",
        "    '''\n",
        "    return torch.randn(n_samples, z_dim, device=device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnOVbTpzW2M"
      },
      "source": [
        "Here's the test for your generator block:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA4AxGnmpuPq"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    '''\n",
        "    Discriminator Class\n",
        "    Values:\n",
        "        im_chan: the number of channels in the images, fitted for the dataset used, a scalar\n",
        "              (MNIST is black-and-white, so 1 channel is your default)\n",
        "    hidden_dim: the inner dimension, a scalar\n",
        "    '''\n",
        "    def __init__(self, im_chan=1, hidden_dim=16):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self.make_disc_block(im_chan, hidden_dim),\n",
        "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
        "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
        "        '''\n",
        "        Function to return a sequence of operations corresponding to a discriminator block of DCGAN, \n",
        "        corresponding to a convolution, a batchnorm (except for in the last layer), and an activation.\n",
        "        Parameters:\n",
        "            input_channels: how many channels the input feature representation has\n",
        "            output_channels: how many channels the output feature representation should have\n",
        "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
        "            stride: the stride of the convolution\n",
        "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
        "                      (affects activation and batchnorm)\n",
        "        '''\n",
        "\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                torch.nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2)                          \n",
        "            )\n",
        "        else: # Final Layer\n",
        "            return nn.Sequential(\n",
        "                torch.nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
        "            )\n",
        "\n",
        "    def forward(self, image):\n",
        "        '''\n",
        "        Function for completing a forward pass of the discriminator: Given an image tensor, \n",
        "        returns a 1-dimension tensor representing fake/real.\n",
        "        Parameters:\n",
        "            image: a flattened image tensor with dimension (im_dim)\n",
        "        '''\n",
        "        disc_pred = self.disc(image)\n",
        "        return disc_pred.view(len(disc_pred), -1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsOvZwjIzQ0F"
      },
      "source": [
        "Here's a test for your discriminator block:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRk_8azSq3tF"
      },
      "source": [
        "## Training\n",
        "Parameters:\n",
        "  *   criterion: the loss function\n",
        "  *   n_epochs: the number of times you iterate through the entire dataset when training\n",
        "  *   z_dim: the dimension of the noise vector\n",
        "  *   display_step: how often to display/visualize the images\n",
        "  *   batch_size: the number of images per forward/backward pass\n",
        "  *   lr: the learning rate\n",
        "  *   beta_1, beta_2: the momentum term\n",
        "  *   device: the device type\n",
        "\n",
        "In addition, be warned that **this runs very slowly on the default CPU**. One way to run this more quickly is to download the .ipynb and upload it to Google Drive, then open it with Google Colab, click on `Runtime -> Change runtime type` and set hardware accelerator to GPU and replace\n",
        "`device = \"cpu\"`\n",
        "with\n",
        "`device = \"cuda\"`. The code should then run without any more changes, over 1,000 times faster. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFLQ039u-qdu"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "z_dim = 64\n",
        "display_step = 500\n",
        "batch_size = 128\n",
        "# A learning rate of 0.0002 works well on DCGAN\n",
        "lr = 0.0002\n",
        "\n",
        "# These parameters control the optimizer's momentum, which you can read more about here:\n",
        "# https://distill.pub/2017/momentum/ \n",
        "beta_1 = 0.5 \n",
        "beta_2 = 0.999\n",
        "device = 'cuda'\n",
        "\n",
        "# Tranform the image values to be between -1 and 1 (the range of the tanh activation)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    MNIST('.', download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a2V7qzknWqh"
      },
      "source": [
        "Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDFRZ8tg_Y57"
      },
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "disc = Discriminator().to(device) \n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "\n",
        "# Weights are initialized to the normal distribution\n",
        "# with mean 0 and standard deviation 0.02\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "gen = gen.apply(weights_init)\n",
        "disc = disc.apply(weights_init)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFMIcRVeUa9",
        "outputId": "ef5b6bc2-8d3e-4a4a-a201-4ca931e9cf57"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iCTg3w4_Zw6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5dhXMXLvt7l"
      },
      "source": [
        "Here's roughly the progression you should be expecting. On GPU this takes about 30 seconds per thousand steps. On CPU, this can take about 8 hours per thousand steps. You might notice that in the image of Step 5000, the generator is disproprotionately producing things that look like ones. If the discriminator didn't learn to detect this imbalance quickly enough, then the generator could just produce more ones. As a result, it may have ended up tricking the discriminator so well that there would be no more improvement, known as mode collapse: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXptQZcwrBrq"
      },
      "source": [
        "n_epochs = 20\n",
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "for epoch in range(n_epochs):\n",
        "    # Dataloader returns the batches\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_batch_size = len(real)\n",
        "        real = real.to(device)\n",
        "\n",
        "        ## Update discriminator ##\n",
        "        disc_opt.zero_grad()\n",
        "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
        "        fake = gen(fake_noise)\n",
        "        disc_fake_pred = disc(fake.detach())\n",
        "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "        disc_real_pred = disc(real)\n",
        "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
        "\n",
        "        # Keep track of the average discriminator loss\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "        # Update gradients\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "        # Update optimizer\n",
        "        disc_opt.step()\n",
        "\n",
        "        ## Update generator ##\n",
        "        gen_opt.zero_grad()\n",
        "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
        "        fake_2 = gen(fake_noise_2)\n",
        "        disc_fake_pred = disc(fake_2)\n",
        "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        # Keep track of the average generator loss\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "\n",
        "        ## Visualization code ##\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            show_tensor_images(fake)\n",
        "            show_tensor_images(real)\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDjslqvjhNmr"
      },
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAao-IgRmtcv"
      },
      "source": [
        "# Test Block 1 \n",
        "'''\n",
        "Test your make_gen_block() function\n",
        "'''\n",
        "gen = Generator()\n",
        "num_test = 100\n",
        "\n",
        "# Test the hidden block\n",
        "test_hidden_noise = get_noise(num_test, gen.z_dim)\n",
        "test_hidden_block = gen.make_gen_block(10, 20, kernel_size=4, stride=1)\n",
        "test_uns_noise = gen.unsqueeze_noise(test_hidden_noise)\n",
        "hidden_output = test_hidden_block(test_uns_noise)\n",
        "\n",
        "# Check that it works with other strides\n",
        "test_hidden_block_stride = gen.make_gen_block(20, 20, kernel_size=4, stride=2)\n",
        "\n",
        "test_final_noise = get_noise(num_test, gen.z_dim) * 20\n",
        "test_final_block = gen.make_gen_block(10, 20, final_layer=True)\n",
        "test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)\n",
        "final_output = test_final_block(test_final_uns_noise)\n",
        "\n",
        "# Test the whole thing:\n",
        "test_gen_noise = get_noise(num_test, gen.z_dim)\n",
        "test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)\n",
        "gen_output = gen(test_uns_gen_noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osbCUvkWk_LI",
        "outputId": "6d7e4fa9-fec4-4923-8e1e-ef88b428089c"
      },
      "source": [
        "# Test Block 2 \n",
        "# UNIT TESTS\n",
        "assert tuple(hidden_output.shape) == (num_test, 20, 4, 4)\n",
        "assert hidden_output.max() > 1\n",
        "assert hidden_output.min() == 0\n",
        "assert hidden_output.std() > 0.2\n",
        "assert hidden_output.std() < 1\n",
        "assert hidden_output.std() > 0.5\n",
        "\n",
        "assert tuple(test_hidden_block_stride(hidden_output).shape) == (num_test, 20, 10, 10)\n",
        "assert final_output.max().item() == 1.0\n",
        "assert final_output.min().item() == -1.0\n",
        "\n",
        "assert tuple(gen_output.shape) == (num_test, 1, 28, 28)\n",
        "assert gen_output.std() > 0.5\n",
        "assert gen_output.std() < 0.8\n",
        "print(\"Success!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly3BwSfmmtc3"
      },
      "source": [
        "#Test Block 4\n",
        "'''\n",
        "Test your make_disc_block() function\n",
        "'''\n",
        "num_test = 100\n",
        "\n",
        "gen = Generator()\n",
        "disc = Discriminator()\n",
        "test_images = gen(get_noise(num_test, gen.z_dim))\n",
        "\n",
        "# Test the hidden block\n",
        "test_hidden_block = disc.make_disc_block(1, 5, kernel_size=6, stride=3)\n",
        "hidden_output = test_hidden_block(test_images)\n",
        "\n",
        "# Test the final block\n",
        "test_final_block = disc.make_disc_block(1, 10, kernel_size=2, stride=5, final_layer=True)\n",
        "final_output = test_final_block(test_images)\n",
        "\n",
        "# Test the whole thing:\n",
        "disc_output = disc(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GemvBkChn0_k",
        "outputId": "34111ddb-d8b5-4f26-c1a7-cf79048258b0"
      },
      "source": [
        "#Test Block 5\n",
        "# Test the hidden block\n",
        "\n",
        "assert tuple(hidden_output.shape) == (num_test, 5, 8, 8)\n",
        "# Because of the LeakyReLU slope\n",
        "assert -hidden_output.min() / hidden_output.max() > 0.15\n",
        "assert -hidden_output.min() / hidden_output.max() < 0.25\n",
        "assert hidden_output.std() > 0.5\n",
        "assert hidden_output.std() < 1\n",
        "\n",
        "# Test the final block\n",
        "\n",
        "assert tuple(final_output.shape) == (num_test, 10, 6, 6)\n",
        "assert final_output.max() > 1.0\n",
        "assert final_output.min() < -1.0\n",
        "assert final_output.std() > 0.3\n",
        "assert final_output.std() < 0.6\n",
        "\n",
        "# Test the whole thing:\n",
        "\n",
        "assert tuple(disc_output.shape) == (num_test, 1)\n",
        "assert disc_output.std() > 0.25\n",
        "assert disc_output.std() < 0.5\n",
        "print(\"Success!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}