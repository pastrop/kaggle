{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fraud_dection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA1KR7Y1EKRCQUntEwe1Yc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/fraud_dection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNk3udGiC603",
        "colab_type": "text"
      },
      "source": [
        "# Fraud Detection Notebook Using Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC88aAXhC50o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use seaborn for the correlation heatmap\n",
        "!pip install seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbVATTXoCo84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Datetime related libraries\n",
        "import time\n",
        "import datetime\n",
        "import dateutil.parser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_RTfm4yDN62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file upload while using Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXgtvBaEDOow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzipping if needed\n",
        "!unzip creditcard.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff92NmwjDT7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('file_name')\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00JFm5IqDojk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_shape = df_model1.shape\n",
        "print(data_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKnmF1XDwY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unknown_count = df_model1.isna().sum().drop_duplicates()\n",
        "unknown_count[unknown_count>0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYq3wf0DEO0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Correlation Analysis - NEEDS REFACTORING\n",
        "# Parameters\n",
        "THRESHOLD = 0.7 # Correlation Coefficient Threshold of Interest\n",
        "#printing formats\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Sample to calculate correlations (using filtered set of column, run exlusion calculation first)\n",
        "#df_model1_sample = measurements_filtered.sample(frac=0.3, random_state=42)\n",
        "df_model1_sample = measurements_for_corr.sample(frac=0.3, random_state=42)\n",
        "\n",
        "#SECTION TO REFACTOR\n",
        "#geo exclusions - filter out lat/long/zipcode \n",
        "column_list = list(df_model1_sample.columns)\n",
        "column_geo_include=[]\n",
        "for column in column_list:\n",
        "  if column.find('longitude') == -1 and column.find('latitude') == -1 and column.find('zipcode') == -1:\n",
        "    column_geo_include.append(column)\n",
        "\n",
        "#List of columns after fitering numeric geo columns out\n",
        "df_model1_sample_filtered = df_model1_sample.filter(column_geo_include).columns\n",
        "#END OF SECTION TO REFACTORls\n",
        "print('columns to correlate')\n",
        "print(df_model1_sample_filtered)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Correlations, positive and negative. Round to 2 decimals and filling NaN with O\n",
        "df_model1_corr = round(df_model1_sample.filter(column_geo_include).corr(),6).fillna(0)\n",
        "\n",
        "print(\"CORRELATION MATRIX\")\n",
        "print(df_model1_corr)\n",
        "\n",
        "n_columns = df_model1_corr.shape[1]\n",
        "column_list = list(df_model1_corr.columns)\n",
        "\n",
        "#Upper triangle matrix of correlation coefficients\n",
        "corr_matrix = df_model1_corr.values\n",
        "triu_corr_matrix = np.triu(corr_matrix, k=1)\n",
        "\n",
        "#printing technical data that is used in follow-up calculations or/and troubleshooting\n",
        "print(\"TRIANGILATED CORRELATION MATRIX\")\n",
        "print(triu_corr_matrix)\n",
        "\n",
        "#Selecting corr coeff within the range of interest\n",
        "i=0\n",
        "corr_ranking=[] # initializing array of highly correlated pairs\n",
        "for i in range(n_columns):\n",
        "  for j in range(i):\n",
        "    if abs(triu_corr_matrix[j][i]) > THRESHOLD and abs(triu_corr_matrix[j][i]) <= 1:\n",
        "      temp=triu_corr_matrix[j][i],column_list[i], column_list[j]\n",
        "      corr_ranking.append(temp)\n",
        "\n",
        "#Ranked Correlation Coeff Array - High to Low\n",
        "corr_ranking.sort(reverse=True)\n",
        "print(\"ranked correlation array\")\n",
        "print(corr_ranking)\n",
        "\n",
        "#Selecting least correlated columns\n",
        "l=0\n",
        "corr_ranking_smallest=[] #initializing array of least correlated pairs\n",
        "for l in range(n_columns):\n",
        "  for k in range(l):\n",
        "    if abs(triu_corr_matrix[k][l]) < THRESHOLD and abs(triu_corr_matrix[k][l]) >= 0:\n",
        "      temp=triu_corr_matrix[k][l],column_list[l], column_list[k]\n",
        "      corr_ranking_smallest.append(temp)\n",
        "sorted(corr_ranking_smallest,key=lambda item: abs(item[0]))\n",
        "if len(corr_ranking_smallest) == 0:\n",
        "  corr_ranking_smallest = corr_ranking[:]\n",
        "\n",
        "#printing technical data that is used in follow-up calculations or/and troubleshooting\n",
        "print(\"most uncorrelated\")\n",
        "print(corr_ranking_smallest)\n",
        "\n",
        "#Select top 10 correlated set by absolute value of the correlation coefficient\n",
        "top_10_corr = [(abs(item[0]),item[1],item[2]) for item in corr_ranking]\n",
        "\n",
        "#printing technical data that is used in follow-up calculations or/and troubleshooting\n",
        "print(\"top 10 coeff by value - {}\".format(top_10_corr))  \n",
        "print(\"Running time in seconds =\", time.time() - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YWEomu5EY2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # Correlation plot related parameters calculation\n",
        "    col_corr = [] # Set of all the names of highly correlated columns\n",
        "    for i in range(len(df_model1_corr.columns)):\n",
        "        for j in range(len(df_model1_corr.columns)):\n",
        "            if (abs(df_model1_corr.iloc[j, i]) > 0.5) and (abs(df_model1_corr.iloc[j, i]) < 0.9) and (df_model1_corr.columns[i] not in col_corr) and i != j:\n",
        "                colname = df_model1_corr.columns[i] # getting the name of column\n",
        "                col_corr.append(colname)\n",
        "    print(col_corr)\n",
        "    top_ten_set = set()\n",
        "    for item in top_10_corr:\n",
        "      for i in range(1,len(item)):\n",
        "        top_ten_set.add(item[i])\n",
        "    print(\"top_ten_set: {}\".format(top_ten_set))\n",
        "    if len(top_ten_set)>0:\n",
        "      df_model1_filtered = df_model1.filter(top_ten_set)\n",
        "    else:\n",
        "      df_model1_filtered=df_model1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqhB1eDxEZ9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HeatMap Using Seaborn\n",
        "sns.set()\n",
        "# this scales up all text, but does not affect annot (see annot_kws={'size':1.4})\n",
        "sns.set(font_scale=1.4)\n",
        "# compute the correlation matrix\n",
        "corr = df_model1_filtered.corr()\n",
        "fig = plt.subplots(figsize=(15,15))\n",
        "cmap = sns.diverging_palette(0, 359, as_cmap=True)\n",
        "# annot controls the correlation values display, bizarre shrink-value properly scales the colorbar \n",
        "ax = sns.heatmap(corr, square=True, cbar_kws={'shrink': 0.82}, annot=True, annot_kws={'size': 14})\n",
        "# take care of the labels printing\n",
        "labels_list = df_model1_filtered.columns\n",
        "# this centers and prints horizontally the y labels\n",
        "ax.set_yticklabels(labels_list, rotation=0, va='center')\n",
        "# this rotates the x labels\n",
        "ax.set_xticklabels(labels_list, rotation=45, va='top')\n",
        "ax.collections[0].colorbar.set_label('Absolute value of the correlation', rotation=-90, va='bottom')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}