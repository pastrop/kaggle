{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keyword_extraction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgJjTnc4FFPNNeJhBsKyXt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/keyword_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUtWcvNzaA3N"
      },
      "source": [
        "from gensim.summarization import keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "NbTErYdlfXN4",
        "outputId": "e323234d-e2ea-4e8c-9faa-e02833d0160d"
      },
      "source": [
        "# file upload while using Google Colab\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd0bc19b-e875-4f3d-bc9c-e794bf542810\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd0bc19b-e875-4f3d-bc9c-e794bf542810\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.txt to data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUf-Rlh4aZkH"
      },
      "source": [
        "with open('data.txt', 'r',encoding='utf-8-sig') as file:\r\n",
        "    data = file.read().replace('\\n', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma84fbBTfp--"
      },
      "source": [
        "kwrds = keywords(data).split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwrIU-vtgFvH",
        "outputId": "609fafcc-149b-4d74-f8b7-965eac00b834"
      },
      "source": [
        "kwrds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['learn',\n",
              " 'learning',\n",
              " 'learned',\n",
              " 'learns',\n",
              " 'models',\n",
              " 'model',\n",
              " 'modeling',\n",
              " 'modelling',\n",
              " 'data',\n",
              " 'graph']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlVco4fEiNg1"
      },
      "source": [
        "data_lst = data.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoHbBYnOkFtv",
        "outputId": "b6b5a3f1-5275-4f1e-cf17-554fcfa995ca"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MapITtfBlV_Z"
      },
      "source": [
        "#lemmatized tokens\r\n",
        "tokenization = nltk.word_tokenize(data)\r\n",
        "tokens = []\r\n",
        "for w in tokenization:\r\n",
        "   tokens.append(wordnet_lemmatizer.lemmatize(w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJhzI4qsmrAH"
      },
      "source": [
        "# stems\r\n",
        "porter_stemmer  = PorterStemmer()\r\n",
        "stems = []\r\n",
        "for w in tokenization:\r\n",
        "  stems.append(porter_stemmer.stem(w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFinFk_57ycF"
      },
      "source": [
        "# remove punctuation from each word\r\n",
        "import string\r\n",
        "table = str.maketrans('', '', string.punctuation)\r\n",
        "stripped = [w.translate(table) for w in tokens]\r\n",
        "#print(stripped[:100])\r\n",
        "\r\n",
        "# convert to lower case\r\n",
        "tokens = [word.lower() for word in tokens]\r\n",
        "\r\n",
        "#exlude stop words\r\n",
        "stop_words = stopwords.words('english')\r\n",
        "tokens = [w for w in tokens if not w in stop_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbyGmx5WonO6"
      },
      "source": [
        "# back to from list to string for keywords extraction\r\n",
        "data1 = ' '.join(tokens)\r\n",
        "tok = keywords(data1).split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "Ke8boyvXp-VR",
        "outputId": "87a3a402-7069-48b9-a305-cda3363c5d57"
      },
      "source": [
        "data1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"interesting paper read neurips2020 zichen wang zichen wangdec 28 , 2020·8 min read image post image post vancouver ( photo julius jansson unsplash ) year ’ neurips conference wa hosted online . lot recorded content , including keynote talk , tutorial workshop available virtual site . highly recommend check amazing content catch latest ml/ai . post share note paper found interesting . list mean unbiased selection exhaustive browsing 1,918 accepted papers.1 . neural networks learn trained random labels ? [ paper ] [ presentation ] paper study intriguing phenomenon over-parameterized deep neural network ( dnns ) trained randomly labeled image speed subsequent learning either real random label new image , wa first described study . author aim study exactly wa learned neural net trained random label dissecting dnn layer layer.the short answer question : dnn learns align covariance weight matrix first layer covariance matrix data.the author started theoretical analysis proving , random normal initialization sgd training , first layer dnn learns align covariance matrix weight covariance matrix data ( drawn i.i.d . centered gaussian ) . next , experimentally showed covariance alignment dnn weight data also happens real image data random label . interestingly , author found eigenvectors convolution filter learned dnn match data eigenvectors , individually combination . image post image post figure maennel et al . http : //arxiv.org/abs/2006.10455next , author demonstrated covariance alignment explain positive transfer effect showing dnn weight randomly sampled another dnn pretrained random label performs almost identically transfer learning tasks.in conclusion , dnn trained random label learns align weight data covariance alignment help dnn learns faster downstream tasks.2 . implicit rank-minimizing autoencoder ( irmae ) [ paper ] [ presentation ] [ code ] regularization pivotal learning useful representation data using autoencoders . without regularization , autoencoders would typically learn identity function mapping input reconstruction . popular regularization mechanism aes include adding noise input ( denoising ae ) enforcing gaussian distribution representation space ( vae ) .in study , author applied fairly novel regularization mechanism ae : inserting bunch linear layer dimension encoder decoder , ae automatically learn low rank representation . “ implicit regularization ” state gradient descent linear matrix lead low rank solution , ha shown useful matrix factorization , linear regression logistic regression . arora et al . ( 2019 ) post developed theoretical understanding type regularization.during training , linear layer encourage learned latent code low rank . author ’ empirical study show irmae outperforms vanilla ae vae generating new image learned representation improves downstream classification task mnist celeba datasets . ablation study also demonstrated non-linear activation essential linear layer amplify regularization effect.3 . graph random neural networks semi-supervised learning graphs [ paper ] [ presentation ] [ code ] one favorite topic ai/ml research graph neural network ( gnn ) . paper , author studied semi-supervised learning graph , important application gnn . goal semi-supervised learning classify unlabeled node using feature vector node well entire connectivity pattern graph . many existing gnn fuckingmodel suffer following limitation : * over-smoothing , make learned node representation indistinguishable layer graph message-passing convolution . * poor robustness : message-passing gnns deterministic , make highly dependent local graph topology le robust adversarial attack . * weak generalization : semi-supervised learning labeled node scarce inherent challenge.the main ingredient graph random neural networks ( grand ) introduced study are:1 . random propagation : data augmentation strategy designed graph . work applying dropout node feature training . author described two specific way dropout node feature vector : 1 ) randomly setting element feature vector 0 ; 2 ) setting entire feature vector 0 ’ node . strategy 2 also referred dropnode , performs empirically better dropout.2 . consistency regularization : ensures prediction different augmented graph “ close ” ( adapted “ sharpening ” trick mixmatch ) next , author demonstrated grand outperforms recent gnn baseline cora , citeseer pubmed semi-supervised node classification task . moreover , author experimentally illustrated grand robust perturbation graph compared gcn gat . over-smoothing issue also eliminated showing deeper gnn layer ( 10 ) doe diminish classification accuracy.4 . design space graph neural networks [ paper ] [ presentation ] [ code ] large-scale systematic review surveyed many gnn architecture designed choice evaluated various task . rapidly expanding research area gnn , type study immensely useful researcher practitioners.design space gnns:1 . intra-layer design , concerned next hidden layer computed current layer.2 . inter-layer design , specifies layer connected ( e.g . whether skip connection exist ) number pre- post-processing mlp layers.3 . training configs : batch size , epoch , learning rate , optimizer . image post image post design space task space gnn et al . http : //arxiv.org/abs/2011.08843task spacethe implementation task space quite innovative : author aim design task similarity metric quantifying similarity performance gnns rather task taxonomy . word , specific design gnn fuckingmodel would perform similarly highly similar task . achieve , author first choose diverse set gnn fuckingmodel anchor , rank performance set task . next , kendall ’ rank correlation coefficient wa used calculate task similarity score across vector performance metric anchor fuckingmodel.key result : gnn design space task space defined , author next evaluated parameter value within design space using controlled random search , exhaustive grid search impossible ~10m parameter combination . key result include : batch norm generally helpful , parametric relu ( prelu ) outperforms activation function , aggregation node signal sum outperforms average max.5 . deep structural causal models tractable counterfactual inference [ paper ] [ presentation ] [ code ] know correlation causation . dl fuckingmodel exploit correlation feature label , albeit useful prediction , susceptible adversarial attack . recently , causal inference method integrated dl research . paper example.some preliminary causal inference necessary understand paper : judea pearl 's ladder causation state three level problem increasing difficulty:1. association : describes relationship observational data using marginal , joint conditional probabilities.2 . intervention : requires interaction system knowledge beyond observation . ( operates population level ) 3. counterfactuals : deal retrospective hypothetical scenario . ( query individual level noise variable kept identical ) structural causal models ( scm ) : essentially directed acyclic graph ( dag ) representing causal relationship among variable , cause pointing effects.the main contribution paper integration deep mechanism scm : author proposed three mechanism employing normalizing flow variational inference . normalizing flow fuckingmodel complex probability distribution using transformation simpler base distribution dimensionality , also allow invertible transformations.the author first experimented dscm fuckingmodel morpho-mnist dataset , variant mnist dataset synthetic causal generation process , including thickness intensity , two endogenous variable , influence appearance digit . scm morpho-mnist allows author obtain ground truth sample intervention counterfactual query perturbing thickness intensity variable . image post image post figure pawlowski et al.the author show dscm fuckingmodel ( full ) able recover data distribution intervention , whereas conditional fuckingmodel without correct scm unable , capturing marginal distribution.the author next applied dscm framework brain mri imaging dataset uk biobank . causal graph fuckingmodel resultant brain mri scan age , sex , brain volume ventricle volume upstream cause , able produce counterfactual query presumably realistic-looking mri image . image post image post figure pawlowski et al.6 . spectral temporal graph neural network multivariate time-series forecasting [ paper ] [ presentation ] paper focus forecasting multivariate time-series data , crucial many real-world application , predicting traffic multiple location , fuckingmodeling signal multiple sensor , forecasting price multiple financial instrument . author argue key consideration desirable fuckingmodel capacity consider intra-series temporal correlation inter-series correlation simultaneously.the author developed spectral temporal graph neural network ( stemgnn ) , specialized gnn architecture forecasting multivariate time-series data . key advance stemgnn use graph neural net fuckingmodel multivariate time-series data multivariate temporal graph . node graph univariate time-series , whereas edge represent inter-series correlation , learned data . image post image post figure cao et al.stemgnn includes following component : latent correlation layer : used learning graph structure among multivariate time-series self-attention mechanism : learned matrix self-attention score ( w = softmax ( qk^t/sqrt ( ) ) ) used adjacency matrix graph , q , k corresponds query key matrix size embedding.stemgnn block ha lot going inside : * graph fourier transform ( gft ) : transforms graph g spectral matrix representation multiplying eigenvectors normalized graph laplacian . * spectral sequential cell ( spe-seq cell ) contains discrete fourier transform ( dft ) , transforms univariate time-series frequency domain ; followed 1d convolution glu learn feature representation frequency domain ; , us inverse dft transform univariate time-series frequency domain back temporal domain . * inverse gft : applies spectral representation obtain final representationthe stemgnn block also split two head make prediction future time step ( forecast ) previous time step ( backcast ) , purpose supervised prediction regularization , respectively.next , author evaluated forecast performance stemgnn competing fuckingmodel 9 public multivariate time-series datasets , demonstrate stemgnn beat fuckingmodel almost datasets . author also performed ablation study show component stemgnn essential superior performance.written byzichen wangscientist biomedical informatics . passionate deep shallow machine learning.follow46sign daily pickby towards data sciencehands-on real-world example , research , tutorial , cutting-edge technique delivered monday thursday . make learning daily ritual . take lookget newsletteremails sent pastrop2003 @ gmail.com.not ? 46 * machine learning* deep learning* artificial intelligence* researchmore towards data sciencefollowa medium publication sharing concept , idea , codes.rashida nasrin sucky·dec 28 , 2020 image post image post photo alice pollet unsplasha collection advanced data visualization matplotlib seabornmake storytelling interestingpython ha data visualization library . arguably matplotlib popular widely used library . several tutorial article matplotlib . article focus advanced visualization technique . plot chart provide extra tool make report presentation data efficient interesting way.i assuming already learned basic plot chart matplotlib . need refresher , please go article first : everyday cheatsheet python ’ matplotliba complete visualization coursetowardsdatascience.comi use several different datasets article different kind plot work different type data . try stick dataset much . …read · 7 min read2092________________mahbubul alam·dec 28 , 2020 image post image post photo carolina sánchez unsplashavoid overfitting regularizationl1 l2 regularization lasso , ridge & elasticnet regressionyou alone hard time understanding exactly regularization work . regularization confusing term ’ attempting clear article.in article ’ three thing : ( ) define problem want tackle regularization ; ( b ) examine exactly regularization help ; finally ( c ) explain regularization work action.what problem ? data scientist take great care fuckingmodeling process make sure fuckingmodel work well neither under- overfit.let ’ say want predict house price based feature . start one feature , floor area , build first regression fuckingmodel . …read · 6 min read531________________günter röhrich·dec 28 , 2020data classification algorithms— supervised machine learning bestsupervised machine learning algorithm around quite time , re-emergence ai hype , moved focus became centerpiece various analytics method . interesting question , one use ? article cover several idea behind classification method like support vector machine fuckingmodel , knn , tree-based fuckingmodel ( cart , random forest ) binary classification sigmoid logistic regression . purpose article guide essential idea behind topic support general understanding.supervised , unsupervised reinforcement learning ? terminology break : many source find good example explanation distinguish learning method , recap aspect . post supervised algorithm , hence algorithm know given set possible output parameter , e.g . class , class b , class c. word , type learning map input value expected output . …read · 14 min read581________________andrew hetherington·dec 28 , 2020continuous mortality investigation : another year , another model parametergreater flexibility — opportunity get wrong ? image post image post photo immo wegmann unsplasha riddle you.it ’ 2020 . wake , pour bowl cornflakes ( milk first , cereal second — obviously ) check news . go garden lock shed note door saying come get ’ . ? answered “ literally anyone ” would probably correct . however , answered “ actuary charge fuckingmodelling projecting future improvement mortality ” get extra brownie point . …read · 4 min read1________________renato boemer·dec 28 , 2020data visualization : choose colours wiselymaking data science inclusive colour blind professional taking data visualization skill next level . image post image post photo robert katzki unsplashas data scientist business corporate environment , goal make work easy understand visually appealing , especially non-data professional . graphs colour , therefore , play crucial role communicating insight business executive . , make sure everyone room understand work.colour blindness genetic condition make difficult distinguish specific colour , usually red green . colour blindness affect approximately 1 12 men ( 8 % ) [ 1 ] . mean uk , 5.6 million colour blind individual . globally , colour blindness affect approximately 300 million people , roughly entire population united states . …read · 5 min read11________________read towards data scienceabouthelplegal\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6dOLDghpEyw",
        "outputId": "98e52d34-e9db-4512-844a-bfeddcaf4d04"
      },
      "source": [
        "tok[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['learning',\n",
              " 'learned',\n",
              " 'data',\n",
              " 'model',\n",
              " 'modeling',\n",
              " 'modelling',\n",
              " 'graph',\n",
              " 'graphs',\n",
              " 'author',\n",
              " 'regularization']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    }
  ]
}