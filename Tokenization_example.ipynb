{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEg7U/YUz4gi/6+JuoHITf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/Tokenization_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ZpDBftJbO8"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import(TreebankWordTokenizer,\n",
        "                          TweetTokenizer,\n",
        "                          MWETokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INJI5NxvJdi0",
        "outputId": "ca32e83e-42f0-4b93-bf05-05a729508f7e"
      },
      "source": [
        "#Create tokenizers:\n",
        "tree = TreebankWordTokenizer()\n",
        "tweet = TweetTokenizer()\n",
        "mwe = MWETokenizer()\n",
        "\n",
        "# Create a string input\n",
        "sent1 = 'There are more things in heaven and earth, Horatio, than are dreamt of in your philosophy'\n",
        "     \n",
        "# Use tokenize method\n",
        "print(f'Treebank -> {tree.tokenize(sent1)}')\n",
        "print(f'Tweettokenizer -> {tweet.tokenize(sent1)}')\n",
        "print(f'MWEtokenizer -> {mwe.tokenize(sent1)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treebank -> ['There', 'are', 'more', 'things', 'in', 'heaven', 'and', 'earth', ',', 'Horatio', ',', 'than', 'are', 'dreamt', 'of', 'in', 'your', 'philosophy']\n",
            "Tweettokenizer -> ['There', 'are', 'more', 'things', 'in', 'heaven', 'and', 'earth', ',', 'Horatio', ',', 'than', 'are', 'dreamt', 'of', 'in', 'your', 'philosophy']\n",
            "MWEtokenizer -> ['T', 'h', 'e', 'r', 'e', ' ', 'a', 'r', 'e', ' ', 'm', 'o', 'r', 'e', ' ', 't', 'h', 'i', 'n', 'g', 's', ' ', 'i', 'n', ' ', 'h', 'e', 'a', 'v', 'e', 'n', ' ', 'a', 'n', 'd', ' ', 'e', 'a', 'r', 't', 'h', ',', ' ', 'H', 'o', 'r', 'a', 't', 'i', 'o', ',', ' ', 't', 'h', 'a', 'n', ' ', 'a', 'r', 'e', ' ', 'd', 'r', 'e', 'a', 'm', 't', ' ', 'o', 'f', ' ', 'i', 'n', ' ', 'y', 'o', 'u', 'r', ' ', 'p', 'h', 'i', 'l', 'o', 's', 'o', 'p', 'h', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV_TwjWtz1CI"
      },
      "source": [
        "**Neural Nets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "779ksClsyWyI"
      },
      "source": [
        "#This is a tokenization example while working with neural nets.  Info only,  this is not directly applicable to the current use case:\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drwsqk7iy8_Z",
        "outputId": "a44d0d43-f497-42cd-80e0-e2f6ab54db7c"
      },
      "source": [
        "sent2 = \"Mary had a little lumb and, according to GPT3, ate it with the mint jelly\"\n",
        "encoded_input = tokenizer(sent2)\n",
        "print(encoded_input.input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2090, 1125, 170, 1376, 181, 1818, 1830, 1105, 117, 2452, 1106, 15175, 1942, 1495, 117, 8756, 1122, 1114, 1103, 22532, 179, 23083, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t96Gf--MiTYT"
      },
      "source": [
        "pip install spacy-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7oRFezoYICi"
      },
      "source": [
        "import spacy\n",
        "from termcolor import colored"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL3CoVbAm1dD"
      },
      "source": [
        "import spacy.cli"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQa3LRO_AkUK",
        "outputId": "c7552a26-149f-4c8d-aa95-08a532554be1"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYml9qR2m8aF",
        "outputId": "6062a992-e6a4-44ee-96ae-da117ffa2536"
      },
      "source": [
        "spacy.cli.download('en_core_web_sm')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Y1ppRi7kln"
      },
      "source": [
        "nlp_sm = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRKngjTjYOBR"
      },
      "source": [
        "nlp_lg = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRKOuBoMh2qK"
      },
      "source": [
        "nlp_trf = spacy.load(\"en_core_web_trf\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lQB_vFXUbru"
      },
      "source": [
        "st = ['Make it so we can hide and unhide the carousel',\n",
        "      'Mary had a little lamb and, according to GPT3, ate it with the mint jelly',\n",
        "      '-The well-tested code',\n",
        "      \"I'M GONNA PUKE\",\n",
        "      'Much sleeker. Very attractive!..I would strongly recommend',\n",
        "      'CoughROOTCough',\n",
        "      \"So...I'm very happy\",\n",
        "      'A starling among starlings',\n",
        "      'It was a love-fest',\n",
        "      \"It's great!\",\n",
        "      'Kindle-Fire is on fire'\n",
        "      ]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDSRAvRITqoS"
      },
      "source": [
        "doc_sm = []\n",
        "for item in st:\n",
        "  doc_sm.append(nlp_sm(item))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_w0a84FeWdD"
      },
      "source": [
        "doc_lg = []\n",
        "for item in st:\n",
        "  doc_lg.append(nlp_lg(item))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Hwp3FOnjki"
      },
      "source": [
        "doc_trf = []\n",
        "for item in st:\n",
        "  doc_trf.append(nlp_trf(item))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzg_HEgLYiKe"
      },
      "source": [
        "doc = nlp('Make it so we can hide and unhide the carousel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flfenmq_UL2S"
      },
      "source": [
        "def res_prt(doc,st):\n",
        "  for item, text in zip(doc,st):\n",
        "    print(colored(text,'red'))\n",
        "    for token in item:\n",
        "      print(token.text,token.pos_, token.tag_)\n",
        "    print(' ')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJpCNwUheTYy",
        "outputId": "f3800a96-c457-495d-8076-f36bf9b46f14"
      },
      "source": [
        "print(colored('EN_CORE_WEB_LG','blue'))\n",
        "res_prt(doc_lg,st)\n",
        "print(colored('EN_CORE_WEB_SM','blue'))\n",
        "res_prt(doc_sm,st)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mEN_CORE_WEB_LG\u001b[0m\n",
            "\u001b[31mMake it so we can hide and unhide the carousel\u001b[0m\n",
            "Make VERB VB\n",
            "it PRON PRP\n",
            "so SCONJ IN\n",
            "we PRON PRP\n",
            "can AUX MD\n",
            "hide VERB VB\n",
            "and CCONJ CC\n",
            "unhide VERB VB\n",
            "the DET DT\n",
            "carousel NOUN NN\n",
            " \n",
            "\u001b[31mMary had a little lamb and, according to GPT3, ate it with the mint jelly\u001b[0m\n",
            "Mary PROPN NNP\n",
            "had VERB VBD\n",
            "a DET DT\n",
            "little ADJ JJ\n",
            "lamb NOUN NN\n",
            "and CCONJ CC\n",
            ", PUNCT ,\n",
            "according VERB VBG\n",
            "to ADP IN\n",
            "GPT3 PROPN NNP\n",
            ", PUNCT ,\n",
            "ate VERB VBD\n",
            "it PRON PRP\n",
            "with ADP IN\n",
            "the DET DT\n",
            "mint NOUN NN\n",
            "jelly NOUN NN\n",
            " \n",
            "\u001b[31m-The well-tested code\u001b[0m\n",
            "-The PUNCT HYPH\n",
            "well ADV RB\n",
            "- PUNCT HYPH\n",
            "tested VERB VBN\n",
            "code NOUN NN\n",
            " \n",
            "\u001b[31mI'M GONNA PUKE\u001b[0m\n",
            "I'M NOUN NN\n",
            "GONNA PROPN NNP\n",
            "PUKE PROPN NNP\n",
            " \n",
            "\u001b[31mMuch sleeker. Very attractive!..I would strongly recommend\u001b[0m\n",
            "Much ADV RB\n",
            "sleeker ADJ JJR\n",
            ". PUNCT .\n",
            "Very ADV RB\n",
            "attractive! NOUN NN\n",
            ".. PUNCT NFP\n",
            "I PRON PRP\n",
            "would AUX MD\n",
            "strongly ADV RB\n",
            "recommend VERB VB\n",
            " \n",
            "\u001b[31mCoughROOTCough\u001b[0m\n",
            "CoughROOTCough NOUN NN\n",
            " \n",
            "\u001b[31mSo...I'm very happy\u001b[0m\n",
            "So ADV RB\n",
            "... PUNCT :\n",
            "I'm NOUN NN\n",
            "very ADV RB\n",
            "happy ADJ JJ\n",
            " \n",
            "\u001b[31mA starling among starlings\u001b[0m\n",
            "A DET DT\n",
            "starling NOUN NN\n",
            "among ADP IN\n",
            "starlings NOUN NNS\n",
            " \n",
            "\u001b[31mIt was a love-fest\u001b[0m\n",
            "It PRON PRP\n",
            "was AUX VBD\n",
            "a DET DT\n",
            "love NOUN NN\n",
            "- PUNCT HYPH\n",
            "fest NOUN NN\n",
            " \n",
            "\u001b[31mIt's great!\u001b[0m\n",
            "It PRON PRP\n",
            "'s AUX VBZ\n",
            "great ADJ JJ\n",
            "! PUNCT .\n",
            " \n",
            "\u001b[31mKindle-Fire is on fire\u001b[0m\n",
            "Kindle PROPN NNP\n",
            "- PUNCT HYPH\n",
            "Fire PROPN NNP\n",
            "is AUX VBZ\n",
            "on ADP IN\n",
            "fire NOUN NN\n",
            " \n",
            "\u001b[34mEN_CORE_WEB_SM\u001b[0m\n",
            "\u001b[31mMake it so we can hide and unhide the carousel\u001b[0m\n",
            "Make VERB VB\n",
            "it PRON PRP\n",
            "so SCONJ IN\n",
            "we PRON PRP\n",
            "can AUX MD\n",
            "hide VERB VB\n",
            "and CCONJ CC\n",
            "unhide ADP IN\n",
            "the DET DT\n",
            "carousel NOUN NN\n",
            " \n",
            "\u001b[31mMary had a little lamb and, according to GPT3, ate it with the mint jelly\u001b[0m\n",
            "Mary PROPN NNP\n",
            "had VERB VBD\n",
            "a DET DT\n",
            "little ADJ JJ\n",
            "lamb NOUN NN\n",
            "and CCONJ CC\n",
            ", PUNCT ,\n",
            "according VERB VBG\n",
            "to ADP IN\n",
            "GPT3 PROPN NNP\n",
            ", PUNCT ,\n",
            "ate VERB VBD\n",
            "it PRON PRP\n",
            "with ADP IN\n",
            "the DET DT\n",
            "mint NOUN NN\n",
            "jelly ADV RB\n",
            " \n",
            "\u001b[31m-The well-tested code\u001b[0m\n",
            "-The INTJ UH\n",
            "well ADV RB\n",
            "- PUNCT HYPH\n",
            "tested VERB VBN\n",
            "code NOUN NN\n",
            " \n",
            "\u001b[31mI'M GONNA PUKE\u001b[0m\n",
            "I'M X ADD\n",
            "GONNA PROPN NNP\n",
            "PUKE PROPN NNP\n",
            " \n",
            "\u001b[31mMuch sleeker. Very attractive!..I would strongly recommend\u001b[0m\n",
            "Much ADJ JJ\n",
            "sleeker NOUN NN\n",
            ". PUNCT .\n",
            "Very ADV RB\n",
            "attractive! PROPN NNP\n",
            ".. PUNCT NFP\n",
            "I PRON PRP\n",
            "would AUX MD\n",
            "strongly ADV RB\n",
            "recommend VERB VB\n",
            " \n",
            "\u001b[31mCoughROOTCough\u001b[0m\n",
            "CoughROOTCough PROPN NNP\n",
            " \n",
            "\u001b[31mSo...I'm very happy\u001b[0m\n",
            "So ADV RB\n",
            "... PUNCT NFP\n",
            "I'm PRON PRP\n",
            "very ADV RB\n",
            "happy ADJ JJ\n",
            " \n",
            "\u001b[31mA starling among starlings\u001b[0m\n",
            "A DET DT\n",
            "starling NOUN NN\n",
            "among ADP IN\n",
            "starlings NOUN NNS\n",
            " \n",
            "\u001b[31mIt was a love-fest\u001b[0m\n",
            "It PRON PRP\n",
            "was AUX VBD\n",
            "a DET DT\n",
            "love NOUN NN\n",
            "- PUNCT HYPH\n",
            "fest ADJ JJS\n",
            " \n",
            "\u001b[31mIt's great!\u001b[0m\n",
            "It PRON PRP\n",
            "'s AUX VBZ\n",
            "great ADJ JJ\n",
            "! PUNCT .\n",
            " \n",
            "\u001b[31mKindle-Fire is on fire\u001b[0m\n",
            "Kindle PROPN NNP\n",
            "- PUNCT HYPH\n",
            "Fire PROPN NNP\n",
            "is AUX VBZ\n",
            "on ADP IN\n",
            "fire NOUN NN\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_vMkySeoHCp",
        "outputId": "ef8e1b02-99c2-4225-f756-401b3d915660"
      },
      "source": [
        "res_prt(doc_trf,st)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Make it so we can hide and unhide the carousel\n",
            "Make VERB VB\n",
            "it PRON PRP\n",
            "so SCONJ IN\n",
            "we PRON PRP\n",
            "can AUX MD\n",
            "hide VERB VB\n",
            "and CCONJ CC\n",
            "unhide VERB VB\n",
            "the DET DT\n",
            "carousel NOUN NN\n",
            "/n\n",
            "Mary had a little lumb and, according to GPT3, ate it with the mint jelly\n",
            "Mary PROPN NNP\n",
            "had VERB VBD\n",
            "a DET DT\n",
            "little ADJ JJ\n",
            "lumb NOUN NN\n",
            "and CCONJ CC\n",
            ", PUNCT ,\n",
            "according VERB VBG\n",
            "to ADP IN\n",
            "GPT3 PROPN NNP\n",
            ", PUNCT ,\n",
            "ate VERB VBD\n",
            "it PRON PRP\n",
            "with ADP IN\n",
            "the DET DT\n",
            "mint NOUN NN\n",
            "jelly NOUN NN\n",
            "/n\n",
            "-The well-tested code\n",
            "-The DET DT\n",
            "well ADV RB\n",
            "- PUNCT HYPH\n",
            "tested VERB VBN\n",
            "code NOUN NN\n",
            "/n\n",
            "\n",
            "-The well-tested code\n",
            "\n",
            " SPACE _SP\n",
            "-The DET DT\n",
            "well ADV RB\n",
            "- PUNCT HYPH\n",
            "tested VERB VBN\n",
            "code NOUN NN\n",
            "/n\n",
            "I'M GONNA PUKE\n",
            "I'M VERB VBP\n",
            "GONNA AUX VBG\n",
            "PUKE VERB VB\n",
            "/n\n",
            "Much sleeker. Very attractive!..I would strongly recommend\n",
            "Much ADV RB\n",
            "sleeker ADJ JJR\n",
            ". PUNCT .\n",
            "Very ADV RB\n",
            "attractive! ADJ JJ\n",
            ".. PUNCT NFP\n",
            "I PRON PRP\n",
            "would AUX MD\n",
            "strongly ADV RB\n",
            "recommend VERB VB\n",
            "/n\n",
            "CoughROOTCough\n",
            "CoughROOTCough INTJ UH\n",
            "/n\n",
            "So...I'm very happy\n",
            "So ADV RB\n",
            "... PUNCT NFP\n",
            "I'm PRON PRP\n",
            "very ADV RB\n",
            "happy ADJ JJ\n",
            "/n\n",
            "A starling among starlings\n",
            "A DET DT\n",
            "starling VERB VBG\n",
            "among ADP IN\n",
            "starlings NOUN NNS\n",
            "/n\n",
            "It was a love-fest\n",
            "It PRON PRP\n",
            "was AUX VBD\n",
            "a DET DT\n",
            "love NOUN NN\n",
            "- PUNCT HYPH\n",
            "fest NOUN NN\n",
            "/n\n",
            "Its great!\n",
            "Its VERB VBZ\n",
            "great ADJ JJ\n",
            "! PUNCT .\n",
            "/n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvAz40eRZGaL",
        "outputId": "d4c12df0-bf28-4436-a1b1-c8253a4d4875"
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text,token.pos_, token.tag_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I PRON PRP\n",
            "have AUX VBP\n",
            "limited VERB VBN\n",
            "bookshelf NOUN NN\n",
            "space NOUN NN\n",
            ". PUNCT .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iflIiOSj9zET"
      },
      "source": [
        "doc = nlp('I have limited bookshelf space.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xU3ZxofCaR"
      },
      "source": [
        "-The well-tested code<br> '\\n-The well-tested code'<br>stopwords when spelled out: 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 20, 40, 50, 60, 100<br>\n",
        "not stopwords when spelled out: 7, 13, 14, 16, 17, 18, 19, 30, 70, 80, 90, 1000, 100000<br>Splits \"3G\", though not \"401k\"</br>Splits hyphenated words (including, e.g. \"thirty-six\", \"x-ray\", \"wi-fi\")<br>Doesn't catch multiword tokens like \"in front of\" or \"according to\"<br>I'M GONNA PUKE<br>Much sleeker. Very attractive!..I would strongly recommend<br>sturdy(something<br>Rosette calls \"CoughROOTCough\" a proper noun, which, sure.  Spacy calls it a number, which, what?<br>\"So...I'm very happy.\"<br>\"A starling among starlings.\"<br>\"It was a love-fest\"<br>'Its great!'\n"
      ]
    }
  ]
}