{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKNMTvOJcNTsTc208R5rXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/Tokenization_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdrLsFoJa6dK"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ZpDBftJbO8"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import(TreebankWordTokenizer,\n",
        "                          TweetTokenizer,\n",
        "                          MWETokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INJI5NxvJdi0",
        "outputId": "ca32e83e-42f0-4b93-bf05-05a729508f7e"
      },
      "source": [
        "#Create tokenizers:\n",
        "tree = TreebankWordTokenizer()\n",
        "tweet = TweetTokenizer()\n",
        "mwe = MWETokenizer()\n",
        "\n",
        "# Create a string input\n",
        "sent1 = 'There are more things in heaven and earth, Horatio, than are dreamt of in your philosophy'\n",
        "     \n",
        "# Use tokenize method\n",
        "print(f'Treebank -> {tree.tokenize(sent1)}')\n",
        "print(f'Tweettokenizer -> {tweet.tokenize(sent1)}')\n",
        "print(f'MWEtokenizer -> {mwe.tokenize(sent1)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treebank -> ['There', 'are', 'more', 'things', 'in', 'heaven', 'and', 'earth', ',', 'Horatio', ',', 'than', 'are', 'dreamt', 'of', 'in', 'your', 'philosophy']\n",
            "Tweettokenizer -> ['There', 'are', 'more', 'things', 'in', 'heaven', 'and', 'earth', ',', 'Horatio', ',', 'than', 'are', 'dreamt', 'of', 'in', 'your', 'philosophy']\n",
            "MWEtokenizer -> ['T', 'h', 'e', 'r', 'e', ' ', 'a', 'r', 'e', ' ', 'm', 'o', 'r', 'e', ' ', 't', 'h', 'i', 'n', 'g', 's', ' ', 'i', 'n', ' ', 'h', 'e', 'a', 'v', 'e', 'n', ' ', 'a', 'n', 'd', ' ', 'e', 'a', 'r', 't', 'h', ',', ' ', 'H', 'o', 'r', 'a', 't', 'i', 'o', ',', ' ', 't', 'h', 'a', 'n', ' ', 'a', 'r', 'e', ' ', 'd', 'r', 'e', 'a', 'm', 't', ' ', 'o', 'f', ' ', 'i', 'n', ' ', 'y', 'o', 'u', 'r', ' ', 'p', 'h', 'i', 'l', 'o', 's', 'o', 'p', 'h', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV_TwjWtz1CI"
      },
      "source": [
        "**Neural Nets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "779ksClsyWyI"
      },
      "source": [
        "#This is a tokenization example while working with neural nets.  Info only,  this is not directly applicable to the current use case:\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drwsqk7iy8_Z",
        "outputId": "a44d0d43-f497-42cd-80e0-e2f6ab54db7c"
      },
      "source": [
        "sent2 = \"Mary had a little lumb and, according to GPT3, ate it with the mint jelly\"\n",
        "encoded_input = tokenizer(sent2)\n",
        "print(encoded_input.input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2090, 1125, 170, 1376, 181, 1818, 1830, 1105, 117, 2452, 1106, 15175, 1942, 1495, 117, 8756, 1122, 1114, 1103, 22532, 179, 23083, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t96Gf--MiTYT"
      },
      "source": [
        "!pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7oRFezoYICi"
      },
      "source": [
        "import spacy\n",
        "from termcolor import colored"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOqLjinkiAVz",
        "outputId": "5691bd25-72fa-4fd6-e626-4e876780b4cd"
      },
      "source": [
        "spacy.cli.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'location': '/usr/local/lib/python3.7/dist-packages/spacy',\n",
              " 'pipelines': {},\n",
              " 'platform': 'Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic',\n",
              " 'python_version': '3.7.12',\n",
              " 'spacy_version': '3.1.3'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Y1ppRi7kln"
      },
      "source": [
        "spacy.cli.download('en_core_web_sm')\n",
        "nlp_sm = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdBvsEGlxY90",
        "outputId": "a77bdc24-68ee-45a9-cbe0-320a266c7c29"
      },
      "source": [
        "spacy.cli.download('fr_core_news_sm')\n",
        "nlp_sm = spacy.load('fr_core_news_sm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TucqMR2DsHkT",
        "outputId": "9c3afd0c-f5a7-4a04-84d2-1032c2857dda"
      },
      "source": [
        "spacy.cli.download('xx_sent_ud_sm')\n",
        "nlp_sm = spacy.load('xx_sent_ud_sm')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XUc15Nmiystd",
        "outputId": "085d452f-c4f5-4577-ac4c-6cd27e61e8b1"
      },
      "source": [
        "nlp_sm.meta['version']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.1.0'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZAr5pEmTk-J"
      },
      "source": [
        "#spacy custom tokenizer\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER, CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
        "from spacy.util import compile_infix_regex\n",
        "#from spacy.attrs import ORTH, NORM\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    infixes = (\n",
        "        LIST_ELLIPSES\n",
        "        + LIST_ICONS\n",
        "        + [\n",
        "            r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
        "            r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
        "                al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
        "            ),\n",
        "            r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
        "            #r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
        "            r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    infix_re = compile_infix_regex(infixes)\n",
        "    #infix_re = spacy.util.compile_infix_regex(infixes)\n",
        "\n",
        "    return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
        "                                suffix_search=nlp.tokenizer.suffix_search,\n",
        "                                infix_finditer=infix_re.finditer,\n",
        "                                token_match=nlp.tokenizer.token_match,\n",
        "                                rules=nlp.Defaults.tokenizer_exceptions)\n",
        "\n",
        "\n",
        "nlp_sm.tokenizer = custom_tokenizer(nlp_sm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2b-9wO3779b"
      },
      "source": [
        "case = [{ORTH: \"won't\", NORM: \"will not\"}]\n",
        "nlp_sm.tokenizer.add_special_case(\"won't\", case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL3CoVbAm1dD"
      },
      "source": [
        "import spacy.cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBioocoNXSB1",
        "outputId": "c851bd9e-c84e-4e72-a595-1bfa1daffcca"
      },
      "source": [
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYml9qR2m8aF",
        "outputId": "88852c0a-d2f9-4da9-e2bc-1ab787adba25"
      },
      "source": [
        "spacy.cli.download('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRKngjTjYOBR"
      },
      "source": [
        "nlp_lg = spacy.load('en_core_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRKOuBoMh2qK"
      },
      "source": [
        "nlp_trf = spacy.load(\"en_core_web_trf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lQB_vFXUbru"
      },
      "source": [
        "st = ['Make it so we can hide and unhide the carousel',\n",
        "      'Mary had a little lamb and, according to GPT3, ate it with the mint jelly',\n",
        "      '-The well-tested code',\n",
        "      \"I'M GONNA PUKE\",\n",
        "      'Much sleeker. Very attractive!..I would strongly recommend',\n",
        "      'CoughROOTCough',\n",
        "      \"So...I'm very happy\",\n",
        "      'A starling among starlings',\n",
        "      'It was a love-fest',\n",
        "      \"It's great!\",\n",
        "      'Kindle-Fire is on fire',\n",
        "      \"Mother-in-law loves riding mary-go-around while watching primHD\",\n",
        "      \"In the US and USSR, men & women are each 50% of the population.\" \n",
        "      ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDSRAvRITqoS"
      },
      "source": [
        "doc_sm = []\n",
        "for item in st:\n",
        "  doc_sm.append(nlp_sm(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p822MECWYS4W",
        "outputId": "99ec335f-56bd-410a-9ecf-091b51b3e297"
      },
      "source": [
        "res = nlp_sm(\"tu penses à toi\"); \n",
        "\n",
        "for token in res:\n",
        "  print(token.text, f'lemma={token.lemma_}', f'pos={token.pos_}', f'tag={token.tag_}', f'is_stop={token.is_stop}', f'start={token.idx}', f'stop={token.idx+len(token.shape_)}')\n",
        "  #print(token.text, token.lemma_, token.pos_, token.tag_)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tu lemma= pos= tag= is_stop=False start=0 stop=2\n",
            "penses lemma= pos= tag= is_stop=False start=3 stop=7\n",
            "à lemma= pos= tag= is_stop=False start=10 stop=11\n",
            "toi lemma= pos= tag= is_stop=False start=12 stop=15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0nckCUZAk-",
        "outputId": "d8be90f0-d054-4b0b-ebf9-4830b0c56ef1"
      },
      "source": [
        "ents = [(e.text, e.label_) for e in res.ents]; ents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('U.S.', 'GPE'), ('USSR', 'GPE'), ('50%', 'PERCENT')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_w0a84FeWdD"
      },
      "source": [
        "doc_lg = []\n",
        "for item in st:\n",
        "  doc_lg.append(nlp_lg(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Hwp3FOnjki"
      },
      "source": [
        "doc_trf = []\n",
        "for item in st:\n",
        "  doc_trf.append(nlp_trf(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flfenmq_UL2S"
      },
      "source": [
        "def res_prt(doc,st):\n",
        "  for item, text in zip(doc,st):\n",
        "    print(colored(text,'red'))\n",
        "    for token in item:\n",
        "      print(token.text,token.pos_, token.tag_)\n",
        "    print(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJpCNwUheTYy",
        "outputId": "38588d36-515f-4f5d-f25c-e1db830904b7"
      },
      "source": [
        "#print(colored('EN_CORE_WEB_LG','blue'))\n",
        "#res_prt(doc_lg,st)\n",
        "print(colored('EN_CORE_WEB_SM','blue'))\n",
        "res_prt(doc_sm,st)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mEN_CORE_WEB_SM\u001b[0m\n",
            "\u001b[31mMake it so we can hide and unhide the carousel\u001b[0m\n",
            "Make VERB VB\n",
            "it PRON PRP\n",
            "so SCONJ IN\n",
            "we PRON PRP\n",
            "can VERB MD\n",
            "hide VERB VB\n",
            "and CCONJ CC\n",
            "unhide VERB VB\n",
            "the DET DT\n",
            "carousel NOUN NN\n",
            " \n",
            "\u001b[31mMary had a little lamb and, according to GPT3, ate it with the mint jelly\u001b[0m\n",
            "Mary PROPN NNP\n",
            "had AUX VBD\n",
            "a DET DT\n",
            "little ADJ JJ\n",
            "lamb NOUN NN\n",
            "and CCONJ CC\n",
            ", PUNCT ,\n",
            "according VERB VBG\n",
            "to ADP IN\n",
            "GPT3 PROPN NNP\n",
            ", PUNCT ,\n",
            "ate VERB VBD\n",
            "it PRON PRP\n",
            "with ADP IN\n",
            "the DET DT\n",
            "mint NOUN NN\n",
            "jelly ADV RB\n",
            " \n",
            "\u001b[31m-The well-tested code\u001b[0m\n",
            "-The NUM CD\n",
            "well ADV RB\n",
            "- PUNCT HYPH\n",
            "tested VERB VBN\n",
            "code NOUN NN\n",
            " \n",
            "\u001b[31mI'M GONNA PUKE\u001b[0m\n",
            "I'M PROPN NNP\n",
            "GONNA PROPN NNP\n",
            "PUKE PROPN NNP\n",
            " \n",
            "\u001b[31mMuch sleeker. Very attractive!..I would strongly recommend\u001b[0m\n",
            "Much ADJ JJ\n",
            "sleeker NOUN NN\n",
            ". PUNCT .\n",
            "Very ADV RB\n",
            "attractive! PROPN NNP\n",
            ".. PUNCT .\n",
            "I PRON PRP\n",
            "would VERB MD\n",
            "strongly ADV RB\n",
            "recommend VERB VB\n",
            " \n",
            "\u001b[31mCoughROOTCough\u001b[0m\n",
            "CoughROOTCough PROPN NNP\n",
            " \n",
            "\u001b[31mSo...I'm very happy\u001b[0m\n",
            "So ADV RB\n",
            "... PUNCT NFP\n",
            "I'm PRON PRP\n",
            "very ADV RB\n",
            "happy ADJ JJ\n",
            " \n",
            "\u001b[31mA starling among starlings\u001b[0m\n",
            "A DET DT\n",
            "starling NOUN NN\n",
            "among ADP IN\n",
            "starlings NOUN NNS\n",
            " \n",
            "\u001b[31mIt was a love-fest\u001b[0m\n",
            "It PRON PRP\n",
            "was AUX VBD\n",
            "a DET DT\n",
            "love NOUN NN\n",
            "- PUNCT HYPH\n",
            "fest NOUN NN\n",
            " \n",
            "\u001b[31mIt's great!\u001b[0m\n",
            "It PRON PRP\n",
            "'s AUX VBZ\n",
            "great ADJ JJ\n",
            "! PUNCT .\n",
            " \n",
            "\u001b[31mKindle-Fire is on fire\u001b[0m\n",
            "Kindle PROPN NNP\n",
            "- PUNCT HYPH\n",
            "Fire PROPN NNP\n",
            "is AUX VBZ\n",
            "on ADP IN\n",
            "fire NOUN NN\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vMkySeoHCp"
      },
      "source": [
        "res_prt(doc_trf,st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvAz40eRZGaL"
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text,token.pos_, token.tag_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iflIiOSj9zET"
      },
      "source": [
        "doc = nlp('I have limited bookshelf space.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xU3ZxofCaR"
      },
      "source": [
        "-The well-tested code<br> '\\n-The well-tested code'<br>stopwords when spelled out: 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 20, 40, 50, 60, 100<br>\n",
        "not stopwords when spelled out: 7, 13, 14, 16, 17, 18, 19, 30, 70, 80, 90, 1000, 100000<br>Splits \"3G\", though not \"401k\"</br>Splits hyphenated words (including, e.g. \"thirty-six\", \"x-ray\", \"wi-fi\")<br>Doesn't catch multiword tokens like \"in front of\" or \"according to\"<br>I'M GONNA PUKE<br>Much sleeker. Very attractive!..I would strongly recommend<br>sturdy(something<br>Rosette calls \"CoughROOTCough\" a proper noun, which, sure.  Spacy calls it a number, which, what?<br>\"So...I'm very happy.\"<br>\"A starling among starlings.\"<br>\"It was a love-fest\"<br>'Its great!'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSKGAqtE_4WQ"
      },
      "source": [
        "# Text Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj_xwbaWFrjW"
      },
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jzjip85QnGn"
      },
      "source": [
        "from scipy.spatial import distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AUXwZMZHX0o",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "02c63fa1-8042-4177-ad63-3390b4b17a32"
      },
      "source": [
        "# file upload while using Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe48ad6d-7e09-49fe-89ce-d56376c36e5c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fe48ad6d-7e09-49fe-89ce-d56376c36e5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving summaries.csv to summaries.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gekeYLabgSqC"
      },
      "source": [
        "#csv file processing block\n",
        "df  = pd.read_csv('beer_5k.csv')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omX1n8f_ImQz"
      },
      "source": [
        "df_s = pd.read_csv('summaries.csv')"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PVn8sbHYIvv9",
        "outputId": "91b2684a-d257-4f90-a6d3-2c894c98ef5b"
      },
      "source": [
        "df_s['Summaries'][0]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Dark orange in color, with a lively carbonation (now visible, under the foam) A lot of foam. But a lot of banana and lactic sourness. Not a good start. The taste of the beer is lactic'"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9LM2bQMhOXq"
      },
      "source": [
        "out = df['text'].tolist(); len(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRdWI8fqF1LE"
      },
      "source": [
        "data = []\n",
        "with open('kindle.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZUiBvJ4GCQ1"
      },
      "source": [
        "data[50]['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc1IWUP4LpLc"
      },
      "source": [
        "txts = [] \n",
        "for item in data:\n",
        "  txts.append(re.sub('\\n+', ' ', item['text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvkqDyTmj4es"
      },
      "source": [
        "**Google Unviersal Encoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9r3x0isJVYx"
      },
      "source": [
        "!pip install -q tensorflow-hub\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyCaA0ykJWPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bec36e7-7264-445c-aa19-fca5f58e60b4"
      },
      "source": [
        "#using universal sentence encoder to get sentence encodings\n",
        "#Load the Universal Sentence Encoder's TF Hub module\n",
        "#param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "print (\"module {} loaded\".format(module_url))\n",
        "model = hub.load(module_url)\n",
        "def embed(input):\n",
        "  return model(input)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38j5vtKsjn3y"
      },
      "source": [
        "**lumi embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwPNIBDH8OF9"
      },
      "source": [
        "test_data = np.load('vector.npz')\n",
        "#test_data['vect'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaWJUT8CGukA"
      },
      "source": [
        "test_data['vect'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CkEVgEqH9yw"
      },
      "source": [
        "concept_data = np.load('concept_vector.npz')\n",
        "concept_data['vect'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znQAWS4FIwoe"
      },
      "source": [
        "lumi = np.concatenate((test_data['vect'],concept_data['vect']), axis=0); lumi.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8ln3PbPHlaF"
      },
      "source": [
        "lumi = []\n",
        "for row in test_data['vect']:\n",
        "  lumi.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoz5TR24IAKY"
      },
      "source": [
        "lumi[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f90zKenojbot"
      },
      "source": [
        "**embedding using universal encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MgzpTPxse-L"
      },
      "source": [
        "concepts = ['Kindle','Amazon','apps','tablet','Kindle Fire','purchase','Kindle Fire HD','iPad','device','download']\n",
        "concept_vectors = np.array(model(concepts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuFOLc08JjRL"
      },
      "source": [
        "embedding_tuples = []\n",
        "for item in txts:\n",
        "  tmp = embed([item]).numpy(),item\n",
        "  embedding_tuples.append(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb8T2fvA7B8-"
      },
      "source": [
        "embedding_tuples[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1WsE_CiaGPA"
      },
      "source": [
        "test = []\n",
        "for item in txts:\n",
        "  test.append(embed([item]).numpy().flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-A5AZlIJaV"
      },
      "source": [
        "test = np.array(test); test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkMvWhssE7SZ"
      },
      "source": [
        "test_test = np.concatenate((test,concept_vectors), axis=0); test_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfVxEkmzJkO9"
      },
      "source": [
        "# data visualization:\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCHQ12p_Jpt9"
      },
      "source": [
        "# visualization code\n",
        "def tsne_plot(emb):\n",
        "    \"Creates and TSNE model and plots it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    #for i in range(len(emb)):\n",
        "        #tokens.append(emb[i][0])\n",
        "        #labels.append(emb[i][1])\n",
        "    tkns = np.array(emb)\n",
        "    tkns = tkns.reshape(tkns.shape[0], -1)\n",
        "    tsne_model = TSNE(perplexity=30, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(tkns)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "        \n",
        "    plt.figure(figsize=(16, 16)) \n",
        "    #Outputting all the embeddings\n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgg7ERxiJvvV"
      },
      "source": [
        "#tsne_plot(embedding_tuples)\n",
        "tsne_plot(lumi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGBIWD6FgoV6"
      },
      "source": [
        "# some funcier visualization code\n",
        "def tsne_plot_fancy(emb):\n",
        "    \"Creates and TSNE model and plots it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    #for i in range(len(emb)):\n",
        "        #tokens.append(emb[i][0])\n",
        "        #labels.append(emb[i][1])\n",
        "    #tokens = np.array(emb)\n",
        "    #print(tokens[:1])\n",
        "    #tokens = tokens.reshape(tokens.shape[0], -1)\n",
        "    #points = points.reshape(tkns.shape[0], -1)\n",
        "    tsne_model = TSNE(perplexity=30, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(emb)\n",
        "    #concepts_values = tsne_model.fit_transform(points)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "\n",
        "    print(new_values[-10:])\n",
        "    x_p = []\n",
        "    y_p = []\n",
        "    for value in new_values[-10:]:\n",
        "        x_p.append(value[0])\n",
        "        y_p.append(value[1])    \n",
        "\n",
        "        \n",
        "    plt.figure(figsize=(16, 16)) \n",
        "    #Outputting all the embeddings and overlying concepts\n",
        "    lb = ['Kindle','Amazon','apps','tablet','Kindle Fire','purchase','Kindle Fire HD','iPad','device','download']\n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "    for i in range(len(x_p)):\n",
        "        plt.scatter(x_p[i],y_p[i],s=500,c='darkblue')\n",
        "        '''plt.annotate(lb[i],\n",
        "              xy=(x_p[i], y_p[i]),\n",
        "              xytext=(15, 15),\n",
        "              textcoords='offset points',\n",
        "              fontsize = 12,\n",
        "              ha='right',\n",
        "              va='bottom')  '''\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrg2Y5Jc1NG3"
      },
      "source": [
        "#tsne_plot with concepts overlay(embedding_tuples)\n",
        "tsne_plot_fancy(test_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8p4bQzmHg4A"
      },
      "source": [
        "tsne_plot_fancy(lumi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSUh2WVkY9Ec"
      },
      "source": [
        " [ -4.180652  -59.0469   ] -- 'Kindle' (1)<br>\n",
        " [ 40.489338  -18.087015 ] -- 'Amazon'(2)<br>\n",
        " [ 45.76149    -6.4174824] -- 'apps'(3)<br>\n",
        " [-28.779793  -39.422756 ] -- 'tablet' (4)<br>\n",
        " [ -4.189738  -59.018326 ] -- 'Kindle Fire (5)'<br>\n",
        " [ 53.536438  -26.654696 ] -- 'purchase'(6)<br>\n",
        " [ -4.195783  -58.99838  ] -- 'Kindle Fire HD' (7)<br>\n",
        " [ -8.17021   -43.90645  ] -- 'iPad' (8)<br>\n",
        " [-28.982622  -39.634308 ] -- 'device' (9)<br>\n",
        " [ 53.530563  -26.637133 ] -- 'download'(10)<br>\n",
        " ['Kindle','Amazon','apps','tablet','Kindle Fire','purchase','Kindle Fire HD','iPad','device','download']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTSdZgHX0Nvx"
      },
      "source": [
        "**Documents to Concepts Measuring**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYc76Yfa0be0"
      },
      "source": [
        "#512 - dimensional embeddings\n",
        "top_20 = []\n",
        "target = concept_vectors[4]\n",
        "for ind, item in enumerate(embedding_tuples[:10]):\n",
        "    tmp = distance.cosine(item[0],target),item[1],ind\n",
        "    top_20.append(tmp)\n",
        "\n",
        "top_20.sort()\n",
        "\n",
        "for ind, item in enumerate(embedding_tuples[10:100]):\n",
        "  tmp = distance.cosine(item[0],target),item[1],ind\n",
        "  if tmp[0]<top_20[-1][0]:\n",
        "    top_20.pop()\n",
        "    top_20.append(tmp)\n",
        "    top_20.sort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mho4cSSs_b_b"
      },
      "source": [
        "[item[2] for item in top_20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twjfx2E9_3yw"
      },
      "source": [
        "[2, 6, 1, 4, 8, 7, 0, 5, 9, 51]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Fx11KC8LtR"
      },
      "source": [
        "import pprint\n",
        "pp = pp = pprint.PrettyPrinter(indent=1, width=100)\n",
        "for text in top_20:\n",
        "  pp.pprint(text[1])\n",
        "  print(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etmtzaseIKTp"
      },
      "source": [
        "*USEFUL CODE SNIPPETS*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV2BB7bUiJeJ"
      },
      "source": [
        "**Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7b8aYMPzfn0"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA2SikT_18V_"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI7XzkFW4mHj"
      },
      "source": [
        "import pprint"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4cEwrya2E93"
      },
      "source": [
        "summarizer = pipeline(\"summarization\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so86cQpLiuYL"
      },
      "source": [
        "summaries = []\n",
        "for item in out:\n",
        "  summaries.append(summarizer(item, max_length=50, do_sample=False, devvice = 1)[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hDkcY8a-anY"
      },
      "source": [
        "new_summaries=list(summaries)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSxtxdgM6AZ",
        "outputId": "b40c7856-b2e8-47d6-ca53-7eb0812768f6"
      },
      "source": [
        "pp.pprint(new_summaries[:2])"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Dark orange in color, with a lively carbonation (now visible, under the foam) A lot of foam. But a lot of banana and lactic sourness. Not a good start. The taste of the beer is lactic',\n",
            " ' Dark red color, light beige foam, average body . Light fruitiness, malt and caramel in the taste, not bad in the end . Aftertaste a light bitterness, with the malt and red fruit . Nothing exceptional, but']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToN2GnUP_1hp"
      },
      "source": [
        "df_out = pd.DataFrame(new_summaries, columns=['Summaries'])\n",
        "df_out.to_csv('summaries1.csv',index=False, sep=',')"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3DI8iJLGvGd"
      },
      "source": [
        "df_out.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccROxGUKkGze"
      },
      "source": [
        "#using Google Universal encoder to get embeddings:\n",
        "res = embed(new_summaries)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYTmfHfWkat-"
      },
      "source": [
        "res_np = res.numpy()"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZjT8MhOlTaZ"
      },
      "source": [
        "#creating tsv format\n",
        "tmp = '\\t'.join(str(x) for x in res.numpy()[0])"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ddHEuuHmpFM"
      },
      "source": [
        "# Save embeddings in tsv file.\n",
        "\n",
        "with open('vectors.tsv', \"w\") as f:\n",
        "  for vec in res_np:\n",
        "    tmp = '\\t'.join(str(x) for x in vec)\n",
        "    f.write(\"{}\\n\".format(tmp))"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJ8BLdvLx79"
      },
      "source": [
        "with open('metadata.tsv', \"w\") as f:\n",
        "  for label in new_summaries:\n",
        "    f.write(\"{}\\n\".format(label))"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y8F-Ep8BmOGn",
        "outputId": "50db92b4-7658-458c-ef15-5506bb88d27c"
      },
      "source": [
        "files.download('vectors.tsv')"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2eebaca1-96f2-4fa6-9975-4557f7dd08dc\", \"vectors.tsv\", 5535652)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgR0EphZ2I8j"
      },
      "source": [
        "test_input = \"\"\" Quite a ruby red hue... deep, rich, almost sporting a soft glow. There's a bit of a sandy colour in the head. \n",
        "Not much for lacing, but the glass seems to be playing a role in that, as it has had a couple different brews in it, all of which laced poorly. \t\t\n",
        "S + T: I thoroughly enjoy a good rauch, and this one performs quite well in the traditional 'ham and cheese sandwich' sense. \n",
        "It's not overly smoky, which is a positive thing in that it allows some of the other delicate scents and flavours to shine. Of those, \n",
        "I pick up on a light - but noticeable - fruitiness, both in nose and on the palate that seems a little odd. \t\t\n",
        "worth note: after writing the above, I noticed the print on the side of the bottle to see that cherry wood is used in addition to beechwood. \n",
        "That would explain the fruitiness noted. \t\tM + D: Body feels a little lighter in the mouthfeel, but seems to pick up a little weight \n",
        "after going down, however little sense that might make. The alcohol content is perhaps a little high, but a little slower sipping never \n",
        "hurt anyone. Not a bad take on the style, though I think I personally would have enjoyed it better if the actual smokiness were a touch \n",
        "more robust.\n",
        "\"\"\""
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBnxzuZMAqqJ",
        "outputId": "286058fb-6171-48ed-949c-0ab6abd32272"
      },
      "source": [
        "pp.pprint(summarizer(test_input, max_length=100, min_length=20, do_sample=False))"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': ' A ruby red hue... deep, rich, almost sporting a '\n",
            "                  'soft glow . Not overly smoky, which is a positive '\n",
            "                  'thing in that it allows some of the other '\n",
            "                  'delicate scents and flavours to shine . The '\n",
            "                  'alcohol content is perhaps a little high, but a '\n",
            "                  'little slower sipping never hurt anyone .'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6oHpZlM37q9"
      },
      "source": [
        "test = \"\"\"appearance: Wow very active beer with a haze through it. The white lace does stay on top forever it felt like. \t\t\n",
        "Smell: Hoppy with needles. It really is a classic lager smell\t\tTaste: Clean with off flavor on the back end that \n",
        "I just can't put my finger on it. someone help me with it....\t\tmouthfeel is bad. It burns there is so much carbonation. \n",
        "I just can't do it. It honestly sent my taste-buds into shock on the first drink there was so much activity on my tongue. \t\t\n",
        "I found myself wanting to rank it higher but it just wasn't there to get the higher rating.\n",
        "Review from BeerAdvocate Magazine Issue #42 (Jul 2010): \t\tYES! More craft brewers need to adjunct their beer. The lacing has staying power, though the haze on the yellow is distracting. This lager packs a yeasty, grassy aroma. Crisp and a bit slick, obvious light body. Fresh- cut grass and nutty yeast coat the palate; hops are fresh with ample bitterness and a good amount of flavor, which brings this beer up a few notches. The maltiness is a bit light, but right where it's supposed to be. Flavor overrides cleanliness. Very drinkable as well.\n",
        "22 picked up at Brewforia on the way home from work. Poured into my big Shorts Imperial Pint (thanks Kevin).\t\tFoamy 1\" white head dies back into nice lacing... no real retention though... okay cap... the brew is very pale golden with seemingly a lite haze of some sort.\t\tClean grains... little else.. a bit husky and traces of sulfur if I really concentrate.\t\tAgain... very clean.... pale malts... a bit doughy.\t\tSlightly better than expected body and carbonation.\t\tMeh... okay I guess... good for what it is... tastes pretty fresh and crisp.\t\t3.5/3/3.5/3.5/4.5\n",
        "Bomber pours a clear straw yellow body with a small vanilla head that quickly drops into some scattered lacing.\t\tAroma has some crackery malt and a hint of floral hops.\t\tMouthfeel is light bodied with a spritzy carbonation.\t\tTaste is dominated by a crackery pilsner type maltiness that is balanced by a dry grassy and floral hoppiness. Reminds me of kolsch.\t\tUnpretentious and unoffensive. A decent lawn mower beer, I suppose.\n",
        "A - Two plus fingers of big chunky fizzy effervescent pure white head... Pretty impressive retention, especially by Adjunct Lager standards... An extremely pale slightly hazy golden straw color... A moderate bit of moderate paced carbonation swirls throughout... \t\tS - Cracker... Cereal... Doughy... Grainy... A touch of honey and a kiss of lemon... \t\tT - Dominated by pale malts... Bready... Grainy... Cracker... Lemon zest... Just the slightest presence of honey... Just an allusion of light pilsneresque hops... \t\tM - Medium bodied... A muted carbonation bite... Slightly chewy... Crisp... Mildly refreshing... \t\tD - Quaffable... Nothing to write home about, but slightly more drinkable than your average Adjunct Lagers.... As simple and straight forward as they come... Doesn't challenge the palette or any of the senses, but every once in a while that's okay...\n",
        "Appearance - Pours a pale golden color with about a finger of quickly dissipating head that leaves little lacing on the edges of the glass.\t\tSmell - Light hops, grainy malts, breadyness.\t\tTaste - Taste is similar to the nose with a hint of caramel/honey. Nothing really stands out to me as special, but then again what do you expect with the description on the side of this.\t\tMouthfeel - Light bodied, prickly carbonation.\t\tDrinkability - Quite drinkable to be honest, however as someone else stated, might as well buy some PBR's rather than spend money on this.\n",
        "220z bomber poured into a pint glass.\t\tA: Pours yellow and fizzy - nothing special here.\t\tS: Smells decent, like a typical mid-range lager.\t\tT: I was really expecting a lager with a bit of hop to it, judging by the name - \"Lawnmower Lager\" thinking it might be a little grassy (hoppy), much to my dismay this couldn't be further from the truth. There's a weird overwhelming honey malt flavor that is out of balance and I really don't get a nice lager flavor at all. It really reminds me of that cheap beer - \"Oregon Honey Beer\". Nothing special at all, and especially at $5.00 a bottle.\t\tM: Light bodied and fizzy as hell. \t\tD: It's actually quite drinkable and probably it's greatest quality, but at $5.00 a bottle - give me a break.\n",
        "Pours a clear very light yellow with strong carbonation but a weak head. The aroma is sweet, non-descript malt with just a touch of grassy hops and some graininess. The flavor is quite similar with pale malt sweetness, some grassy herbal hops, clean yeast, grainy notes and a surprising amount of bitterness. I have to say that the flavor is pretty disappointing, even for this style, though the dryness does give it some merit. Mouthfeel is not just light, but watery. It has a nice dry finish and is very quaffable, and holds up alright when compared to other beers in this category, but I think there are better options.\n",
        "22 oz. bomber,\t\tA: Pours a pale yellow, soft white head, fairly good retention per the style.\t\tS: Some grainy malt notes, light hops, mild inoffensive nose.\t\tT: Direct pilsner esque barley malt flavour, light hopping. Again, mild but the malt flavour is good.\t\tM: Light-bodied, crisp, very clean, refreshing.\t\tD: A solid pale lager, not as much flavour as I wanted, maybe akin to Full Sail Session is what I was looking for. As an innocuous easy drinking lager it did its job.\n",
        "Saw this at the store for a great price (2 bucks for a 22oz bottle) and picked it up.\t\tA- A clear pale straw yellow, very clear and clean. Very little head but then again most beers of this style don't have much head so in comparison to the style it is good. \t\tS- This has your typical lager yeast smell. There is a bready, earthy, grainy and gritty smell. Very rounded and bold smells in terms of beer of this style.\t\tT- The beer is crisp and refreshing. I'm getting a big grain taste that is like chewing on the top of a barley stalk. More like the smell of when a grain truck dumps its freshly harvested barley load into the grain grate to be weighed and priced, take that smell and put it as a taste and that's what I'm getting. There is a subtle sweet honey taste that is coming though and adds a nice level of flavor. There is actually a nice complexity going on with this beer, especially when you are comparing it to other beers of the style. \t\tM- Good mouthfeel, nice carbination and a very light body.\t\tD- Easy to drink, the name of the beer fits very well. I would drink this after working out in the yard no prob. This is clean but not BMC clean. It's more like clean but in a dirty glass type clean. \t\tLagers are not my favorite styles of beer. But one thing I've found is that the flavors are more subtle then other styles. Many craft lagers get a bad wrap because of BMC lagers and how many people are so against them here on BA. I rated this beer based on its style, and for its style it is very well done and tasty. I would definitely buy this one again.\n",
        "Poured a very pale yellow. No head whatsoever. Some bready aroma, but very light. Very faint lemony flavor. Extremely light malt flavors that finished with a distinct light beer aftertaste. \tThis beer shoud've been labeled as a light beer. Shame on me for buying a lager with an ABV less than 4. Almost any mass produced light beer is better than this one. I even drank it after mowing my lawn. Should've had a tall glass of water.\n",
        "22 oz bomber. Slight aroma of bread, light whiffs of cheese for some reason. Ugly looking beer..insipid pee colour..least the small white head hangs around. Taste papery, bread, some lemongrass. Really very little to it Macro-lager palate to it..average. Overall pretty bad stuff here.' Get a 40 of MHL or PBR save you money.\n",
        "Pours clear gold with one finger of fluffy white head. Minor lacing. Aroma is slightly corny, some bread from the yeast. Taste is malty and just a hint of hop bitterness. Clean and full bodied for the style. Moderate carbonation. Clean, sweet, and some mild bitterness in the finish. Served a bit warmer than the style calls for. Still prefer Full Sail Session beer for mowing lawns but if Caldera were to can this beer I would drink some on a hot day by the pool or mowing the yard. I like the fact that it is 3.9% abv. Good beer for such a low alcohol content. Really a \"light lager\". And in that category it is a winner. I paid $3.09 for a bomber which is too expensive for lawnmower beer. Let's see if they can this brew. I would buy it over the macros if it was about $5.99 a sixer.\n",
        "Let me start by sharing what's on the side of the bottle: \"For all you people who are afraid of beer you can't see through, this one is for you. This beer is yellow, fizzy, and clearly meant for washing dirt out of your mouth after mowing the lawn.\" I'm not even sure it's good for that. It's definitely yellow and fizzy, with no head to speak of, and zero lacing. It almost smells like a loaf of bread, and nearly tastes the same. It's very earthy and grainy with nary a hop to be found. Man, I love me some Caldera, but I would rather drink a Bud Light than this on a hot summer day. Sorry guys, but this beer gets an F.\"\"\""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBYdY_AHNL9V",
        "outputId": "2604286a-87a1-4d50-8903-fc0c1dda8eff"
      },
      "source": [
        "len(test.split())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1644"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooG__Yj3Lf_L"
      },
      "source": [
        "test1 = ' '.join(test.split()[:600])\n",
        "test2 = ' '.join(test.split()[600:1200])\n",
        "test3 = ' '.join(test.split()[1200:1644])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6f_f8xNWJW"
      },
      "source": [
        "test2 = ' '.join(test.split()[600:1200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQPQYNvk9oyf"
      },
      "source": [
        "question_answerer = pipeline(\"question-answering\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBRP6MZL9376",
        "outputId": "b83abfb1-6fbb-4d21-8081-464b911ad759"
      },
      "source": [
        "result = question_answerer(question=\"What are the flavors?\", context= test)\n",
        "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 'pale malt and low hop bitterness', score: 0.0508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7xmpiP-2jrr",
        "outputId": "9dac0aea-4f7b-4427-e36d-0cb51216078f"
      },
      "source": [
        "pp = pprint.PrettyPrinter(width=70)\n",
        "pp.pprint(summarizer(test1, max_length=100, do_sample=False))\n",
        "pp.pprint(summarizer(test2, max_length=100, do_sample=False))\n",
        "pp.pprint(summarizer(test3, max_length=100, do_sample=False))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': ' BeerAdvocate Magazine Issue #42 (Jul 2010): YES! '\n",
            "                  'More craft brewers need to adjunct their beer . '\n",
            "                  'The lacing has staying power, though the haze on '\n",
            "                  'the yellow is distracting . Taste dominated by a '\n",
            "                  'crackery pilsner type maltiness balanced by a dry '\n",
            "                  'grassy and floral hoppiness .'}]\n",
            "[{'summary_text': ' The aroma is sweet, non-descript malt with just '\n",
            "                  'a touch of grassy hops and some graininess . The '\n",
            "                  'flavor is quite similar with pale malt sweetness, '\n",
            "                  'some grassy herbal hops, clean yeast, grainy '\n",
            "                  'notes and a surprising amount of bitterness . It '\n",
            "                  'has a nice dry finish and is very quaffable, but '\n",
            "                  'I think there are better options .'}]\n",
            "[{'summary_text': ' Pours clear gold with one finger of fluffy white '\n",
            "                  'head . Aroma is slightly corny, some bread from '\n",
            "                  'the yeast . Taste is malty and just a hint of hop '\n",
            "                  'bitterness . Clean and full bodied for the style '\n",
            "                  '. Served a bit warmer than the style calls for .'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIZilgfSORkK"
      },
      "source": [
        "test_sum = (' BeerAdvocate Magazine Issue #42 (Jul 2010): YES! '\n",
        "                  'More craft brewers need to adjunct their beer . '\n",
        "                  'The lacing has staying power, though the haze on '\n",
        "                  'the yellow is distracting . Taste dominated by a '\n",
        "                  'crackery pilsner type maltiness balanced by a dry '\n",
        "                  'grassy and floral hoppiness .'' The aroma is sweet, non-descript malt with just '\n",
        "                  'a touch of grassy hops and some graininess . The '\n",
        "                  'flavor is quite similar with pale malt sweetness, '\n",
        "                  'some grassy herbal hops, clean yeast, grainy '\n",
        "                  'notes and a surprising amount of bitterness . It '\n",
        "                  'has a nice dry finish and is very quaffable, but '\n",
        "                  'I think there are better options .'' The aroma is sweet, non-descript malt with just '\n",
        "                  'a touch of grassy hops and some graininess . The '\n",
        "                  'flavor is quite similar with pale malt sweetness, '\n",
        "                  'some grassy herbal hops, clean yeast, grainy '\n",
        "                  'notes and a surprising amount of bitterness . It '\n",
        "                  'has a nice dry finish and is very quaffable, but '\n",
        "                  'I think there are better options .')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "8xXi2EOKOqZC",
        "outputId": "ec88ac93-56a2-4c72-bcd0-b43712dd61a7"
      },
      "source": [
        "test_sum"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' BeerAdvocate Magazine Issue #42 (Jul 2010): YES! More craft brewers need to adjunct their beer . The lacing has staying power, though the haze on the yellow is distracting . Taste dominated by a crackery pilsner type maltiness balanced by a dry grassy and floral hoppiness . The aroma is sweet, non-descript malt with just a touch of grassy hops and some graininess . The flavor is quite similar with pale malt sweetness, some grassy herbal hops, clean yeast, grainy notes and a surprising amount of bitterness . It has a nice dry finish and is very quaffable, but I think there are better options . The aroma is sweet, non-descript malt with just a touch of grassy hops and some graininess . The flavor is quite similar with pale malt sweetness, some grassy herbal hops, clean yeast, grainy notes and a surprising amount of bitterness . It has a nice dry finish and is very quaffable, but I think there are better options .'"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zmrdKjOPZw0",
        "outputId": "a4408040-8506-42f4-dc71-f74b9cd74cc3"
      },
      "source": [
        "pp.pprint(summarizer(test_sum, max_length=100, do_sample=False))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': ' The aroma is sweet, non-descript malt with just '\n",
            "                  'a touch of grassy hops and some graininess . The '\n",
            "                  'flavor is quite similar with pale malt sweetness, '\n",
            "                  'some grassy herbal hops, clean yeast, grainy '\n",
            "                  'notes and a surprising amount of bitterness . It '\n",
            "                  'has a nice dry finish and is very quaffable, but '\n",
            "                  'I think there are better options .'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZmsge_yXoo"
      },
      "source": [
        "concepts = ['Kindle','Amazon','apps','tablet','Kindle Fire','purchase','Kindle Fire HD','iPad','device','download']\n",
        "concept_vectors = np.array(model(concepts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nj8OPRgyYyt"
      },
      "source": [
        "distance.cosine(concept_vectors[0],concept_vectors[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16HDSWo62ZlU"
      },
      "source": [
        "concept_data = np.load('concept_vector.npz')\n",
        "concept_data['vect'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5vt43au2as8"
      },
      "source": [
        "distance.cosine(concept_data['vect'][4],concept_data['vect'][9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzepDgI_AorF"
      },
      "source": [
        "#concept_vectors.shape\n",
        "a=np.zeros((90,512))\n",
        "concept_vectors_padded = np.concatenate((concept_vectors,a), axis=0); concept_vectors_padded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OSrG5rbQOre"
      },
      "source": [
        "str1 = 'I\\'m no good'\n",
        "str2 =  \"I'm no good\"\n",
        "str3 = 'I am no good' \n",
        "inp = [str1,str2,str3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlQUQkxDRUYE"
      },
      "source": [
        "out = np.array(model(inp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQF5oeMEROLG"
      },
      "source": [
        "distance.cosine(out[0],out[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCGjkajvIuaP"
      },
      "source": [
        "!unzip file_location"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgdVOuXgGHJr"
      },
      "source": [
        "for item in data:\n",
        "  re.sub('\\n+', ' ' item['text'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}