{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQ9MDEUWGi+WUOH+hRBTRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastrop/kaggle/blob/master/Tokenization_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ZpDBftJbO8"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import(TreebankWordTokenizer,\n",
        "                          TweetTokenizer,\n",
        "                          MWETokenizer)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INJI5NxvJdi0",
        "outputId": "ca32e83e-42f0-4b93-bf05-05a729508f7e"
      },
      "source": [
        "#Create tokenizers:\n",
        "tree = TreebankWordTokenizer()\n",
        "tweet = TweetTokenizer()\n",
        "mwe = MWETokenizer()\n",
        "\n",
        "# Create a string input\n",
        "sent1 = 'There are more things in heaven and earth, Horatio, than are dreamt of in your philosophy'\n",
        "     \n",
        "# Use tokenize method\n",
        "print(f'Treebank -> {tree.tokenize(sent1)}')\n",
        "print(f'Tweettokenizer -> {tweet.tokenize(sent1)}')\n",
        "print(f'MWEtokenizer -> {mwe.tokenize(sent1)}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treebank -> ['There', 'are', 'more', 'things', 'in', 'heaven', 'and', 'earth', ',', 'Horatio', ',', 'than', 'are', 'dreamt', 'of', 'in', 'your', 'philosophy']\n",
            "Tweettokenizer -> ['There', 'are', 'more', 'things', 'in', 'heaven', 'and', 'earth', ',', 'Horatio', ',', 'than', 'are', 'dreamt', 'of', 'in', 'your', 'philosophy']\n",
            "MWEtokenizer -> ['T', 'h', 'e', 'r', 'e', ' ', 'a', 'r', 'e', ' ', 'm', 'o', 'r', 'e', ' ', 't', 'h', 'i', 'n', 'g', 's', ' ', 'i', 'n', ' ', 'h', 'e', 'a', 'v', 'e', 'n', ' ', 'a', 'n', 'd', ' ', 'e', 'a', 'r', 't', 'h', ',', ' ', 'H', 'o', 'r', 'a', 't', 'i', 'o', ',', ' ', 't', 'h', 'a', 'n', ' ', 'a', 'r', 'e', ' ', 'd', 'r', 'e', 'a', 'm', 't', ' ', 'o', 'f', ' ', 'i', 'n', ' ', 'y', 'o', 'u', 'r', ' ', 'p', 'h', 'i', 'l', 'o', 's', 'o', 'p', 'h', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV_TwjWtz1CI"
      },
      "source": [
        "**Neural Nets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar898zERyyhF"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "779ksClsyWyI"
      },
      "source": [
        "#This is a tokenization example while working with neural nets.  Info only,  this is not directly applicable to the current use case:\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drwsqk7iy8_Z",
        "outputId": "a44d0d43-f497-42cd-80e0-e2f6ab54db7c"
      },
      "source": [
        "sent2 = \"Mary had a little lumb and, according to GPT3, ate it with the mint jelly\"\n",
        "encoded_input = tokenizer(sent2)\n",
        "print(encoded_input.input_ids)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2090, 1125, 170, 1376, 181, 1818, 1830, 1105, 117, 2452, 1106, 15175, 1942, 1495, 117, 8756, 1122, 1114, 1103, 22532, 179, 23083, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7oRFezoYICi"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQa3LRO_AkUK",
        "outputId": "d27ed3d2-2301-4ec8-f6e3-50fd983d1f2d"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRKngjTjYOBR"
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzg_HEgLYiKe"
      },
      "source": [
        "doc = nlp('Make it so we can hide and unhide the carousel')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvAz40eRZGaL",
        "outputId": "d4c12df0-bf28-4436-a1b1-c8253a4d4875"
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text,token.pos_, token.tag_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I PRON PRP\n",
            "have AUX VBP\n",
            "limited VERB VBN\n",
            "bookshelf NOUN NN\n",
            "space NOUN NN\n",
            ". PUNCT .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iflIiOSj9zET"
      },
      "source": [
        "doc = nlp('I have limited bookshelf space.')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xU3ZxofCaR"
      },
      "source": [
        "-The well-tested code<br> '\\n-The well-tested code'<br>stopwords when spelled out: 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 20, 40, 50, 60, 100<br>\n",
        "not stopwords when spelled out: 7, 13, 14, 16, 17, 18, 19, 30, 70, 80, 90, 1000, 100000<br>Splits \"3G\", though not \"401k\"</br>Splits hyphenated words (including, e.g. \"thirty-six\", \"x-ray\", \"wi-fi\")<br>Doesn't catch multiword tokens like \"in front of\" or \"according to\"<br>I'M GONNA PUKE<br>Much sleeker. Very attractive!..I would strongly recommend<br>sturdy(something<br>Rosette calls \"CoughROOTCough\" a proper noun, which, sure.  Spacy calls it a number, which, what?\n"
      ]
    }
  ]
}